\chapter[Pruebas de hipótesis]{Pruebas de hipótesis}

El tema de las pruebas de hipótesis se difiere con la estimación puntual y la estimación por intervalo de confianza en el sentido de que éstos proveen valor o un conjunto de valores específicos que el parámetro de interés puede tomar, mientras que una prueba de hipótesis\index{Prueba de hipótesis} trata de verificar si una cierta afirmación acerca del parámetro puede considerarse como válida basándose en una muestra observada. Por consiguiente, una prueba de hipótesis es muy útil en situaciones donde no es de mucho interés el valor (estimado) del parámetro, sino la validez de la afirmación en cuestión. A continuación se presenta un ejemplo donde resulta útil el uso de pruebas de hipótesis.

Para el propósito de importación de ciertas motocicletas, la entidad ambiental del país importador necesita verificar que el nivel de contaminantes producidos por estas motocicletas cumple con las normas del país. En particular la emisión de monóxido de carbono (CO), denotada por $\mu$, no debe superar a $5.5g/Km$. En este caso sólo se necesita verificar si la afirmación $\mu\leq5.5g/Km$ puede considerarse como válida, mientras que la estimación puntual de $\mu$ no es de gran interés, como se verá más adelante.

\section{Conceptos preliminares}

Dada una muestra aleatoria $X_1$, $\ldots$, $X_n$ provenientes de una distribución con función de densidad $f(x,\theta)$, donde el espacio paramétrico del parámetro $\theta$ se denota por $\bTheta$. Un sistema de hipótesis\index{Hipótesis!nula} está\index{Hipótesis!alterna} conformado por dos afirmaciones acerca de $\theta$ de la siguiente forma
\begin{equation}\label{general}
H_0:\ \theta\in\bTheta_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta\in\bTheta_1
\end{equation}

donde $\bTheta_0,\bTheta_1$ son subconjuntos de $\bTheta$\index{Espacio paramétrico} y se denominan espacio paramétrico nulo\index{Espacio paramétrico!nulo} y espacio paramétrico alterno\index{Espacio paramétrico!alterno}, respectivamente. La única condición que se debe cumplir es $\bTheta_0\cap\bTheta_1=\emptyset$. $H_0$ se denomina la hipótesis nula, y $H_1$ la hipótesis alterna. El procedimiento del prueba de hipótesis consiste en decidir cuál de las dos hipótesis puede ser aceptada como válida, basado en una muestra aleatoria observada. Para eso, se necesita, en primer lugar, encontrar una estadística de prueba\index{Estadística de prueba}; y posteriormente se debe establecer una regla de decisión\index{Regla de decisión} que nos indica para qué valores de la estadística de prueba se debe rechazar $H_0$ y aceptar $H_1$.

La búsqueda de una regla de decisión para un sistema de hipótesis se lleva a cabo teniendo en cuenta que en el procedimiento de la prueba de hipótesis, se puede cometer dos tipos de errores:
\begin{itemize}
    \item Rechazar $H_0$ cuando ésta es verdadera. Este error se denomina error tipo I\index{Error!tipo I}.
    \item No rechazar $H_0$ cuando ésta es falsa. Este error se denomina error tipo II\index{Error!tipo II}.
\end{itemize}

Es claro que ambos errores conducen a decisiones erróneas y éstas pueden causar pérdidas económicas y demás daños y perjuicios; por consiguiente, una buena regla de decisión debe garantizar que la probabilidad de cometer tanto el error tipo I como el error tipo II sea pequeña. Sin embargo, no es fácil, por no decir imposible, minimizar las dos probabilidades simultáneamente. Una solución a este problema es plantear el sistema (\ref{general}) de tal forma que el error tipo I sea menos grave que el error tipo II, y garantizar únicamente que la probabilidad de cometer error tipo I sea pequeña. Una falla evidente de este procedimiento es que no se controla la magnitud del error tipo II, y la probabilidad de cometer este error puede ser realmente grande en algunos casos. Lo anterior ha sido siempre una de las críticas que existen en la literatura hacia el procedimiento de pruebas de hipótesis. Para implementar el anterior procedimiento, se necesita determinar, para cada sistema de hipótesis, cuál de los dos errores es más grave. En muchas situaciones prácticas se necesita la ayuda de expertos en el tema. Considere el ejemplo de motocicletas enunciado al comienzo de este capítulo.

\begin{Eje}
Suponga que la emisión de CO de cierto tipo de motocicletas \emph{Scooter} no debe superar a 5.5g/Km. La entidad ambiental responsable selecciona un número determinado de estas motocicletas para efectuar pruebas correspondientes. Si se denota la emisión de CO de estas motocicletas por $\mu$, entonces existen dos hipótesis acerca de $\mu$: $\mu\leq5.5$ y $\mu>5.5$. Basada en los resultados de la muestra, la entidad debe decidir cuál de las dos hipótesis aceptar. Si el sistema de hipótesis planteado es
\begin{equation}\label{sis_ejem}
H_0:\ \mu\leq5.5\ \ \ \ vs.\ \ \ \ H_1:\ \mu>5.5
\end{equation}

entonces tenemos que
\begin{itemize}
    \item El error tipo I implica rechazar $\mu\leq5.5$ cuando realmente $\mu\leq5.5$, esto es, motocicletas que están emitiendo una cantidad permitida de CO no pasan la prueba. Y esto puede causar una pérdida económica para la empresa que fabrica y la empresa que importa estas motocicletas. Y esto puede causar despido de empleados, y en el peor de los casos, la quiebra de las dos empresas.
    \item El error tipo II implica aceptar $\mu\leq5.5$ cuando en la realidad $\mu>5.5$, esto implica que motocicletas que emiten una gran cantidad de CO pasan la prueba y pueden ser importadas. Y esto causará inevitablemente la contaminación excesiva del medio ambiente.
\end{itemize}
Si el experto del tema considera más grave la pérdida económica de las empresas que la contaminación del medio ambiente, se puede mantener el sistema (\ref{sis_ejem}) planteado anteriormente; mientras que si la prioridad es conservar el medio ambiente, el sistema que se plantea debe ser
\begin{equation*}
H_0:\ \mu>5.5\ \ \ \ vs.\ \ \ \ H_1:\ \mu\leq5.5,
\end{equation*}

el cual, como se verá más adelante, tiene la misma regla de decisión que el sistema
\begin{equation*}
H_0:\ \mu\geq5.5\ \ \ \ vs.\ \ \ \ H_1:\ \mu<5.5
\end{equation*}

En este ejemplo, considerando el contexto del problema, el espacio paramétrico de $\mu$ es $\mathbf{\Theta}=(0,\infty)$, y en el sistema (\ref{sis_ejem}), $\bTheta_0=(0,5.5]$ y $\bTheta_1=(5.5,\infty)$.
\end{Eje}

En el ejemplo anterior, la unión de los conjuntos $\bTheta_0$ y $\bTheta_1$ conforma espacio paramétrico completo $\bTheta$, todos los sistemas de hipótesis tienen que cumplir con esta condición. Suponga que la empresa que fabrica las motocicletas del ejemplo anterior diseña un dispositivo para disminuir la emisión del gas CO. Si las motocicletas sin el dispositivo emiten $3.7g/Km$, entonces para probar la eficiencia del dispositivo, el sistema de hipótesis que se plantea será
\begin{equation*}
H_0:\ \mu=3.7\ \ \ \ vs.\ \ \ \ H_1:\ \mu<3.7.
\end{equation*}

Y en este caso, $\bTheta_0=\{3.7\}$, $\bTheta_1=(0,3.7)$ y la unión de estos conjuntos no conforman el espacio paramétrico completo.

Para el desarrollo de la teoría básica concerniente al tema de pruebas de hipótesis primero se estudian muestras provenientes de la distribución normal y posteriormente se consideran muestras provenientes de distribuciones diferentes a la normal.

\section{Una muestra bajo normalidad}
Como supuesto general para esta parte del libro, suponga que se dispone de una muestra aleatoria $X_1$, $\cdots$, $X_n$ provenientes de una distribución $N(\mu,\sigma^2)$. Estudiaremos por separado los sistemas de hipótesis para $\mu$ y $\sigma^2$.

\subsection{Pruebas de hipótesis para la media teórica}
En esta sección, estudiamos las pruebas de hipótesis acerca de la media teórica $\mu$ en una distribución $N(\mu,\sigma^2)$, es decir, basado en una muestra aleatoria $X_1$, $\cdots$, $X_n$ con distribución teórica $N(\mu,\sigma^2)$, estamos interesados en encontrar una regla de decisión para el sistema
\begin{equation*}
H_0:\ \mu\in\bTheta_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\in\bTheta_1
\end{equation*}
El procedimiento para encontrar una regla de decisión depende de si el valor de la varianza teórica es conocido o no\footnote{Análogo a los intervalos de confianza para $\mu$ que también depende de si $\sigma^2$ es conocida o no.}; también plantearemos diferentes sistemas de hipótesis según $\bTheta_0$ y $\bTheta_1$ toma diferentes formas.

\subsubsection{$H_0:\ \mu=\mu_0$ vs. $H_1:\ \mu\neq\mu_0$ con $\sigma^2$ conocida\index{Prueba de hipótesis!normal!media teórica}}
Este sistema de hipótesis es apto para cuando hay un valor supuesto para la media teórica y se quiere verificar la validez de este supuesto. Por ejemplo, muchas especificaciones técnicas que encontramos en los empaques de productos como eléctricos, farmaceúticos, de ferretería, entre otros, son valores que se suponen válidos para estos productos, en el caso de que haya sospecha de que el valor propuesto $\mu_0$ ya no es válido para la población, y tampoco hay sospecha de que el valor verdadero de la media teórica esté mayor o menor que $\mu_0$. Podemos utilizar la hipótesis
\begin{equation}\label{igual_desigual}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq\mu_0
\end{equation}


Necesitamos encontrar una regla de decisión en términos de alguna estadística de prueba que nos permita juzgar el sistema para cada posible muestra observada. Hay diferentes formas de encontrar una regla de decisión, ilustramos el razonamiento de uno de estos métodos con una situación práctica.

Suponga que la longitud de los clavos producidos en cierta fábrica debe ser de 5cm,  para verificar que los productos terminados en una línea de producción satisfacen con este requisito, se seleccionan aleatoriamente 50 clavos, se mide la longitud de cada uno de estos y se obtiene la longitud promedio de estos 50 clavos. Es claro que el promedio muestral de estos 50 clavos es una estimación de la media teórica; de esta forma, si este promedio muestral  es de 7cm, claramente se concluye que la línea de producción no cumple con el requisito, ya que intuitivamente 7cm está muy lejos del valor especificado de 5cm. Se tiene la misma conclusión si este promedio es de 3cm, por ejemplo. En otras palabras, la simple lógica sugiere que se debe rechazar la hipótesis de que la longitud promedio de los clavos producidos por la línea de producción es de 5cm si el promedio muestral está muy alejado de 5cm.

Escribiendo formalmente la idea anterior, se rechaza $H_0$ en (\ref{igual_desigual}) cuando el valor de $\bar{x}$ está muy alejado de $\mu_0$, y podemos describirlo como
\begin{center}
Rechazar $H_0$ cuando $|\bar{x}-\mu_0|>K$ para algún $K>0$.
\end{center}
El uso del valor absoluto se debe a que matemáticamente la distancia entre dos valores $a$ y $b$ se mide con $|a-b|$. La anterior afirmación es la regla de decisión para el sistema (\ref{igual_desigual}) y necesitamos encontrar el valor de $K$ para completarla. Para eso, podemos hacer uso de la definición del error tipo I, pero en primer lugar, se debe determinar cuál es la máxima magnitud permitida de la probabilidad de cometer este tipo de errores. Este límite superior se denotará por $\alpha$ y se conoce como el tamaño de la prueba o el nivel de significación\index{Prueba de hipótesis!Tamaño}\index{Nivel de significación}. Teóricamente, el valor de $\alpha$ puede ser cualquier valor entre 0 y 1, pero como ésta sirve para restringuir la probabilidad de cometer error tipo I, se escogen valores pequeños para $\alpha$. Usualmente en la práctica se usan valores como 0.01, 0.02, 0.05, 0.10. De esta forma, tenemos que
\begin{align*}
\alpha&\geq Pr(\text{Rechazar} H_0\ |\ \text{$H_0$ es verdadera})
\end{align*}

Ahora, una regla de decisión se define en términos de una estadística, entonces para calcular la anterior probabilidad, se necesita conocer la distribución de la estadística suponiendo cierta $H_0$. Esta distribución se conoce como la distribución nula, y depende de $H_0$. Dependiente de la forma de $H_0$, tenemos los dos siguientes casos
\begin{itemize}
    \item Cuando $H_0$ es de la forma $\theta=\theta_0$ para algún valor específico $\theta_0$, la hipótesis se conoce como \textbf{hipótesis simple}\index{Hipótesis!simple}, el espacio paramétrico nulo toma la forma $\bTheta_0=\{\theta_0\}$. En este caso, la distribución nula de la estadística de prueba está determinada de manera única, y tomamos
        \begin{equation*}
        \alpha=Pr(\text{Rechazar} H_0\ |\ \text{$H_0$ es verdadera}).
        \end{equation*}
    \item Cuando $H_0$ es tal que el espacio paramétrico nulo contiene más de un valor para el parámetro se denomina \textbf{hipótesis compuesta}\index{Hipótesis!compuesta}, y la distribución nula de la estadística de prueba consiste en una familia de distribuciones, y por consiguiente $Pr(\text{Rechazar} H_0\ |\ \text{$H_0$ es verdadera})$ puede tomar más de un valor. En este caso, tomamos
        \begin{equation*}
        \alpha=\sup_{\theta\in\bTheta_0}Pr(\text{Rechazar} H_0\ |\ \text{$H_0$ es verdadera}).
        \end{equation*}
\end{itemize}

En el sistema de hipótesis (\ref{igual_desigual}), $H_0$ es una hipótesis simple; por consiguiente, tenemos que
\begin{align*}
\alpha&=Pr(\text{Rechazar} H_0\ |\ \text{$H_0$ es verdadera})\\
&=Pr(|\bar{X}-\mu_0|>K\ |\ \text{$H_0$ es verdadera})\\
&=Pr(\bar{X}-\mu_0>K\ |\ \text{$H_0$ es verdadera})+Pr(\bar{X}-\mu_0<-K\ |\ \text{$H_0$ es verdadera})
\end{align*}

Nótese que cuando $H_0$ es verdadera, tenemos que $\mu=\mu_0$, entonces la distribución nula de $\bar{X}$ es $N(\mu_0,\sigma^2/n)$. Usando esta distribución nula de $\bar{X}$, tenemos que
\begin{align*}
\alpha&=Pr\left(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}>\frac{K}{\sigma/\sqrt{n}}\right)+Pr\left(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}<-\frac{K}{\sigma/\sqrt{n}}\right)\\
&=1-\Phi\left(\frac{K}{\sigma/\sqrt{n}}\right)+\Phi\left(-\frac{K}{\sigma/\sqrt{n}}\right)\\
&=2\Phi\left(-\frac{K}{\sigma/\sqrt{n}}\right)
\end{align*}

de donde se concluye que $-\frac{K}{\sigma/\sqrt{n}}=z_{\alpha/2}$, de donde $K=-z_{\alpha/2}\frac{\sigma}{\sqrt{n}}=z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$. Con el valor de $K$ encontrado, tenemos la siguiente regla de decisión\index{Regla de decisión!normal!media teórica} para el sistema (\ref{igual_desigual}):
\begin{center}
Rechazar $H_0$ cuando $|\bar{X}-\mu_0|>z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$.
\end{center}
Se puede ver fácilmente que la anterior regla de decisión es equivalente a
\begin{center}
Rechazar $H_0$ cuando $|\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}|>z_{1-\alpha/2}$.
\end{center}
O equivalente a
\begin{center}
Rechazar $H_0$ cuando $\bar{X}>\mu_0+z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$ ó $\bar{X}<\mu_0-z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$.
\end{center}
En conclusión, para el anterior sistema de hipótesis, existen tres reglas de decisión equivalentes\index{Estadística  de prueba!normal!media teórica}:
\begin{enumerate}[(a)]
\item $|\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}|>z_{1-\alpha/2}$ donde la estadística de prueba es $\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$
\item $|\bar{X}-\mu_0|>z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$ donde la estadística de prueba es $\bar{X}-\mu_0$
\item $\bar{X}>\mu_0+z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$ ó $\bar{X}<\mu_0-z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$ donde la estadística de prueba es $\bar{X}$.
\end{enumerate}

Las anteriores reglas de decisión se basan en una estadística de prueba, en la práctica cuando se observa un conjunto de datos $x_1$, $\cdots$, $x_n$, se calcula el valor de la estadística y se verifica si se cumple cualquiera de las anteriores reglas de decisión. Presentamos una ilustración en el siguiente ejemplo.

\begin{Eje}
Retomando el ejercicio 6 del capítulo 2. Una máquina de llenado de botellas debe estar programada para efectuar un llenado de 350ml, y se quiere conocer el funcionamiento real de la máquina. Para eso se extrajeron aleatoriamente 20 botellas llenadas por la máquina y se midió el contenido de la botella, los resultados fueron: 355, 350, 340, 345, 354, 358, 350, 343, 349, 346, 351, 358, 342, 350, 356, 345, 349, 356, 354, 346. Una simple gráfica QQ nos ilustra que se puede suponer que los datos provienen de una distribución normal. Suponga adicionalmente que la desviación estándar es igual a 5ml, si se desea evaluar la calidad de la máquina de llenado, el sistema de hipótesis es
\begin{equation*}
H_0:\ \mu=350\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq350,
\end{equation*}

y supongamos que se probará el sistema con un nivel de significación igual a 5\%.

Como se comentó anteriormente, la regla de decisión puede ser cualquiera de las tres dadas anteriormente, puesto que las tres son equivalentes y conducen a la misma decisión. Si usamos la regla de decisión (b), se calcula $|\bar{x}-350|$ que es igual a 0.15, y por el otro lado se calcula $z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$ que es igual a 1.75, de donde se concluye que $|\bar{x}-350|$ no es mayor a $z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$, lo cual conduce a la decisión de no rechazar o aceptar $H_0$, y se puede afirmar que la máquina efectivamente realiza un llenado de 350ml.
\end{Eje}

\subsubsection*{Región de rechazo}\index{Región de rechazo}

Otro concepto importante en las pruebas de hipótesis es la región de rechazo asociada a una regla de decisión, y se define como el conjunto conformado por todos los valores de la estadística de prueba que conducen a la decisión de rechazar $H_0$. En cada una de las tres anteriores reglas de decisión (a), (b) y (c), la estadística de prueba es diferente, y para cada una de ellas, podemos obtener la correspondiente región de rechazo:
\begin{itemize}
     \item \index{Región de rechazo!normal!media teórica}Para la estadística $\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$ de la regla de decisión (a), la región de rechazo es $\{c\in\mathbb{R}:c>z_{1-\alpha/2}\ \text{ó}\ c<-z_{1-\alpha/2}\}$. Podemos ilustrar esta región de rechazo en la Figura 4.1, junto con la distribución nula de la estadística de prueba que corresponde a la distribución normal estándar.
         \begin{figure}[!htb]
\centering
\includegraphics[bb=0 0 1268 1072, scale=0.2]{RC1.jpg}
\caption[\textsl{Región de rechazo de la regla de decisión (a)}]{\textsl{Ilustración de la región de rechazo de la regla de decisión (a).}}
\end{figure}
    \item \index{Región de rechazo!normal!media teórica}Ahora para la estadística $\bar{X}$ de la regla de decisión (c), la región de rechazo es $\{c\in\mathbb{R}:c>\mu_0+z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\ \text{ó}\ c<\mu_0-z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$. Ahora nótese que la distribución bajo la hipótesis nula de $\bar{X}$ es $N(\mu_0,\sigma^2/n)$. Ilustramos la región de rechazo en la Figura 4.2 suponiendo que $\sigma=2$ y $n=20$.
\begin{figure}[!htb]
\centering
\includegraphics[bb=0 0 1320 1061, scale=0.2]{RC2.jpg}
\caption[\textsl{Región de rechazo de la regla de decisión (c)}]{\textsl{Ilustración del región de rechazo de la regla de decisión (c).}}
\end{figure}
\end{itemize}

En resumen, para un sistema de hipótesis dado, puede haber varias reglas de decisión, y asociadas a ellas, varias estadísticas de pruebas, y para cada una de las estadísticas de prueba, se tiene la respectiva región de rechazo. Por lo tanto, cuando se refiere al término región de rechazo, siempre debe especificar cuál es la estadística de prueba correspondiente.

\subsubsection*{$p$ valor}\index{$p$ valor}

Una vez dado el concepto de región de rechazo, ahora estudiamos un concepto de fundamental importancia en las pruebas de hipótesis: el denominado $p$ valor. Para introducir el concepto, considérese de nuevo el sistema de hipótesis
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq\mu_0,
\end{equation*}

basándose en una muestra con distribución normal, supongamos que se usa la regla de decisión (a) dada anteriormente, de manera que cuando se observa la realización de una muestra $x_1$, $\cdots$, $x_n$, se calcula el valor de la estadística de prueba, en este caso, $\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$. Si el valor de la estadística está dentro de la región de rechazo $\{c\in\mathbb{R}:c>z_{1-\alpha/2}\ \text{ó}\ c<-z_{1-\alpha/2}\}$, entonces se rechaza $H_0$, de lo contrario se acepta $H_0$.

Retomando el Ejemplo 4.2.1, el valor de la estadística $\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$ en la muestra observada es de -0.1341. Si el nivel de significación es de 5\%, entonces $z_{1-\alpha/2}=1.96$, y claramente el valor  -0.1341 no se encuentra dentro de la región de rechazo. Nótese que la decisión tomada es la misma que en el Ejemplo 4.2.1; sin embargo, tanto el razonamiento del Ejemplo 4.2.1 como el uso de la región de rechazo tiene una desventaja que radica en que si el usuario decide usar otro nivel de significación, el procedimiento debe realizarse de nuevo y eso no es eficiente computacionalmente. Es por esta razón que los programas o software estadísticos siempre calculan el $p$ valor que nos permite realizar la prueba de hipótesis para diferentes niveles de significación.

\newpage

\begin{figure}[!htb]
\centering
\includegraphics[bb=0 0 1280 1081, scale=0.2]{RC3.jpg}
\caption[\textsl{Región de rechazo y $p$ valor de la regla de decisión (a)}]{\textsl{Ilustración del región de rechazo y $p$ valor de la regla de decisión (a).}}
\end{figure}

El concepto del $p$ valor está íntimamente ligado con el de región de rechazo. Observe la Figura 4.3, donde se muestra la región de rechazo si se utiliza la regla de decisión (a). Dada la forma de la distribución nula de la estadística de prueba y la región de rechazo, los valores que puede tomar la estadística de prueba se pueden dividir en cuatro grupos: (1) entre 0 y $z_{1-\alpha/2}$, (2) mayor que $z_{1-\alpha/2}$, (3) entre 0 y $-z_{1-\alpha/2}$ y finalmente, (4) menor que $-z_{1-\alpha/2}$. De esta forma, si en una muestra observada el valor de la estadística de prueba, digamos $v_1$, es como el caso (1) mostrado en la gráfica, es claro que no se rechaza $H_0$. Nótese que en este caso, el área hacia la derecha de $v_1$ es mayor que el área de RC2, el cual es $\alpha/2$. Ahora si el valor de la estadística $v_2$ es como el caso (2), entonces pertenece a la región de rechazo, que es equivalente al hecho de que el área hacia la derecha de $v_2$ es menor que $\alpha/2$. Lo anterior sugiere establecer una nueva regla de decisión:

\emph{Rechazar $H_0$ si el área a la derecha del valor de la estadística es menor a $\alpha/2$}

que es equivalente a

\emph{Rechazar $H_0$ si el área a la derecha del valor de la estadística multiplicado por 2 es menor a $\alpha$.}

Ahora, la anterior regla de decisión es correcta si el valor de la estadística es mayor que 0; en el caso contrario, el análisis es diferente. Suponga que el valor de la estadística es igual a $v_3$, es claro que el área hacia la derecha de $v_3$ es mayor a $\alpha/2$; de hecho, es mayor a 0.5. Sin embargo, éste pertenece a la región de rechazo. El análisis correcto, cuando el valor de la estadística es menor que 0, es observar el área hacia la izquierda. Entonces para el valor $v_3$, el área hacia la izquierda es menor a $\alpha/2$ y se rechaza $H_0$; para el valor $v_4$, el área hacia la izquierda es mayor a $\alpha/2$, y no se rechaza $H_0$.

\index{$p$ valor!normal!media teórica}En conclusión, denotando el valor de la estadística de prueba $\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$ como $v$, podemos establecer la siguiente regla de decisión:

Rechazar $H_0$ si
\begin{equation*}
\left\{
  \begin{array}{ll}
    \hbox{el área a la derecha de $v$ multiplicada por 2 es menor a $\alpha$}, & \hbox{para\ $v>0$ ;} \\
    \hbox{el área a la izquierda de $v$ multiplicada por 2 es menor a $\alpha$}, & \hbox{para \ $v<0$.}
  \end{array}
\right.
\end{equation*}

Ahora, recordando que un área bajo la curva de una función de densidad se puede interpretar como una probabilidad, la anterior regla de decisión se convierte en:

\begin{equation*}
\text{Rechazar}\ H_0\ \text{si}
\left\{
  \begin{array}{ll}
    \hbox{$2Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}>v\right)<\alpha$}, & \hbox{para\ $v>0$ ;} \\
    \hbox{$2Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}<v\right)<\alpha$}, & \hbox{para \ $v<0$.}
  \end{array}
\right.
\end{equation*}

Y el $p$ valor asociado al valor de la estadística $v$ se define como
\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}>v\right)$}, & \hbox{para\ $v>0$ ;} \\
    \hbox{$2Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}<v\right)$}, & \hbox{para \ $v<0$.}
  \end{array}
\right.
\end{equation*}

O equivalentemente
\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr(Z>v)$}, & \hbox{para\ $v>0$ ;} \\
    \hbox{$2Pr(Z<v)$}, & \hbox{para \ $v<0$.}
  \end{array}
\right.
\end{equation*}

donde $Z$ denota una variable aleatoria con distribución normal estándar. Dada la anterior definición del $p$ valor podemos reescribir la regla de decisión en término del $p$ valor:
\begin{center}
Rechazar $H_0$ si el $p$ valor es menor al nivel de significación $\alpha$.
\end{center}

\index{$p$ valor!normal!media teórica}Ilustremos el cálculo y el uso del $p$ valor con el problema descrito en el Ejemplo 4.2.1. usando la regla de decisión (a). El valor de la estadística $\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$ es -0.1341, el cual es menor que 0, por lo tanto, el $p$ valor se define como
 \begin{equation*}
 2Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}< -0.1341\right)=0.8933.
\end{equation*}

Entonces si el nivel de significación es de 5\%, no se rechaza $H_0$, pues el $p$ valor es mayor a 5\%. Ahora, si se cambia el nivel de significación a 10\%, no es necesario volver a realizar cálculos numéricos para tomar la decisión, pues simplemente comparamos el $p$ valor con el 10\%, y la decisión sigue siendo ''No rechazar $H_0$''. Por esta razón, en la práctica, el uso de $p$ valor puede ser más sencillo que los otros procedimientos, y los software estadísticos, en la mayoría de los casos, simplemente arrojan el valor de la estadística de prueba y el $p$ valor, y los usuarios pueden comparar el $p$ valor con el nivel de significación deseado.

Es difícil dar una definición formal de $p$ valor, puesto que su cálculo depende en primer lugar del planteamiento del sistema de hipótesis, y en segundo lugar depende de la estadística de prueba que se utiliza. Una definición muy popular de $p$ valor, pero errónea, afirma que el $p$ valor es la probabilidad de que $H_0$ es verdadera. De esta manera, si el $p$ valor es menor que el nivel de significación $\alpha$, implica que la probabilidad de que $H_0$ sea verdadera es pequeña, conduciendo a la decisión de rechazar $H_0$. A pesar de que el anterior razonamiento funciona, no es correcto, puesto que para $H_0$, solo hay dos posibilidades, o es verdadera o es falsa, así que la probabilidad de que $H_0$ sea verdadera es o bien 0 o bien 1, mientras que $p$ valor puede tomar cualquier valor entre 0 y 1.

\subsubsection*{Función de potencia}

Para un sistema de hipótesis, puede haber más de una regla de decisión. En este caso, necesitamos comparar estas reglas de decisión en términos de la probabilidad de cometer los dos tipos de errores, para lo cual, definimos la función de potencia.

\begin{Defi}
La función de potencia\index{Función de potencia} de una regla de decisión para un sistema de hipótesis es una función del parámetro $\theta$ definida como
\begin{equation}
\beta(\theta)=Pr(\text{Rechazar}\ H_0)
\end{equation}
\end{Defi}

Nótese que $1-\beta(\theta)=Pr(\text{Aceptar}\ H_0)$, y podemos asociar la función de potencia con los dos errores que se pueden cometer en una prueba de hipótesis de la siguiente forma
\begin{itemize}
    \item Si la hipótesis $H_0$ es verdadera, esto es, si $\theta\in\bTheta_0$, entonces al rechazar $H_0$, se está cometiendo el error tipo I, y la máxima probabilidad de cometer el error tipo I es el nivel de significación $\alpha$. De esta forma $\beta(\theta)\leq\alpha$
    \item Si la hipótesis $H_0$ es falsa, esto es, si $\theta\in\bTheta_0^c$ (no necesariamente $\theta\in\bTheta_1$), entonces aceptar $H_0$ equivale a cometer el error tipo II. Y si denotamos la probabilidad de cometer error tipo II como $\beta$, tenemos que $1-\beta(\theta)=\beta$.
\end{itemize}

Y en conclusión, la función de potencia queda expresada como
\begin{equation}\label{funcion_potencia}
\beta(\theta)=\begin{cases}
\text{Probabilidad de cometer error tipo I}\leq\alpha&\text{si $\theta\in\bTheta_0$}\\
1-\beta&\text{si $\theta\in\bTheta_0^c$}
\end{cases}
\end{equation}

y podemos ver claramente que la función de potencia es una función del parámetro $\theta$. Ahora miremos cómo se calcula la función de potencia para la regla de decisión encontrada anteriormente para el sistema de hipótesis
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq\mu_0,
\end{equation*}

Tenemos que\index{Función de potencia!normal!media teórica}
\begin{align}\label{Potencia_norm1}
\beta(\mu)&=Pr(\text{Rechazar}\ H_0)\notag\\
&=Pr\left(\bar{X}>\mu_0+z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\ \text{ó}\ \bar{X}<\mu_0-z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\right)\notag\\
&=Pr\left(\bar{X}>\mu_0+z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\right)+Pr\left(\bar{X}<\mu_0-z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\right)\notag\\
&=Pr\left(\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}>\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha/2}\right)+Pr\left(\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}<\frac{\mu_0-\mu}{\sigma/\sqrt{n}}-z_{1-\alpha/2}\right)\notag\\
&=1-\Phi\left(\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha/2}\right)+\Phi\left(\frac{\mu_0-\mu}{\sigma/\sqrt{n}}-z_{1-\alpha/2}\right)
\end{align}
donde $\Phi$ denota la función de distribución de una variable normal estándar. Podemos observar las siguientes propiedades de la función $\beta(\mu)$:
\begin{itemize}
    \item Para $\mu\in\bTheta_0$, esto es, cuando $\mu=\mu_0$, $\beta(\mu)=1-\Phi(z_{1-\alpha/2})+\Phi(-z_{1-\alpha/2})=\alpha$, y coincide con el primer caso de (\ref{funcion_potencia}).
    \item Para $\mu\in\bTheta_1$, esto es, cuando $\mu\neq\mu_0$, entre más alejado esté $\mu$ de $\mu_0$, el término $\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha/2}$ se aproxima a $\frac{\mu_0-\mu}{\sigma/\sqrt{n}}-z_{1-\alpha/2}$ y en consecuencia $\beta(\mu)$ se acerca al valor 1. Dado (\ref{funcion_potencia}), esto indica que cuando $\mu$ es muy diferente de $\mu_0$, la probabilidad de cometer error tipo II es muy pequeña, es decir, la regla de decisión será capaz de reconocer hipótesis nulas falsas.

        También, cuando el tamaño de muestra $n$ es grande, $\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha/2}$ y $\frac{\mu_0-\mu}{\sigma/\sqrt{n}}-z_{1-\alpha/2}$ se hace grande, y ambos $\Phi\left(\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha/2}\right)$ y $\Phi\left(\frac{\mu_0-\mu}{\sigma/\sqrt{n}}-z_{1-\alpha/2}\right)$ se acercan a 1 y la función $\beta(\mu)$ también se acerca a 1, esto es, entre mayor sea la muestra, una hipótesis nula falsa es más fácil de detectar.
    \item Es claro que la función de potencia depende del nivel de significación $\alpha$ que se interpreta como la probabilidad de cometer error tipo I, y se determina de antemano. Al principio se comentó que no se pueden minimizar simultáneamente las probabilidades de cometer error tipo I y error tipo II, entonces se espera que la función de potencia tome valores pequeños cuando $\alpha$ es pequeño y al observar la forma de (\ref{Potencia_norm1}), confirmamos lo dicho anteriormente.
\end{itemize}

Los anteriores comentarios se pueden ilustrar graficando la función de potencia para diferentes tamaños de muestra. Utilizamos el siguiente código, y la gráfica resultante se muestra en la Figura 4.4.

\begin{verbatim}
> po_norm<-function(mu,n,mu0,alpha,sigma){
+ 1-pnorm((mu0-mu)*sqrt(n)/sigma+qnorm(1-alpha/2))+
+ pnorm((mu0-mu)*sqrt(n)/sigma-qnorm(1-alpha/2))
+ }
> alpha<-0.05
> sigma<-1
> mu0<-2
> n1<-10
> n2<-30
> n3<-50
>
> plot(function(x) po_norm(x,n1,mu0,alpha,sigma),0,4,type="l",
+ xlab="mu",ylab="función de potencia")
> curve(po_norm(x,n2,mu0,alpha,sigma),0,4,lty=2,add=T)
> curve(po_norm(x,n3,mu0,alpha,sigma),0,4,lty=3,add=T)
> legend(3,0.4,c("n=10","n=30","n=50"),lty=c(1,2,3))
> windows()
>
> alpha1<-0.03
> alpha2<-0.05
> alpha3<-0.1
> sigma<-1
> mu0<-2
> n<-20
>
> plot(function(x) po_norm(x,n,mu0,alpha1,sigma),0,4,type="l",
+ xlab="mu",ylab="función de potencia")
> curve(po_norm(x,n,mu0,alpha2,sigma),0,4,lty=2,add=T)
> curve(po_norm(x,n,mu0,alpha3,sigma),0,4,lty=3,add=T)
> legend(2.6,0.3,c("alpha=0.03","alpha=0.05","alpha=0.1"),lty=c(1,2,3))

\end{verbatim}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{Potencia_norm.eps}
\caption[\textsl{Función de potencia (\ref{Potencia_norm1})}]{\textsl{Función de potencia (\ref{Potencia_norm1}) para diferentes tamaños de muestra con $\mu_0=2$, $\sigma=1$ y $\alpha=0.05$}}
\end{figure}

Por otro lado, también podemos graficar la función de potencia para diferentes niveles de significación, para corroborar que entre mayor sea $\alpha$, mayor es la potencia de la prueba. Una modificación del anterior código arroja la gráfica en la Figura 4.5.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{Potencia_norm_alpha.eps}
\caption[\textsl{Función de potencia (\ref{Potencia_norm1})}]{\textsl{Función de potencia (\ref{Potencia_norm1}) para diferentes niveles de significación con $\mu_0=2$, $\sigma=1$ y $n=20$.}}
\end{figure}

\subsubsection*{Aceptar $H_0:\ \mu=\mu_0$ no significa que $\mu$ tome el valor $\mu_0$}

Los procedimientos vistos hasta el momento nos ayudan a tomar una decisión acerca de un sistema de hipótesis, y es muy común pensar que al aceptar la hipótesis nula $\mu=\mu_0$, ya tenemos la certeza de que en la media teórica $\mu$ toma el valor de $\mu_0$, lo cual no es correcto, puesto que el hecho de que no se rechaza $\mu=\mu_0$ solo indica que al asumir el valor $\mu_0$ para $\mu$, no se presenta ninguna discordancia con lo observado en la muestra, mas puede haber otros valores <<apropiados>> para $\mu$.

Además, en la toma de decisiones acerca de $H_0$, hay posibilidad de cometer error tipo II, esto es, aceptar $H_0:\ \mu=\mu_0$ aún cuando el valor verdadero de $\mu$ no sea $\mu_0$. Para ilustrarlo, se realiza un estudio de simulación donde el valor de $\mu$ es 3, pero se plantean varias hipótesis nulas $\mu=\mu_0$ con $\mu_0=2.9,\ 2.95,\ 3,\ 3.05$, etc. Para cada uno de estos valores de $\mu_0$ se simulan 1000 muestras de tamaño 30 de la distribución $N(3,1)$, y para cada una de las muestras simuladas se aplica la regla de decisión rechazar $H_0$ si $|\sqrt{n}(\bar{x}-\mu_0)|/\sigma>z_{1-\alpha/2}$, y se calcula cuántas veces se acepta $H_0$. Los resultados se presentan en la Figura 4.6, donde se observa que entre más cercano esté $\mu_0$ del $\mu$ verdadero, más fácil es aceptar $H_0:\ \mu=\mu_0$, es decir, hay mayor probabilidad de cometer error tipo II. Esto es lógico puesto que si $\mu_0$ es muy cercano a $\mu$ hay poca diferencia entre una muestra proveniente de $N(\mu_0,\sigma^2)$ y una proveniente de $N(\mu,\sigma^2)$, y por consiguiente es difícil detectar la falsedad de la afirmación $\mu=\mu_0$.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.65]{mu_igual_mu0.eps}
\caption[\textsl{Región de rechazo y $p$ valor de la regla de decisión (a)}]{\textsl{Ilustración del región de rechazo y $p$ valor de la regla de decisión (a).}}
\end{figure}

En el Ejemplo 4.2.1 sobre el problema de llenado de botella, se trató de probar si el llenado promedio es de 350 ml, basado en una muestra. Se llegó a la conclusión de que se puede asumir que $H_0:\ \mu=350ml$ es verdadera. Sin embargo, según las anotaciones anteriores, existe la posibilidad de que $\mu$ no tome el valor de 350 ml, y a pesar de esto, se llega a la conclusión de aceptar $H_0$.

Entonces al observar la decisión de aceptar $H_0$, no estamos diciendo que tenemos la seguridad de que $\mu=350\ ml$, sino que la diferencia entre $\mu$ y $350\ ml$ es muy pequeña y por consiguiente no se detecta con los datos. Ahora, en la práctica, tenemos que estar conscientes de que el valor a probar $\mu_0$ no necesariamente es el único valor que es aceptable para el experto del tema en cuestión. Por ejemplo, se supone que la máquina debe efectuar un llenado de 350ml, pero si la máquina efectúa un llenado de 348ml, también puede ser aceptable para la compañía.

Los estudiantes deben tener claro que la ciencia de estadística se trata de incertidumbres, y no hay verdades absolutas como en la ciencia de matemática; por lo tanto, al aceptar $\mu=\mu_0$, lo único que podemos concluir es que los datos no manifiestan ningún conflicto con esta afirmación. De hecho se puede ver que para los datos del Ejemplo 4.2.1, si planteamos el sistema de hipótesis como $H_0:\ \mu=349\ ml$ vs. $H_1:\ \mu\neq349\ ml$ también se llega a la decisión de aceptar $H_0$.

\subsubsection{$H_0:\ \mu\leq(=)\mu_0$ vs. $H_1:\ \mu>\mu_0$ con $\sigma^2$ conocida\index{Prueba de hipótesis!normal!media teórica}}

Ahora, consideramos un sistema de hipótesis donde $H_0$ es compuesta y la búsqueda de una regla de decisión es un poco diferente que cuando $H_0$ es simple. Supongamos ahora que la hipótesis que se desea verificar es que la media teórica no supere a cierto valor $\mu_0$, y el sistema que se considera es el siguiente
\begin{equation}\label{menor_mayor}
H_0:\ \mu\leq\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0,
\end{equation}

donde el espacio paramétrico nulo está dado por $\bTheta_0=(\infty,\mu_0]$. Para encontrar una regla de decisión, es natural pensar en rechazar $H_0$ y aceptar $H_1:\  \mu>\mu_0$ cuando en una muestra observada la estimación de $\mu$, $\bar{x}$ es muy grande comparada con $\mu_0$. Esto conduce a la siguiente regla de decisión:
\begin{equation}\label{x-mu_mayor}
\text{Rechazar}\ H_0\ \text{si}\ \bar{X}-\mu_0>K
\end{equation}

para algún $K>0$. Para encontrar el valor de $K$, se hace uso de la definición del error tipo I, y restringiendose a que la probabilidad de cometer este tipo de error sea a lo más $\alpha$. Considerando que $H_0$ es una hipótesis compleja, tenemos que
\begin{align*}
\alpha&=\sup_{\mu\in\bTheta_0}Pr(\text{Rechazar $H_0$}|\ \text{$H_0$ es verdadera})\\
&=\sup_{\mu\in\bTheta_0}Pr(\bar{X}-\mu_0>K\ |\ \text{$H_0$ es verdadera})
\end{align*}

Cuando $H_0$ es verdadera, la media teórica $\mu$ es menor o igual a $\mu_0$, por lo tanto la distribución nula de $\bar{X}$ es $N(\mu,\sigma^2/n)$, donde $\mu\leq\mu_0$, estandarizando la variable $\bar{X}$, tenemos que
\begin{align*}
\alpha&=\sup_{\mu\in\bTheta_0}Pr\left(\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}>\frac{K+\mu_0-\mu}{\sigma/\sqrt{n}}\right)\\
&=\sup_{\mu\in\bTheta_0}\left(1-\Phi\left(\frac{K+\mu_0-\mu}{\sigma/\sqrt{n}}\right)\right)
\end{align*}

Para encontrar el valor de la constante $K$, necesitamos ver cuál es el valor de $\mu$ en $\bTheta_0$ que hace máximo a $1-\Phi\left(\frac{K+\mu_0-\mu}{\sigma/\sqrt{n}}\right)$. Es claro que $1-\Phi\left(\frac{K+\mu_0-\mu}{\sigma/\sqrt{n}}\right)$ es una función creciente de $\mu$, es decir, un valor grande de $\mu$ hace grande a $1-\Phi\left(\frac{K+\mu_0-\mu}{\sigma/\sqrt{n}}\right)$, pero la hipótesis nula asegura que $\mu\leq\mu_0$, entonces podemos ver que el valor de $\mu$ que maximiza a $1-\Phi\left(\frac{K+\mu_0-\mu}{\sigma/\sqrt{n}}\right)$ bajo $H_0$ es $\mu=\mu_0$. Por consiguiente, tenemos que $\alpha=1-\Phi(\sqrt{n}K/\sigma)$, y se encuentra que $K=z_{1-\alpha}\sigma/\sqrt{n}$. Y la regla de decisión para (\ref{menor_mayor}) es
\begin{center}
Rechazar $H_0$ si $\bar{X}-\mu_0>z_{1-\alpha}\frac{\sigma}{\sqrt{n}}$.
\end{center}

En otras situaciones puede haber un valor supuesto para la media teórica $\mu_0$ pero se sospecha que éste no es adecuado, sino que la media teórica es mayor a $\mu_0$. Por ejemplo, la fábrica de clavos del Ejemplo 4.2.1 despacha un pedido de clavos de 5cm, pero recibe devolución de este pedido puesto que el cliente manifiesta que los clavos de este pedido son más largos que los de costumbre. En estos casos, el sistema de hipótesis de interés puede ser de la forma
\begin{equation}\label{igua_mayor}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0
\end{equation}

En este caso, la hipótesis alterna es la misma que el sistema (\ref{menor_mayor}), y como una regla de decisión establece cuándo se debe rechazar la hipótesis nula, o equivalentemente, cuándo aceptar la hipótesis alterna, entonces \textbf{dos sistemas que difieren en la hipótesis nula, pero concuerdan en la hipótesis alterna tienen la misma regla de decisión.} Por consiguiente, la regla de decisión para (\ref{igua_mayor}) es

\begin{center}
Rechazar $H_0$ si $\bar{X}-\mu_0>z_{1-\alpha}\frac{\sigma}{\sqrt{n}}$.
\end{center}
O equivalentemente

\begin{center}
Rechazar $H_0$ si $\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}>z_{1-\alpha}$.
\end{center}

\textbf{\emph{Región de rechazo}}

\index{Región de rechazo!normal!media teórica}Y es claro que para la anterior regla de decisión, la estadística de prueba es $\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$ y el región de rechazo asociado es $\{c\in\mathbb{R}: c>z_{1-\alpha}\}$.

\textbf{\emph{$p$ valor}}

\index{$p$ valor!normal!media teórica}Ahora consideramos la forma de calcular el $p$ valor para la anterior regla de decisión para los sistemas (\ref{menor_mayor}) y (\ref{igua_mayor}). En primer lugar, observemos la forma de la región de rechazo correspondiente ilustrada en la Figura 4.7. Suponga que el valor de la estadística $\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$ observada en una muestra es el valor $v$ (ver Figura 4.7), entonces la decisión de aceptar o rechazar $H_0$ depende del área bajo curva hacia la derecha de $v$, esto es, $Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}>v\right)$. Si esta área es mayor que el área de la región de rechazo $\alpha$, entonces $v$ no cae en la región de rechazo, y por consiguiente, se acepta $H_0$; por otro lado, si el área bajo curva hacia la derecha de $v$ es menor que $\alpha$, se rechaza $H_0$.

\begin{figure}[!htb]
\centering
\includegraphics[bb=0 0 1198 1029, scale=0.2]{RC4.jpg}
\caption[\textsl{Región de rechazo de la regla del sistema (\ref{menor_mayor}) y (\ref{igua_mayor})}]{\textsl{Ilustración del región de rechazo de la regla del sistema (\ref{menor_mayor}) y (\ref{igua_mayor}).}}
\end{figure}

De esta forma, el $p$ valor para el sistema de hipótesis (\ref{menor_mayor}) o (\ref{igua_mayor}) ligado al valor observado de la estadístca $v$ se define como
\begin{equation*}
p\ \text{valor}=Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}>v\right)
\end{equation*}

o equivalentemente
\begin{equation}\label{p_valor_menor}
p\ \text{valor}=Pr(Z>v)=1-\Phi(v)
\end{equation}

Y rechazamos la hipótesis nula si el $p$ valor es pequeño comparado con el nivel de significación.

Ilustramos una aplicación de lo anterior en el siguiente ejemplo.

\begin{Eje}
Retomamos el Ejemplo 4.1.1, donde se desea conocer el comportamiento de un tipo de motocicleta en términos de la emisión del gas CO. Si el sistema planteado es
\begin{equation}\label{ejem_Scooter}
H_0:\ \mu\leq5.5\ \ \ \ vs.\ \ \ \ H_1:\ \mu>5.5
\end{equation}

y en una muestra de 10 motocicletas, mediante el uso de QQ plot, se verificó que la distribución normal describe bien el comportamiento de los datos \footnote{Dado que el tamaño muestral es pequeño, no se utiliza el histograma para verificar la distribución teórica.}. Se observa un promedio de emisión de CO del $7.2g/Km$ y suponga que en promedio las motocicletas se difieren en $1.2g/Km$ en términos de emisión de CO.

Para observar si los datos muestrales muestran evidencia en contra de $H_0$, calculamos el valor de la estadística de prueba $\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$, la cual tiene un valor de 4.48, y es claramente mayor que el percentil $z_{1-\alpha}$ para todos los valores comunes de $\alpha$ en la práctica, y esto revela que los datos muestran una fuerte evidencia en contra de que la emisión de CO no supere a $5.5g/Km$.

Por otro lado, la decisión se puede tomar en base del $p$ valor que se calcula según (\ref{p_valor_menor}). Y tenemos que
\begin{equation*}
p\ \text{valor}=1-\Phi(4.48)=3.73e-06
\end{equation*}

De donde podemos anotar que los datos observados están en contra de la hipótesis nula, ya que $p$ valor es extremadamente pequeño.
\end{Eje}

\subsubsection*{Función de potencia}

\index{Función de potencia!normal!media teórica}Finalmente, estudiamos la función de potencia para la regla de decisión encontrada para los sistemas (\ref{menor_mayor}) y (\ref{igua_mayor}). Tenemos que
\begin{align}\label{Potencia_norm2}
\beta(\mu)&=Pr(\text{Rechazar}\ H_0)\notag\\
&=Pr(\bar{X}-\mu_0>z_{1-\alpha}\frac{\sigma}{\sqrt{n}})\notag\\
&=Pr\left(\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}>\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha}\right)\notag\\
&=1-\Phi\left(\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha}\right)
\end{align}

Se puede verificar que los comentarios para la relación entre esta función de potencia con el tamaño muestral y el nivel de significación son los mismos que los del sistema $\mu=\mu_0\ vs.\ \mu\neq\mu_0$. Esto es, la potencia de la prueba incrementa a medida que (1) incrementa el tamaño muestral (2) aumenta el nivel de significación $\alpha$. En las Figuras 4.8 y 4.9 se grafican (\ref{Potencia_norm2}) para diferentes tamaños de muestra y diferentes niveles de significación.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{Potencia_norm1.eps}
\caption[\textsl{Función de potencia (\ref{Potencia_norm2})}]{\textsl{Función de potencia (\ref{Potencia_norm2}) para diferentes tamaños de muestra con $\mu_0=2$, $\sigma=1$ y $\alpha=0.05$.}}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{Potencia_norm1_alpha.eps}
\caption[\textsl{Función de potencia (\ref{Potencia_norm2})}]{\textsl{Función de potencia (\ref{Potencia_norm2}) para diferentes niveles de significación con $\mu_0=2$, $\sigma=1$ y $n=20$.}}
\end{figure}

En la práctica se debe tener en cuenta que cuando se acepta $H_0:\ \mu\leq\mu_0$ todavía es posible que el $\mu$ verdadero sea mayor a $\mu_0$, es decir, siempre se debe tener en cuenta que estamos propensos a cometer el error tipo II, y hasta ahora, no se ha puesto un límite a la probabilidad de cometer este tipo de errores. Dadas las discusiones previas acerca de la función de potencia, tenemos que esta probabilidad se puede calcular como $\beta=1-\beta(\mu)=\Phi\left(\frac{\mu_0-\mu}{\sigma/\sqrt{n}}+z_{1-\alpha}\right)$ con $\mu>\mu_0$. La forma de estas probabilidades se muestra en la Figura 4.10 (con $\mu_0=2$), donde podemos observar que entre más cercano esté $\mu$ de $\mu_0$ mayor será la probabilidad de aceptar una hipótesis nula falsa.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{error_II_menor_mayor.eps}
\caption[\textsl{Probabilidad de error tipo II para sistemas (\ref{menor_mayor}) y (\ref{igua_mayor})}]{\textsl{Probabilidad de cometer error tipo II de la regla de decisión encontrada para sistemas (\ref{menor_mayor}) y (\ref{igua_mayor}) con $\mu_0=2$.}}
\end{figure}

\subsubsection{$H_0:\ \mu\geq(=)\mu_0$ vs. $H_1:\ \mu<\mu_0$ con $\sigma^2$ conocida\index{Prueba de hipótesis!normal!media teórica}}

Para el sistema
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu<\mu_0
\end{equation*}
o
\begin{equation*}
H_0:\ \mu\geq\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu<\mu_0
\end{equation*}

Se deja como ejercicio completar el procedimiento para obtener la siguiente regla de decisión\index{Regla de desición!normal!media teórica} de nivel de significación $\alpha$ (Ejercicio 4.2)
\begin{equation}\label{x-mu_menor}
\text{Rechazar}\ H_0\ \text{si}\ \dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}<-z_{1-\alpha}.
\end{equation}

Y asociada a la anterior regla de decisión si el valor de la estadística de prueba $\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}$ se denota por $v$, entonces el $p$ valor está dado por\index{$p$ valor!normal!media teórica}
\begin{equation}\label{p_valor_mayor}
p\ \text{valor}=Pr(Z<v)=\Phi(v)
\end{equation}

y como de costumbre se rechaza $H_0$ si el $p$ valor es menor que el nivel de significación $\alpha$.

También se deja como ejercicio el procedimiento para encontrar la función de potencia dada por \index{Función de potencia!normal!media teórica}(Ejercicio 4.2)
\begin{equation*}
\beta(\mu)=\Phi\left(\frac{\mu_0-\mu}{\sigma/\sqrt{n}}-z_{1-\alpha}\right).
\end{equation*}

\subsubsection*{Prueba de razón de verosimilitud\index{Prueba!de razón de verosimilitud}}

Otra forma de encontrar una regla de decisión para las anteriores sistemas es el método de la prueba de razón de verosimilitud que se describe a continuación.
\begin{Defi}
Sea $X_1$, $\cdots$, $X_n$ una muestra aleatoria con función de densidad $f(x_i,\theta)$, donde $\theta$ es el parámetro desconocido. Suponga que se quiere probar el siguiente sistema de hipótesis:
\begin{equation*}
H_0:\ \theta=\theta_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta=\theta_1,
\end{equation*}

se denomina la prueba de razón de verosimilitud a la prueba con regla de decisión dada por
\begin{center}
Rechazar $H_0$ si $\lambda>K$ para algún constante $K$,
\end{center}
donde $\lambda$ es la razón de verosimilitud dada por
\begin{equation}\label{lambda}
\lambda=\dfrac{L(\theta_1,x_1,\cdots,x_n)}{L(\theta_0,x_1,\cdots,x_n)}=\frac{\prod_{i=1}^nf(x_i,\theta_1)}{\prod_{i=1}^nf(x_i,\theta_0)},
\end{equation}

\end{Defi}

Para entender mejor la anterior definición, recordemos que la función de verosimilitud $L(\theta,x_1,\cdots,x_n)$ se puede interpretar como la probabilidad de observar valores $x_1$, $\cdots$, $x_n$ cuando el valor del parámetro es $\theta$. Así que si $L(\theta_1,x_1,\cdots,x_n)$ es mucho más grande que $L(\theta_0,x_1,\cdots,x_n)$, podemos concluir que el valor $\theta_1$ es más creíble que $\theta_0$ para el parámetro, puesto que los valores observados son $x_1$, $\cdots$, $x_n$ y por consiguiente, la probabilidad de observar estos valores debe ser grande. En conclusión, cuando $\lambda$ es grande, los datos muestran evidencias a favor de $\theta_1$, y se rechaza el valor de $\theta_0$.\index{Prueba!de razón de verosimilitud!regla de decisión}

Una forma equivalente pero más sencilla de la prueba de razón de verosimilitud es rechazar $H_0$ cuando $\ln\lambda>\ln K$, puesto que la función logarítmica es una función estrictamente creciente, y valores grandes de $\lambda$ conducen a valores grandes de $\ln\lambda$ y viceversa. De esta manera, una regla de decisión equivalente es
\begin{center}
Rechazar $H_0$ si $\sum_{i=1}^n(\ln f(x_i,\theta_1)-\ln f(x_i,\theta_0))>K^*$ para alguna constante $K^*$.
\end{center}

La metodología de prueba de razón de verosimilitud sirve, aparentemente, para sistemas de hipótesis donde tanto la hipótesis nula como la alterna son igualdad. Es claro que muchos sistemas de hipótesis no son de esta forma, pero generalmente se pueden escribir en forma de igualdades, como lo indica en el Tabla 4.1. Ahora, aunque un sistema de hipótesis de forma de igualdad versus desigualdad se puede escribir como un sistema conformado por dos igualdades, generalmente no es posible aplicar el método de la prueba de razón de verosimilitud, sino la prueba generalizada de razón de verosimilitud que se expondrá más adelante.
\begin{table}[!htb]\centering
\begin{tabular}{c|c}\hline
$\theta=\theta_0\ vs.\ \theta<\theta_0$&$\theta=\theta_0\ vs.\ \theta=\theta_1$ con $\theta_1<\theta_0$\\
$\theta=\theta_0\ vs.\ \theta>\theta_0$&$\theta=\theta_0\ vs.\ \theta=\theta_1$ con $\theta_1>\theta_0$\\
$\theta\leq\theta^*\ vs.\  \theta>\theta^*$&$\theta=\theta_0\ \ vs.\ \theta=\theta_1$ con $\theta_0\leq\theta^*$ y $\theta_1>\theta^*$\\
$\theta\geq\theta^*\ vs.\ \theta<\theta^*$&$\theta=\theta_0\ vs.\ \theta=\theta_1$ con $\theta_0\geq\theta^*$ y $\theta_1<\theta^*$\\
$\theta=\theta_0\ vs.\ \theta\neq\theta_0$&$\theta=\theta_0\ vs.\ \theta=\theta_1$ con $\theta_1\neq\theta_0$.\\\hline
\end{tabular}\caption{\textsl{Sistemas de hipótesis equivalentes.}}
\end{table}

Retomamos el sistema (\ref{igua_mayor}) en el siguiente ejemplo para ilustrar el uso de la prueba de razón de verosimilitud.

\begin{Eje}
\index{Prueba!de razón de verosimilitud!normal}Sea $X_1$, $\cdots$, $X_n$ una muestra aleatoria proveniente de $N(\mu,\sigma^2)$ con $\sigma^2=\sigma^2_0$ conocida, consideramos el siguiente sistema de hipótesis
\begin{equation}\label{igua_mayor_sig   }
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0.
\end{equation}

De acuerdo con la Tabla 4.1, el anterior sistema es equivalente a
\begin{equation}\label{igua_igua}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu=\mu_1
\end{equation}

con $\mu_1>\mu_0$. De esta manera, se puede establecer una regla de decisión usando la prueba de razón de verosimilitud.
Tenemos que
\begin{align*}
\sum_{i=1}^n(\ln f(x_i,\theta_1)-\ln f(x_i,\theta_0))&=\sum_{i=1}^n\left(\frac{1}{2}\frac{(x_i-\mu_0)^2}{\sigma_0^2}-\frac{1}{2}\frac{(x_i-\mu_1)^2}{\sigma_0^2}\right)\\
&=\frac{1}{2\sigma^2_0}\sum_{i=1}^n\left((x_i-\mu_0)^2-(x_i-\mu_1)^2\right)\\
&=\frac{1}{\sigma^2_0}(\mu_1-\mu_0)\sum_{i=1}^nx_i+\frac{n(\mu_0^2-\mu_1^2)}{2\sigma^2_0}.
\end{align*}
De manera que la regla de decisión de la prueba de razón de verosimilitud está dada por:
\begin{center}
Rechazar $H_0$ si $\dfrac{1}{\sigma^2_0}(\mu_1-\mu_0)\sum_{i=1}^nx_i+\dfrac{n(\mu_0^2-\mu_1^2)}{2\sigma^2_0}>K^*$ para alguna constante $K^*$.
\end{center}
La anterior regla de decisión, sin duda, tiene una forma poco amigable. Para lograr una regla de decisión equivalente pero más simple, se observa que en la anterior regla de decisión la única cantidad aleatoria que varía de muestra a muestra es la realización de la estadística $\sum_{i=1}^nx_i$, entonces se despeja para este valor, y se tiene que
\begin{center}
Rechazar $H_0$ si $\sum_{i=1}^nx_i>\dfrac{\sigma^2_0}{\mu_1-\mu_0}(K^*-\dfrac{n(\mu_0^2-\mu_1^2)}{2\sigma^2_0})=K_1$,
\end{center}
o también se puede escribir la anterior regla de decisión como:
\begin{center}
Rechazar $H_0$ si $\bar{x}>K_1/n=K$.
\end{center}
Una vez establecida la regla de decisión, el siguiente paso es encontrar el valor de la constante involucrada $K$. Para eso se procede de la manera corriente, recurriendo a la definición del error tipo I, y se despeja el valor de $K$ de la igualdad
\begin{equation*}
\alpha=Pr(\text{cometer error tipo I}),
\end{equation*}

de donde se tiene que $K=\frac{\sigma_0}{\sqrt{n}}z_{1-\alpha}+\mu_0$, y de esta manera, se completa la regla de decisión:
\begin{center}
Rechazar $H_0$ si $\bar{x}>\dfrac{\sigma_0}{\sqrt{n}}z_{1-\alpha}+\mu_0$.
\end{center}
O equivalentemente
\begin{center}
Rechazar $H_0$ si $\dfrac{\sqrt{n}(\bar{x}-\mu_0)}{\sigma_0}>z_{1-\alpha}$.
\end{center}
\end{Eje}

El lector puede darse cuenta de que la anterior regla de decisión coincide con la hallada anteriormente, pero con mucho más operaciones algebraicas, entonces ¿para qué utilizar la prueba de razón de verosimilitud?, ¿qué ventajas tiene ésta? Hay por lo menos las dos siguientes razones: en primer lugar, la prueba de razón de verosimilitud es una herramienta estándar que puede ser utilizada en muchas áreas de la estadística donde no es fácil proponer una regla de decisión; en segundo lugar, anteriormente se comentó que aunque matemáticamente se puede calcular la función de potencia asociada a una prueba, en la práctica no se puede cuantificar la potencia, entonces surge la pregunta de si puede existir otra regla de decisión que tenga mayor potencia comparada con las reglas encontradas anteriormente. El lemma de Neyman Pearson responde esta pregunta y afirma que la regla de decisión encontrada usando el método de la prueba de razón de verosimilitud es la más potente, es decir, la prueba de razón de verosimilitud es la prueba que tiene menor probabilidad de cometer error tipo II.

\begin{Res}
(Lema de Neyman-Pearson)\index{Lema de Neyman-Pearson} Sea $X_1$, $\cdots$, $X_n$ una muestra aleatoria con función de densidad $f(x_i,\theta)$, donde $\theta$ es el parámetro desconocido. Suponga que se quiere probar el siguiente sistema de hipótesis:
\begin{equation*}
H_0:\ \theta=\theta_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta=\theta_1,
\end{equation*}

entonces la prueba de razón de verosimilitud: \emph{Rechazar $H_0$ si $\lambda>K$} es la prueba más potente de tamaño $\alpha$ si $\beta(\theta_0)=\alpha$.
\end{Res}

Para verificar que la regla de decisión Rechazar $H_0$ si $\dfrac{\sqrt{n}(\bar{x}-\mu_0)}{\sigma_0}>z_{1-\alpha}$ para $(\ref{igua_mayor})$ la más potente de tamaño $\alpha$, se debe verificar que $\beta(\mu_0)=\alpha$. Ahora, la función de potencia está dada en (\ref{Potencia_norm2}), de donde $\beta(\mu_0)=1-\Phi(1-\alpha)=\alpha$.

Se debe hacer énfasis en que la anterior prueba es la más potente de tamaño $\alpha$, puesto que al aumentar el nivel de significación, la potencia también aumenta, por lo tanto pruebas con un alto nivel de significación pueden ser más potentes que la anterior prueba de razón de verosimilitud.

También hacemos aclaración de que el hecho de que una prueba sea la más potente se refiere a que la función de potencia $\beta(\theta)$ es no inferior a la función de potencia de cualquier otra prueba para todo $\theta\in\bTheta_1$, no para algún $\theta$ particular.

Ahora, como se mencionaba antes, aunque algunos sistemas de hipótesis como (\ref{igual_desigual}) que se desean probar pueden ser expresados como
\begin{equation*}
H_0:\ \theta=\theta_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta=\theta_1,
\end{equation*}

no siempre se puede encontrar una regla de decisión usando el método de la razón de verosimilitud. En estos casos, se puede aplicar el método de la razón generalizada de verosimilitud, que se describe a continuación.

\begin{Defi}
Sea $X_1$, $\cdots$, $X_n$ una muestra aleatoria con función de densidad $f(x_i,\theta)$, donde $\theta$ es el parámetro desconocido. Suponga que se quiere probar el siguiente sistema de hipótesis:
\begin{equation*}
H_0:\ \theta\in\mathbf{\Theta}_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta\in\mathbf{\Theta_1},
\end{equation*}

con $\mathbf{\Theta}_0\cup\mathbf{\Theta}_1\subseteq\mathbf{\Theta}$, el espacio paramétrico de $\theta$, y $\mathbf{\Theta}_0\cap\mathbf{\Theta}_0=\emptyset$, entonces la prueba con regla de decisión dada por\index{Prueba!de razón generalizada de verosimilitudes}
\begin{center}
Rechazar $H_0$ si $\lambda>K$ para algún constante $K$,
\end{center}
donde $\lambda$ es la razón generalizada de verosimilitud dada por
\begin{equation}\label{lambda_general}
\lambda=\dfrac{\sup_{\mathbf{\Theta}_0\cup\mathbf{\Theta}_1}L(\theta,x_1,\cdots,x_n)}{\sup_{\mathbf{\Theta}_0}L(\theta,x_1,\cdots,x_n)},
\end{equation}

donde $\sup_AL(\theta,x_1,\cdots,x_n)$ se denota el valor máximo que puede tomar la función de verosimilitud $L$ en el conjunto $A$.
\end{Defi}

La lógica de esta prueba es similar a la prueba de razón de verosimilitud, cuando $\lambda$ es muy grande, $\sup_{\mathbf{\Theta}_0\cup\mathbf{\Theta}_1}L(\theta,x_1,\cdots,x_n)$ es mayor que $\sup_{\mathbf{\Theta}_0}L(\theta,x_1,\cdots,x_n)$, implicando que el valor máximo de $L(\theta,x_1,\cdots,x_n)$ en $\mathbf{\Theta}_1$ es mayor que el valor máximo en $\mathbf{\Theta}_0$. Esto es, es mas creíble que $\theta$ toma valor en $\mathbf{\Theta}_1$ que en $\mathbf{\Theta}_0$, y por consiguiente se rechaza $H_0$.

Por otro lado, cuando $\mathbf{\Theta}_1=\mathbf{\Theta}^c$, se tiene que $\mathbf{\Theta}_0\cup\mathbf{\Theta}_1=\mathbf{\Theta}$, y dado que $\mathbf{\Theta}$ es el espacio paramétrico completo de $\theta$, entonces el numerador de $\lambda$ en (\ref{lambda_general}) se convierte simplemente en la función de verosimilitud evaluada en el estimador $MV$ de $\theta$, esto es, $L(\hat{\theta}_{MV},x_1,\cdots,x_n)$.

Anteriormente se mencionó que cuando el sistema de hipótesis que se desea probar es de la forma de igualdad frente a desigualdad, no siempre se puede aplicar la prueba de razón de verosimilitud. Veamos en el siguiente ejemplo que la prueba de razón generalizada de verosimilitud puede resultar útil.

\begin{Eje}
\index{Prueba!de razón generalizada de verosimilitudes!normal}Dada una muestra aleatoria $X_1$, $\cdots$, $X_n$ proveniente de una distribución $N(\mu,\sigma^2)$, usaremos la prueba de razón generalizada de verosimilitud para encontrar una regla de decisión para el sistema
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq\mu_0.
\end{equation*}

En primer lugar, nótese que $\mathbf{\Theta}_0$ es el conjunto cuyo único valor es $\mu_0$, esto es, $\mathbf{\Theta}_0=\{\mu_0\}$, y $\mathbf{\Theta}_1=\mathbf{\Theta}_0^c$, así que el numerador de $\lambda$ es la función de verosimilitud evaluada en $\hat{\mu}_{MV}$.

Ahora, para calcular la razón generalizada de verosimilitud $\lambda$, recordemos, en primer lugar, que la función de verosimilitud está dada por
\begin{equation*}
L(\mu,x_1,\cdots,x_n)=(2\pi\sigma^2)^{-n/2}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\right\}.
\end{equation*}

Ahora, la estimación $MV$ de $\mu$ es el promedio muestral $\bar{x}$, entonces el numerador de $\lambda$ se convierte en
\begin{equation*}
L(\hat{\mu}_{MV},x_1,\cdots,x_n)=(2\pi\sigma^2)^{-n/2}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\bar{x})^2\right\}.
\end{equation*}

Y por otro lado, $\mathbf{\Theta}_0=\{\mu_0\}$, entonces el máximo valor de $L$ en $\mathbf{\Theta}_0$ es $L$ evaluado en $\mu_0$, entonces
\begin{equation*}
L(\mu_0,x_1,\cdots,x_n)=(2\pi\sigma^2)^{-n/2}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu_0)^2\right\}.
\end{equation*}

De donde se tiene que la razón generalizada de verosimilitud está dada por
\begin{align*}
\lambda&=\dfrac{(2\pi\sigma^2)^{-n/2}\exp\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\bar{x})^2\}}{(2\pi\sigma^2)^{-n/2}\exp\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu_0)^2\}}\\
&=\exp\left\{\frac{1}{2\sigma^2}\left[\sum_{i=1}^n(x_i-\mu_0)^2-\sum_{i=1}^n(x_i-\bar{x})^2\right]\right\}.
\end{align*}
Usando la monotocidad de la función logarítmica y eliminando constantes de la desigualdad, se tiene la regla de decisión:
\begin{center}
Rechazar $H_0$ si $\sum_{i=1}^n[(x_i-\mu_0)^2-(x_i-\bar{x})^2]>K^*$
\end{center}
para alguna constante $K^*$. Ahora, es fácil ver que $\sum_{i=1}^n[(x_i-\mu_0)^2-(x_i-\bar{x})^2]=n(\bar{x}-\mu_0)^2$, entonces se rechaza $H_0$ cuando $(\bar{x}-\mu_0)^2>K_1$, la cual es equivalente a $|\bar{x}-\mu_0|>K$ encontrada al principio de este capítulo. Finalmente, se encuentra el valor para $K$ siguiendo a los pasos expuestos anteriormente.
\end{Eje}

Aunque en muchos casos, como en el ejemplo anterior, la regla de decisión encontrada al utilizar la prueba de razón (generalizada) de verosimilitud es equivalente a la encontrada simplemente analizando el sistema de hipótesis y usando el sentido común. La prueba de razón de verosimilitud ofrece una metodología estándar para una amplia gama de sistemas de hipótesis, ésta es particularmente útil cuando la distribución de donde proviene la muestra es diferente que la distribución normal y/o el sentido común no da ninguna pista sobre cómo debe ser la regla de decisión.

\subsubsection{$H_0:\ \mu=\mu_0$ vs. $H_1:\ \mu\neq\mu_0$ con $\sigma^2$ desconocida\index{Prueba de hipótesis!normal!media teórica}}

En muchos casos, por falta de información acerca de la población objetiva, la varianza teórica no es conocida; en este caso, para el sistema de hipótesis
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq\mu_0
\end{equation*}

las reglas de decisión dadas para el caso cuando $\sigma^2$ es conocida ya no serán válidas, aunque el procedimiento para obtener las reglas de decisión son las mismas. En primer lugar, dado que el sistema de hipótesis es el mismo, la regla de decisión sigue siendo: Rechazar $H_0$ cuando $|\bar{x}-\mu_0|>K$ para alguna constante positivo $K$. Al restringir la magnitud de cometer el error tipo I a ser igual al nivel de significación $\alpha$, se tiene
\begin{equation*}
\alpha=Pr(|\bar{X}-\mu_0|>K)
\end{equation*}

cuando $\mu=\mu_0$. Para encontrar el valor de $K$ en la anterior ecuación, se multiplica $\frac{\sqrt{n}}{S_{n-1}}$, de donde
\begin{align*}
\alpha=&Pr\left(\frac{\sqrt{n}|\bar{X}-\mu_0|}{S_{n-1}}>\frac{\sqrt{n}K}{S_{n-1}}\right)\\
&=Pr\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}>\frac{\sqrt{n}K}{S_{n-1}}\right)+Pr\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}<-\frac{\sqrt{n}K}{S_{n-1}}\right).
\end{align*}

Ahora bajo la hipótesis nulo $\mu=\mu_0$, se tiene que la distribución de $\frac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}$ es la distribución $t_{n-1}$, que es simétrica con respecto a 0. Por lo tanto, las dos probabilidades en la ecuación anterior son iguales, entonces se tiene
\begin{equation*}
\frac{\alpha}{2}=Pr\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}>\frac{\sqrt{n}K}{S_{n-1}}\right),
\end{equation*}

de donde $\frac{\sqrt{n}K}{S_{n-1}}=t_{n-1,1-\alpha/2}$, de esta manera se tiene que $K=t_{n-1,1-\alpha/2}\frac{S_{n-1}}{\sqrt{n}}$. De esta manera, se completa la regla de decisión, y tiene forma:\index{Regla de decisión!normal!media teórica}
\begin{center}
Rechazar $H_0$ si $|\bar{x}-\mu_0|>t_{n-1,1-\alpha/2}\frac{s_{n-1}}{\sqrt{n}}$,
\end{center}
de manera equivalente se tiene la siguiente regla de decisión:\index{Regla de decisión!normal!media teórica}
\begin{equation}\label{regla}
\text{Rechazar}\ H_0\ \text{si}\ \frac{\sqrt{n}(\bar{x}-\mu_0)}{s_{n-1}}>t_{n-1,1-\alpha/2} \text{o}\ \frac{\sqrt{n}(\bar{x}-\mu_0)}{s_{n-1}}<-t_{n-1,1-\alpha/2},
\end{equation}

donde la estadística de prueba es $\frac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}$, y la región de rechazo\index{Región de rechazo!normal!media teórica} está dada por $\{c\in\mathbb{R}: c>t_{n-1,1-\alpha/2}\ \text{ó}\ c<-t_{n-1,1-\alpha/2}\}$. Esta prueba es conocida como la prueba $t$ a dos colas, en la Figura 4.11, se muestra esta región de rechazo.

\begin{figure}[!htb]
\centering
\includegraphics[bb=0 0 1198 1004, scale=0.2]{RC1t.jpg}
\caption[\textsl{Región de rechazo de la prueba $t$ a dos colas}]{\textsl{Ilustración del región de rechazo de la prueba $t$ a dos colas.}}
\end{figure}

\subsubsection*{$p$ valor}

También podemos calcular el $p$ valor\index{$p$ valor!normal!media teórica} para esta prueba. El razonamiento es análogo al caso cuando $\sigma^2$ es conocido, lo único que es diferente en el caso cuando $\sigma^2$ es desconocido es que la estadística de prueba es $\frac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}$ cuya distribución nula es $t_{n-1}$; de esta forma, el $p$ valor para la prueba $t$ de dos colas está dado por:

\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}>v\right)$}, & \hbox{para\ $v>0$ ;} \\
    \hbox{$2Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{S_{n-1}}<v\right)$}, & \hbox{para \ $v<0$.}
  \end{array}
\right.
\end{equation*}

o equivalentemente
\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr(T_{n-1}>v)$}, & \hbox{para\ $v>0$ ;} \\
    \hbox{$2Pr(T_{n-1}<v)$}, & \hbox{para \ $v<0$.}
  \end{array}
\right.
\end{equation*}

donde $T_{n-1}$ denota una variable aleatoria con distribución $t_{n-1}$.

Volviendo al Ejemplo 4.2.1, suponga que el valor de la desviación estándar es desconocida; en este caso, el sistema de hipótesis sigue siendo
\begin{equation*}
H_0:\ \mu=350\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq350,
\end{equation*}

y la regla de decisión es
\begin{center}
Rechazar $H_0$ si $\dfrac{\sqrt{n}(\bar{x}-\mu_0)}{s_{n-1}}>t_{n-1,1-\alpha/2}$ ó $\dfrac{\sqrt{n}(\bar{x}-\mu_0)}{s_{n-1}}<-t_{n-1,1-\alpha/2}$
\end{center}
donde se supone que $\alpha=5\%$. Para la muestra observada de tamaño 20, se tiene que $\bar{x}=349.85$ y $s_{n-1}=5.4$, entonces $\frac{\sqrt{n}(\bar{x}-\mu_0)}{s_{n-1}}=-0.124$, y $t_{n-1,1-\alpha/2}=2.093$, de donde se observa que el valor de la estadística de prueba no se encuentra dentro de la región de rechazo, entonces se puede concluir que la máquina sí lleva a cabo un llenado de 350ml.

Por otro lado, calculamos el $p$ valor. El valor de la estadística de prueba -0.124 es negativo, de manera que
\begin{equation*}
p\ \text{valor}=2Pr(T_{n-1}<-0.124),
\end{equation*}

con la ayuda de una tabla estadística de la distribución $t$ o la función \verb"pt" del software R, se tiene que el $p$ valor es 0.9026, el cual es mayor a cualquier nivel de significación $\alpha$ usado en la práctica, de donde se concluye no se rechaza $H_0$.

El anterior procedimiento también se puede llevar a cabo usando el comando \verb"t.test", el uso y el resultado arrojado es como sigue
\begin{verbatim}
> x<-c(355, 350, 340, 345, 354, 358, 350, 343, 349, 346, 351, 358,
+ 342, 350, 356, 345, 349, 356, 354, 346)
> t.test(x,mu=350)

        One Sample t-test

data:  x
t = -0.1242, df = 19, p-value = 0.9025
alternative hypothesis: true mean is not equal to 350
95 percent confidence interval:
 347.3216 352.3784
sample estimates:
mean of x
   349.85
\end{verbatim}

Podemos ver que los resultados son iguales a los obtenidos manualmente. Adicionalmente, vemos que un intervalo del 95\% para la media teórica es (347.3,352.4), y el valor 350 se encuentra dentro de este intervalo, conduciéndonos a la misma conclusión de aceptar $H_0$.

\subsubsection*{Función de potencia}

Para encontrar la función de potencia\index{Función de potencia!normal!media teórica} de la anterior regla de decisión, procedemos de forma similar al caso cuando $\sigma^2$ es desconocida. Tenemos que
\begin{align*}
\beta(\mu)&=Pr(\text{Rechazar}\ H_0)\\
&=Pr\left(\frac{\bar{X}-\mu_0}{S_{n-1}/\sqrt{n}}>t_{n-1,1-\alpha/2}\right)+Pr\left(\frac{\bar{X}-\mu_0}{S_{n-1}/\sqrt{n}}<t_{n-1,1-\alpha/2}\right)
\end{align*}

Ahora, $\bar{X}\sim N(\mu,\sigma^2/n)$ de donde $\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}\sim N\left(\frac{\mu-\mu_0}{\sigma/\sqrt{n}},1\right)$, y por otro lado, $\frac{(n-1)S^2_{n-1}}{\sigma^2}\sim\chi^2_{n-1}$. Utilizando la independencia entre $\bar{X}$ y $S^2_{n-1}$, tenemos que
\begin{equation*}
\frac{\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}}{\sqrt{\frac{S^2_{n-1}}{\sigma^2}}}=\frac{\bar{X}-\mu_0}{S_{n-1}/\sqrt{n}}\sim t^{nc}_{n-1,\delta}.
\end{equation*}

con $\delta=\frac{\mu-\mu_0}{\sigma/\sqrt{n}}$. Y de allí podemos calcular la función de potencia como
\begin{equation}\label{Potencia_t}
\beta(\mu)=1-F_{t^{nc}_{n,\delta}}(t_{n-1,1-\alpha/2})+F_{t^{nc}_{n,\delta}}(t_{n-1,\alpha/2})
\end{equation}

donde $F_{t^{nc}_{n-1,\delta}}(\cdot)$ denota la función de distribución de la distribución $t^{nc}_{n-1^,\delta}$. Para reproducir gráficas similares a las de las Figuras 4.4 y 4.5, tenemos el siguiente código
\begin{verbatim}
> po_t_nocen<-function(mu,n,mu0,alpha,sigma){
+ delta<-(mu-mu0)*sqrt(n)/sigma
+ 1-pt(qt(1-alpha/2,n-1),df=n-1,ncp=delta)+pt(qt(alpha/2,n-1),
+ df=n-1,ncp=delta)
+ }
>
> alpha<-0.05
> sigma<-1
> mu0<-2
> n1<-10
> n2<-30
> n3<-50
>
>
> mu<-mu0+seq(-2,2,0.05)
>
> plot(po_t_nocen(mu,n1,mu0,alpha,sigma),type="l",xaxt="n",xlab="mu",
+ ylab="función de potencia")
> axis(1, 1:length(mu), mu)
> lines(po_t_nocen(mu,n2,mu0,alpha,sigma),lty=2)
> lines(po_t_nocen(mu,n3,mu0,alpha,sigma),lty=3)
> legend(60,0.4,c("n=10","n=30","n=50"),lty=c(1,2,3))

> windows()
> alpha1<-0.03
> alpha2<-0.05
> alpha3<-0.1
> n<-20
>
> plot(po_t_nocen(mu,n,mu0,alpha1,sigma),type="l",xaxt="n",xlab="mu",
+ ylab="función de potencia")
> axis(1, 1:length(mu), mu)
> lines(po_t_nocen(mu,n,mu0,alpha2,sigma),lty=2)
> lines(po_t_nocen(mu,n,mu0,alpha3,sigma),lty=3)
> legend(55,0.3,c("alpha=0.03","alpha=0.05","alpha=0.1"),lty=c(1,2,3))
\end{verbatim}

En las Figuras 4.12 y 4.13 se muestra la función (\ref{Potencia_t}) variando el tamaño de muestral y el nivel de significación. Podemos ver que las figuras son muy similares que las de la función de potencia (\ref{Potencia_norm1}) debido a la similitud entre la distribución $t$ y la distribución normal, y como consecuencia, concluimos que la potencia aumenta cuando se tiene una muestra grande y también cuando el nivel de significación $\alpha$ es grande.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{potencia_t1.eps}
\caption[\textsl{Función de potencia (\ref{Potencia_t})}]{\textsl{Función de potencia (\ref{Potencia_t}) con $\alpha=0.05$, $\sigma=1$ y diferentes tamaños de muestra.}}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{potencia_t_alpha.eps}
\caption[\textsl{Función de potencia (\ref{Potencia_t})}]{\textsl{Función de potencia (\ref{Potencia_t}) para diferentes niveles de significación con $\mu_0=2$, $\sigma=1$ y $n=20$.}}
\end{figure}

\subsubsection{$H_0:\ \mu\leq(=)\mu_0$ vs. $H_1:\ \mu>\mu_0$ con $\sigma^2$ desconocida\index{Prueba de hipótesis!normal!media teórica}}

Si el sistema de interés es
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0.
\end{equation*}

o
\begin{equation*}
H_0:\ \mu\leq\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0.
\end{equation*}

Se vio anteriormente que para el caso cuando $\sigma^2$ es conocido, la regla de decisión encontrada es
\begin{center}
Rechazar $H_0$ si $\bar{x}>K$.
\end{center}
y el procedimiento para encontrar esta regla de decisión no está sujeto al supuesto de que la varianza es conocida. Entonces cuando no se tiene este supuesto, se obtiene la misma regla de decisión. Y el hecho de que la varianza es desconocida conlleva a que al encontrar el valor de la constante $K$, la distribución usada será la distribución $t_{n-1}$. Y se tiene que\index{Regla de decisión!normal!media teórica}
\begin{center}
Rechazar $H_0$ si $\dfrac{\sqrt{n}(\bar{x}-\mu_0)}{s_{n-1}}>t_{n-1,1-\alpha}$.
\end{center}

\subsubsection*{$p$ valor}

\index{$p$ valor!normal!media teórica}Se puede encontrar la forma de calcular el $p$ valor cuando la estadística de prueba $\bar{X}$ toma un valor $v$, análogo al caso cuando $\sigma^2$ es conocida. Se deja como ejercicio ver que (Ejercicio 4.3)
\begin{equation*}
p\ \text{valor}=Pr\left(\dfrac{\sqrt{n}(\bar{X}-\mu)}{S_{n-1}}>v\right)=Pr(T_{n-1}>v),
\end{equation*}

y se rechaza $H_0$ cuando el $p$ valor es menor que el nivel de significación $\alpha$.

\subsubsection*{Función de potencia}

\index{Función de potencia!normal!media teórica}Es fácil ver que la función de potencia está dada por

\begin{equation*}
\beta(\mu)=1-F_{t^{nc}_{n-1,\delta}}\left(t_{n-1,1-\alpha}\right)
\end{equation*}

donde $\delta=\frac{\mu-\mu_0}{\sigma/\sqrt{n}}$.

\subsubsection{Dualidad entre $IC(\mu)$ y pruebas de hipótesis}
En el capítulo anterior, se mencionó que los intervalos de confianza para $\mu$ son útiles para tomar decisiones sobre hipótesis como $\mu=\mu_0$, $\mu\leq\mu_0$ o $\mu\geq\mu_0$. Veamos que las decisiones tomadas usando los intervalos de confianza concuerdan con las vistas en el presente capítulo.

En el caso de sistema de hipótesis
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq\mu_0,
\end{equation*}

con $\sigma^2$ desconocida, se vio que un intervalo de confianza para $\mu$ es
\begin{equation*}
(\bar{x}-t_{n-1,1-\alpha/2}s_{n-1}/\sqrt{n},\bar{x}+t_{n-1,1-\alpha/2}s_{n-1}/\sqrt{n}).
\end{equation*}

Y se rechaza $H_0$ si el intervalo no contiene a $\mu_0$, esto es, si
\begin{equation*}
\mu_0<\bar{x}-t_{n-1,1-\alpha/2}s_{n-1}/\sqrt{n}\ \ \text{o}\ \ \mu>\bar{x}+t_{n-1,1-\alpha/2}s_{n-1}/\sqrt{n}
\end{equation*}

que es equivalente a
\begin{equation*}
t_{n-1,1-\alpha/2}<\sqrt{n}(\bar{x}-\mu_0)/s_{n-1}\ \ \text{o}\ \ \sqrt{n}(\bar{x}-\mu_0)/s_{n-1}<-t_{n-1,1-\alpha/2},
\end{equation*}

la cual es la regla de decisión encontrada anteriormente, ver (\ref{regla}).

Por otro lado, si el sistema de interés es
\begin{equation*}
H_0:\ \mu\leq\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0,
\end{equation*}

entonces el intervalo útil es $(\bar{x}-z_{1-\alpha}\sigma/\sqrt{n},\infty)$, y rechaza $H_0$, si
\begin{equation*}
\bar{x}-z_{1-\alpha}\sigma/\sqrt{n}>\mu_0,
\end{equation*}

equivalente a
\begin{equation*}
\sqrt{n}(\bar{x}-\mu_0)/\sigma>z_{1-\alpha},
\end{equation*}

que es la regla de decisión encontrada anteriormente, ver (\ref{x-mu_mayor})

Aunque en los anteriores, el uso de los intervalos de confianza es equivalente a los procedimientos de prueba de hipótesis, el uso de los intervalos de confianza es muy limitado, pues no funcionan para sistemas donde $\mathbf{\Theta}_1\neq\mathbf{\Theta}_0^c$. Por consiguiente, no funcionan para sistemas como
\begin{equation*}
H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0.
\end{equation*}

Otra observación importante acerca de los prueba de hipótesis es con respecto al nivel de significación $\alpha$. En la práctica, el valor usado para $\alpha$ es generalmente 0.02, 0.05 o 0.1. Como se ha visto anteriormente, ésta es la probabilidad de cometer el error tipo I, pero en muchos informes estadísticos, se presenta a $\alpha$ como la magnitud del error, sin mencionar el error tipo II. Y esto causa la falsa impresión de que entre más pequeño sea $\alpha$, más confiable es el resultado del procedimiento. Lo que ocurre realmente al escoger un valor de $\alpha$ pequeño, como 0.02 o 0.01, es que el área de la región de rechazo también disminuye, pues ésta es igual a $\alpha$. De esta forma, es más difícil rechazar $H_0$. De hecho, existen situaciones donde al disminuir el valor de $\alpha$, la decisión puede cambiar de rechazar al no rechazar.

Considera el sistema
\begin{equation*}
H_0:\ \mu=0\ \ \ \ vs.\ \ \ \ H_1:\ \mu\neq0,
\end{equation*}

con $\sigma^2$ desconocido. Se ha visto anteriormente que la regla de decisión es: rechazar $H_0$ si $\frac{\sqrt{n}(\bar{x}-\mu_0)}{s}>t_{n-1,1-\alpha/2}\ \text{ó}\ \frac{\sqrt{n}(\bar{x}-\mu_0)}{s}<-t_{n-1,1-\alpha/2}$. Suponga que en una muestra de 20 observaciones, $\bar{x}=0.5$, y $s^2_{n-1}=1$, entonces $\sqrt{n}\bar{x}/s_{n-1}=2.24$. Ahora, si el nivel de significación $\alpha=0.05$, entonces $t_{n-1,1-\alpha/2}=2.09$, y llegamos a la conclusión de rechazar $H_0$; por otro lado, si $\alpha=0.02$, entonces $t_{n-1,1-\alpha/2}=2.54$, y llegamos a la conclusión de no rechazar $H_0$, y observamos cómo los resultados cambian al cambiar el nivel de significación.


Finalmente, volvemos a tomar el tema del planteamiento de un sistema de hipótesis. Cuando se plantea un sistema como
\begin{equation*}
H_0:\ \theta\in\boldsymbol{\Theta}_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta\in\boldsymbol{\Theta}_1.
\end{equation*}

La decisión se toma en base a una muestra observada, y la muestra debe tener suficiente evidencia en contra de $H_0$ para llegar a la decisión de rechazar $H_0$. De hecho, si revisamos los sistemas de hipótesis vistos anteriormente, podemos observar que el área del región de rechazo es de tan solo $\alpha$. En algunas situaciones, una muestra observada puede no mostrar suficiente evidencia en contra de $H_0$, ni en contra de $H_1$. En estas situaciones, el planteamiento del sistema de hipótesis es crucial en la toma correcta de decisiones.

Considera el sistema
\begin{equation*}
H_0:\ \mu\geq5\ \ \ \ vs.\ \ \ \ H_1:\ \mu<5,
\end{equation*}

con $\sigma^2$ desconocido. Suponga que el nivel de significación es $\alpha=0.05$. Se ha visto anteriormente que la regla de decisión es: rechazar $H_0$ si $\sqrt{n}(\bar{x}-5)/s_{n-1}<t_{n-1,\alpha}=-1.73$. Suponga que en una muestra de 20 observaciones, $\bar{x}=5.2$, y $s^2_{n-1}=1$, entonces $\sqrt{n}(\bar{x}-5)/s_{n-1}=0.89$, y no se rechaza $H_0$, es decir, podemos aceptar $\mu\geq5$.

Ahora cambiamos los hipótesis en el anterior sistema, y consideramos el siguiente sistema
\begin{equation*}
H_0:\ \mu\leq5\ \ \ \ vs.\ \ \ \ H_1:\ \mu>5,
\end{equation*}

se puede ver que la regla de decisión en este caso es: rechazar $H_0$ si $\sqrt{n}(\bar{x}-5)/s_{n-1}>t_{n-1,1-\alpha}=1.73$, para la misma muestra observada, $\sqrt{n}(\bar{x}-5)/s_{n-1}=0.89$, y llegamos a la conclusión de no rechazar $H_0$, es decir, aceptamos $\mu\leq5$. Obsérvese que dos personas pueden llegar a conclusiones totalmente diferentes utilizando los mismos datos, inclusive utilizando ambos los correctos procedimientos estadísticos. Situaciones como ésta forman parte de las críticas que existen hacia los procedimientos de pruebas de hipótesis. El problema radica en el planteamiento de la hipótesis, debemos recordar que en el procedimiento de buscar reglas de decisión, sólo se está teniendo en cuenta la magnitud del error tipo I, sin considerar el error tipo II; por lo tanto, el usuario de las técnicas de prueba de hipótesis debe asociarse con el experto del tema específico, y plantear el sistema donde el error tipo I es menos grave que el error tipo II.

Una observación interesante acerca de las pruebas de hipótesis es que el procedimiento de éste es similar al procedimiento matemático utilizado para hacer una demostración por contradicción, miremos por qué.
Desde nuestros primeros contactos con la estadística nos hemos dado cuenta de que ésta está muy ligada a los fundamentos matemáticos (alguien dijo que la matemática es la esclava de todas las ciencias). También sabemos que una herramienta fundamental de la estadística es, sin duda alguna, la prueba de hipótesis; mientras que para los matemáticos la demostración por contradicción es indispensable en muchos desarrollos teóricos. Bien, para la sorpresa de muchos, hay una similitud increíble entre estos métodos.

Antes que todo recordemos cómo se demuestra la veracidad de una proposición, $P$, mediante contradicción:
se supone que la proposición, $P$, es falsa, luego se observa si con este supuesto se puede llegar a alguna contradicción.
Si así sucede, podemos concluir que el supuesto anterior es falso; es decir, que la falsedad de $P$ es falsa, y por consiguiente se concluye lo que se quería demostrar: que $P$ es verdadera.

Ahora pensemos en el procedimiento de la prueba de una hipótesis $H_0$: primero se supone que $H_0$ es verdadero. Bajo este supuesto, se observa si el valor muestral de la estadística de prueba pertenece a la región de rechazo que equivale a la contradicción, lo cual sucede con una probabilidad $\alpha$ que, por lo general, es muy pequeña.
Si este evento sucede, concluimos que $H_0$ es falso.
Se puede ver la similitud entre estos dos procedimientos teniendo en cuenta que en el primer paso se asume un supuesto en ambos casos. En el segundo paso, podemos ver que una contradicción equivale, en el caso de prueba de hipótesis, a que un evento, con probabilidad de ocurrencia muy pequeña, suceda. Este evento es: el valor de la estadística pertenece a la región de rechazo. En el tercer paso, si se llega a la contradicción se concluye que el supuesto planteado en el primer paso es falso; es decir, se rechaza $H_0$.

\subsection{Pruebas de hipótesis acerca de la varianza teórica}

\subsubsection{$H_0:\ \sigma^2=\sigma^2_0$ vs. $H_1:\ \sigma^2\neq\sigma^2_0.$ con $\mu$ conocido\index{Prueba de hipótesis!normal!varianza teórica}}
Consideramos el siguiente sistema de hipótesis en una muestra aleatoria $X_1$, $\ldots$, $X_n$ proveniente de una distribución $N(\mu,\sigma^2)$ con $\mu$ conocida.
\begin{equation}\label{sigma_igual_dif}
H_0:\ \sigma^2=\sigma^2_0\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2\neq\sigma^2_0.
\end{equation}

El estimador $MV$ de $\sigma^2$ está dado por $\hat{\sigma}^2_{MV}=\frac{1}{n}\sum_{i=1}^n(X_i-\mu)^2$. Considerando la forma del sistema de hipótesis, se puede plantear una regla inicial de decisión: rechazar $H_0$ cuando $\hat{\sigma}^2_{MV}$ es muy grande comparado con $\sigma^2_0$ o muy pequeño comparado con $\sigma^2_0$. Esta idea puede ser formalizada como
\begin{center}
Rechazar $H_0$ cuando $\hat{\sigma}^2_{MV}-\sigma^2_0>K_1$ o $\hat{\sigma}^2_{MV}-\sigma^2_0<K_2$
\end{center}
para constantes $K_1>0$ y $K_2<0$. Para completar la regla de decisión, es necesario encontrar los valores de $K_1$ y $K_2$; para ello, recurrimos nuevamente a la definición del error tipo I, y al limitar a la probabilidad de cometer este error a ser igual a $\alpha$, tenemos
\begin{align*}
\alpha&=Pr(\hat{\sigma}^2_{MV}-\sigma^2_0>K_1)+Pr(\hat{\sigma}^2_{MV}-\sigma^2_0<K_2)\ \ \ \ \text{Cuando $H_0$ es cierta}\\
&=Pr\left(\frac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}>\frac{nK_1}{\sigma^2_0}+n\right)+Pr\left(\frac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}<\frac{nK_2}{\sigma^2_0}+n\right).
\end{align*}

Recordando que $\frac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}\sim\chi^2_n$ bajo la hipótesis nula de $\sigma^2=\sigma^2_0$, se tiene que $\frac{nK_1}{\sigma^2_0}+n$ y $\frac{nK_2}{\sigma^2_0}+n$ son percentiles de la distribución $\chi^2_n$, y existen muchos percentiles que satisfacen la anterior igualdad. Los percentiles que se usan con más frecuencia son $\frac{nK_1}{\sigma^2_0}+n=\chi^2_{n,1-\alpha/2}$ y $\frac{nK_2}{\sigma^2_0}+n=\chi^2_{n,\alpha}$. De donde se tiene que $K_1=\frac{\chi^2_{n,1-\alpha/2}-n}{n\sigma^2_0}$ y $K_2=\frac{\chi^2_{n,\alpha/2}-n}{n\sigma^2_0}$. De esta forma, tenemos la siguiente regla de decisión para el sistema (\ref{sigma_igual_dif})\index{Regla de decisión!normal!varianza teórica}
\begin{center}
Rechazar $H_0$ cuando $\hat{\sigma}^2_{MV}-\sigma^2_0>\frac{\chi^2_{n,1-\alpha/2}-n}{n\sigma^2_0}$ o $\hat{\sigma}^2_{MV}-\sigma^2_0<\frac{\chi^2_{n,\alpha/2}-n}{n\sigma^2_0}$.
\end{center}
Simples operaciones algebraicas nos conducen a la siguiente regla de decisión equivalente\index{Regla de decisión!normal!varianza teórica}
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}>\chi^2_{n,1-\alpha/2}$ o $\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}<\chi^2_{n,\alpha/2}$.
\end{center}

\subsubsection*{$p$ valor}

\index{$p$ valor!normal!varianza teórica}Para obtener la forma de calcular el $p$ valor para el sistema (\ref{sigma_igual_dif}) ligado a la anterior regla de decisión, se tiene en cuenta que la estadística de prueba es $\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}$. En una muestra observada, el valor que toma la estadística puede ser mayor o menor al percentil 0.5 de la distribución $\chi^2_{n}$, como lo ilustra en la Figura 4.14. Puede tomar valores como $v_1$ o como $v_2$. Cuando el valor de la estadística $v$ es mayor a $\chi^2_{n,0.5}$, podemos observar que $v$ cae en la región de rechazo cuando la probabilidad a la derecha es menor a $\alpha/2$, el área del región de rechazo a la derecha, esto es, cuando $Pr(\chi^2_n>v)<\alpha/2$, con $\chi^2_n$ una variable aleatoria con distribución $\chi^2_{n}$; por otro lado, cuando el valor de la estadística $v$ es menor a $\chi^2_{n,0.5}$, se rechaza $H_0$ cuando $Pr(\chi^2_{n}<v)<\alpha/2$. En conclusión
\begin{equation*}
\text{Rechazar}\ H_0\ \text{si}
\left\{
  \begin{array}{ll}
    \hbox{$2Pr(\chi^2_n>v)<\alpha$}, & \hbox{para\ $v>\chi^2_{n,0.5}$ ;} \\
    \hbox{$2Pr(\chi^2_n<v)<\alpha$}, & \hbox{para \ $v<\chi^2_{n,0.5}$.}
  \end{array}
\right.
\end{equation*}


\begin{figure}[!htb]
\centering
\includegraphics[bb=0 0 1233 1022, scale=0.2]{pvalor_chi.jpg}
\caption[\textsl{$p$ valor para la hipótesis (\ref{sigma_igual_dif})}]{\textsl{Ilustración del $p$ valor para la hipótesis (\ref{sigma_igual_dif})}}
\end{figure}

De esta forma, se define el $p$ valor como
\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr(\chi^2_n>v)$}, & \hbox{para\ $v>\chi^2_{n,0.5}$ ;} \\
    \hbox{$2Pr(\chi^2_n<v)$}, & \hbox{para \ $v<\chi^2_{n,0.5}$.}
  \end{array}
\right.
\end{equation*}

y se rechaza $H_0$ cuando el $p$ valor es menor que el nivel de significación $\alpha$.

\subsubsection*{Función de potencia}

\index{Función de potencia!normal!varianza teórica}De la definición de la función de potencia tenemos que
\begin{align}\label{potencia_sigma1}
\beta(\sigma^2)&=Pr\left(\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}>\chi^2_{n,1-\alpha/2}\right)+ Pr\left(\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}<\chi^2_{n,\alpha/2}\right)\notag\\
&=Pr\left(\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2}>\frac{\sigma^2_0}{\sigma^2}\chi^2_{n,1-\alpha/2}\right)+ Pr\left(\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2}<\frac{\sigma^2_0}{\sigma^2}\chi^2_{n,\alpha/2}\right)\notag\\
&=1-F_{\chi^2_{n}}\left(\frac{\sigma^2_0}{\sigma^2}\chi^2_{n,1-\alpha/2}\right)+F_{\chi^2_{n}}\left(\frac{\sigma^2_0}{\sigma^2}\chi^2_{n,\alpha/2}\right)
\end{align}

donde $F_{\chi^2_{n}}(\cdot)$ es la función de distribución de uan distribución $\chi^2_{n}$. Nótese que en primer lugar, esta función se define para valores positivos, y además no depende de la media teórica $\mu$. Observando simplemente la forma de esta función, no es claro si al aumentar el tamaño muestral la potencia incrementa o no, pero podemos graficar la función $\beta(\sigma^2)$ para diferentes tamaños muestrales y cómo afectan estos en la potencia de la prueba.
\begin{verbatim}
> po_sigma<-function(sigma,n,sigma0,alpha){
+ 1-pchisq(sigma0/sigma*qchisq(1-alpha/2,n),n)+
+ pchisq(sigma0/sigma*qchisq(alpha/2,n),n)   }
>
> alpha<-0.05
> sigma0<-10
> n1<-10
> n2<-30
> n3<-50
>
> sigma<-sigma0+seq(-10,30,0.1)
>
> plot(function(x) po_sigma(x,n1,sigma0,alpha),0,40,type="l",
+ xlab="sigma^2",ylab="función de potencia")
> curve(po_sigma(x,n2,sigma0,alpha),0,40,,lty=2,add=T)
> curve(po_sigma(x,n3,sigma0,alpha),0,40,,lty=3,add=T)
> legend(30,0.4,c("n=10","n=30","n=50"),lty=c(1,2,3))
\end{verbatim}

En la Figura 4.15 se muestra esta función de potencia para diferentes tamaños de muestra y se observa que la potencia aumenta al incrementarse el tamaño muestral. Además observe que $\beta(\sigma^2)$ no es simétrica con respecto a $\sigma^2$, esto implica que si se tienen dos muestras aleatorias, la primera con varianza teórica $\sigma^2_0+\delta$ y la segunda con $\sigma^2_0-\delta$ para algún $0<\delta<\sigma^2_0$, y se juzga el sistema $H_0:\ \sigma^2=\sigma^2_0$ vs. $H_1:\ \sigma^2\neq\sigma^2_0$, es menos probable aceptar $H_0$ en la segunda muestra que en la primera. En otras palabras, cuando en la práctica se acepta $H_0:\ \sigma^2=\sigma^2_0$, es posible que en la población $\sigma^2$ sea diferente que $\sigma^2_0$ y lo que ilustran las gráficas de (\ref{potencia_sigma1}) es que es más probable que en la población ocurra $\sigma^2>\sigma^2_0$ que ocurra $\sigma^2<\sigma^2_0$.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.6]{potencia_sigma1.eps}
\caption[\textsl{Función de potencia (\ref{potencia_sigma1})}]{\textsl{Función de potencia (\ref{potencia_sigma1}) para diferentes tamaños de muestra con $\alpha=0.05$ y $\sigma^2_0=10$.}}
\end{figure}

\subsubsection{$H_0:\ \sigma^2\leq(=)\sigma^2_0$ vs. $H_1:\ \sigma^2>\sigma^2_0.$ con $\mu$ conocido\index{Prueba de hipótesis!normal!varianza teórica}}

Ahora, consideramos el siguiente sistema de hipótesis
\begin{equation}\label{sigma_igual_mayo}
H_0:\ \sigma^2=\sigma^2_0\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2>\sigma^2_0.
\end{equation}

que tiene la misma regla de decisión que el sistema

\begin{equation*}
H_0:\ \sigma^2\leq\sigma^2_0\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2>\sigma^2_0.
\end{equation*}

Usaremos la prueba de la razón de verosimilitud\index{Prueba!de razón de verosimilitud!normal} para encontrar una regla de decisión. Para eso, primero transformamos el anterior sistema en el siguiente
\begin{equation}\label{sigma_igual_mayor}
H_0:\ \sigma^2=\sigma^2_0\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2=\sigma^2_1,
\end{equation}

con $\sigma^2_1>\sigma^2_0$.

La función de verosimilitud en una muestra proveniente de la distribución normal está dada por
\begin{equation*}
L(\sigma^2)=(2\pi\sigma^2)^{-n/2}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(X_i-\mu)^2\right\}.
\end{equation*}

Entonces la razón de verosimilitudes está dada por
\begin{equation*}
\lambda=\dfrac{(\sigma^2_1)^{-n/2}}{(\sigma^2_0)^{-n/2}}\exp\left\{-\frac{1}{2}\left(\frac{1}{\sigma_1^2}-\frac{1}{\sigma^2_0}\right)\sum_{i=1}^n(X_i-\mu)^2\right\},
\end{equation*}

y $H_0$ se rechaza para valores grandes de $\lambda$. Ahora, en la expresión de $\lambda$, la parte aleatoria que toma valores diferentes en muestras diferentes es $\sum_{i=1}^n(X_i-\mu)^2$, y obsérvese que la expresión $\frac{(\sigma^2_1)^{-n/2}}{(\sigma^2_0)^{-n/2}}$ y $-\frac{1}{2}\left(\frac{1}{\sigma_1^2}-\frac{1}{\sigma^2_0}\right)$ son ambos positivos, entonces cuando $\sum_{i=1}^n(X_i-\mu)^2$ toma valores grandes, $\lambda$ también lo hace. De esta forma podemos afirmar que se rechaza $H_0$ para valores grandes de $\sum_{i=1}^n(X_i-\mu)^2$. Esto es
\begin{center}
Rechazar $H_0$ cuando $\sum_{i=1}^n(X_i-\mu)^2>K$
\end{center}
para algún $K>0$. De nuevo, para encontrar el valor de $K$, se utiliza la definición del error tipo I, de donde
\begin{align*}
\alpha&=Pr\left(\sum_{i=1}^n(X_i-\mu)^2>K\right)\ \ \ \ \text{Cuando $H_0$ es cierta}\\
&=Pr\left(\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}>\dfrac{K}{\sigma^2_0}\right).
\end{align*}

Cuando $H_0$ es cierta, $\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}\sim\chi^2_{n}$, entonces la anterior expresión indica que $\dfrac{K}{\sigma^2_0}=\chi^2_{n,1-\alpha}$. De esta forma se tiene la siguiente regla de decisión\index{Regla de decisión!normal!varianza teórica}
\begin{center}
Rechazar $H_0$ cuando $\sum_{i=1}^n(X_i-\mu)^2>\chi^2_{n,1-\alpha}\sigma^2_0$,
\end{center}
o equivalentemente\index{Regla de decisión!normal!varianza teórica}
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}>\chi^2_{n,1-\alpha}$.
\end{center}

\subsubsection*{Región de rechazo y $p$ valor}

\index{Región de rechazo!normal!varianza teórica}\index{$p$ valor!normal!varianza teórica}En la anterior regla de decisión la región de rechazo asociada con la estadística de prueba $\frac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}$ está dada por $\{c:\in\mathbb{R}:\ c>\chi^2_{n,1-\alpha}\}$. Y asociado a esta región de rechazo el $p$ valor se calcula como
\begin{equation*}
p\ \text{valor}=Pr(\chi^2_n>v),
\end{equation*}

donde $v$ es el valor observado de la estadística de prueba $\frac{\sum_{i=1}^n(X_i-\mu)^2}{\sigma^2_0}$.

\subsubsection*{Función de potencia}

\index{Función de potencia!normal!varianza teórica}Teniendo en cuenta la definición de la función de potencia, tenemos que
\begin{equation}\label{potencia_sigma2}
\beta(\sigma^2)=1-F_{\chi^2_{n}}\left(\dfrac{\sigma^2_0}{\sigma^2}\chi^2_{n,1-\alpha}\right).
\end{equation}

Ilustramos la forma de esta función en la Figura 4.16 con $\sigma^2_0=10$, $\alpha=0.05$ para diferentes tamaños de muestra.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.6]{potencia_sigma2.eps}
\caption[\textsl{Función de potencia (\ref{potencia_sigma2})}]{\textsl{Función de potencia (\ref{potencia_sigma2}) para diferentes tamaños de muestra con $\alpha=0.05$ y $\sigma^2_0=10$.}}
\end{figure}

\subsubsection{$H_0:\ \sigma^2\geq(=)\sigma^2_0$ vs. $H_1:\ \sigma^2<\sigma^2_0.$ con $\mu$ conocido}

El procedimiento para encontrar una regla de decisión para este sistema es similar a lo desarrollado anteriormente y se deja como ejercicio (Ejercicio 4.7).

\subsubsection{$H_0:\ \sigma^2=\sigma^2_0$ vs. $H_1:\ \sigma^2\neq\sigma^2_0.$ con $\mu$ desconocido\index{Prueba de hipótesis!normal!varianza teórica}}
Cuando la media teórica $\mu$ es desconocida, el estimador de máxima verosimilitud para $\sigma^2$ es $\hat{\sigma^2}_{MV}=\frac{1}{n}\sum_{i=1}^n(X_i-\bar{X})^2$, y al adoptar el procedimiento presentado al principio de la sección 4.2.2 para el caso cuando $\mu$ es conocido, se puede encontrar que para el sistema
\begin{equation*}
H_0:\ \sigma^2=\sigma^2_0\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2\neq\sigma^2_0,
\end{equation*}

una regla de decisión es\index{Regla de decisión!normal!varianza teórica}
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2_0}>\chi^2_{n-1,1-\alpha/2}$ o $\dfrac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2_0}<\chi^2_{n-1,\alpha/2}$.
\end{center}
Y se encuentra, similarmente, el $p$ valor dado por\index{$p$ valor!normal!varianza teórica}
\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr(\chi^2_{n-1}>v)$}, & \hbox{para\ $v>\chi^2_{n-1,0.5}$ ;} \\
    \hbox{$2Pr(\chi^2_{n-1}<v)$}, & \hbox{para \ $v<\chi^2_{n-1,0.5}$.}
  \end{array}
\right.
\end{equation*}

donde $\chi^2_{n-1}$ denota una variable aleatoria con distribución $\chi^2_{n-1}$ y $v$ es el valor observado de la estadística de prueba $\frac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2_0}$.

También, es fácil verificar que la función de potencia está dada por\index{Función de potencia!normal!varianza teórica}
\begin{equation}\label{potencia_sigma3}
\beta(\sigma^2)=1-F_{\chi^2_{n-1}}\left(\frac{\sigma^2_0}{\sigma^2}\chi^2_{n-1,1-\alpha/2}\right)+F_{\chi^2_{n-1}}\left(\frac{\sigma^2_0}{\sigma^2}\chi^2_{n-1,\alpha/2}\right)
\end{equation}

El lector puede ver que la anterior función de potencia es muy similar a (\ref{potencia_sigma1}) cuando $\mu$ es conocido excepto que el grado de libertad de la distribución $\chi^2$ se cambia de $n$ a $n-1$, por consiguiente la forma de la función de potencia (\ref{potencia_sigma3}) tamién es muy similar a la de (\ref{potencia_sigma1}) presentada en la Figura 4.15.

\subsubsection{$H_0:\ \sigma^2\leq(=)\sigma^2_0$ vs. $H_1:\ \sigma^2>\sigma^2_0.$ con $\mu$ desconocido\index{Prueba de hipótesis!normal!varianza teórica}}

Para el sistema $H_0:\ \sigma^2=\sigma^2_0$ vs. $H_1:\ \sigma^2>\sigma^2_0$ hacemos uso de la prueba de razón de verosimilitudes escribiendo al sistema como
\begin{equation*}
H_0:\ \sigma^2=\sigma^2_0\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2=\sigma^2_1,
\end{equation*}

con $\sigma^2_1>\sigma^2_0$. Al replicar el procedimiento de la prueba de razón de verosimilitud para el caso cuando $\mu$ es conocido, se encuentra la misma estadística de prueba $\sum_{i=1}^n(X_i-\mu)^2$, que no se puede calcular cuando $\mu$ es desconocido. La solución a este problema es reemplazar $\mu$ por su estimador $\bar{X}$. De esta forma, se tiene que la razón de verosimilitud\index{Prueba!de razón de verosimilitud!normal} está dada por
\begin{equation*}
\lambda=\dfrac{(\sigma^2_1)^{-n/2}}{(\sigma^2_0)^{-n/2}}\exp\left\{-\frac{1}{2}\left(\frac{1}{\sigma_1^2}-\frac{1}{\sigma^2_0}\right)\sum_{i=1}^n(X_i-\bar{X})^2\right\}.
\end{equation*}

Usando $\sigma^2_1>\sigma^2_0$, se concluye que $H_0$ se rechaza cuando $\sum_{i=1}^n(X_i-\bar{X})^2>K$. Finalmente, usando la propiedad
\begin{equation*}
\dfrac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2_0}\sim\chi^2_{n-1},
\end{equation*}

bajo $H_0$, se tiene que $K=\sigma^2_0\chi^2_{n-1,1-\alpha}$, y la regla de decisión está dada por\index{Regla de decisión!normal!varianza teórica}
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2_0}>\chi^2_{n-1,1-\alpha}$.
\end{center}
Y el $p$ valor asociado está dado por\index{$p$ valor!normal!varianza teórica}
\begin{equation*}
p\ \text{valor}=Pr(\chi^2_{n-1}>v)
\end{equation*}

donde $v$ es el valor observado de la estadística de prueba $\frac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2_0}$.

\subsubsection{$H_0:\ \sigma^2\geq(=)\sigma^2_0$ vs. $H_1:\ \sigma^2<\sigma^2_0.$ con $\mu$ desconocido}

El procedimiento para encontrar una regla de decisión para este sistema es similar a lo desarrollado anteriormente y se deja como ejercicio (Ejercicio 4.7).

\section{Dos muestras}
Ahora consideramos el problema de dos muestras, donde se encuentran dos poblaciones que tienen una característica común de interés, y se desea comparar las dos poblaciones con base en muestras de estas poblaciones. Suponga que tienen dos muestras aleatorias independientes de tamaño $n_X$ y $n_Y$ denotadas por $X_1$, $\ldots$, $X_{n_X}$ y $Y_1$, $\ldots$, $Y_{n_Y}$ provenientes de $N(\mu_X,\sigma^2_X)$ y $N(\mu_Y,\sigma^2_Y)$, respectivamente.

\subsection{Comparación entre dos medias\index{Prueba de hipótesis!normal}}
En primer lugar, consideramos el problema de comparar las dos poblaciones en términos de las medias teóricas. Por ejemplo, en la industria, cuando se dispone de dos maquinarias o dos líneas de producción que realizan la misma labor, se quiere comparar las dos maquinarias en términos de alguna variable de interés como calidad de productos o eficiencia de producción.

El lector recuerda que en problemas de una muestra cuando se juzgan hipótesis acerca de la media teórica $\mu$, la regla de decisión depende de si la varianza teórica es conocida o no. En el problema de dos muestras tenemos dos varianzas teóricaes $\sigma^2_X$ y $\sigma^2_Y$, y la regla de decisión para sistemas de hipótesis acerca de las medias teóricas también depende de si estas dos varianzas son conocidas o no.

\subsubsection{$H_0:\ \mu^2_X=\mu^2_Y$ vs. $H_1:\ \mu^2_X\neq\mu^2_Y,$ con $\sigma^2_X$ y $\sigma^2_Y$ conocidas}
En primer lugar, suponemos que las varianzas teóricas, $\sigma^2_X$ y $\sigma^2_Y$ son conocidas. Usa\-re\-mos la prueba de razón generalizada de verosimilitudes\index{Prueba!de razón generalizada de verosimilitudes!normal} para encontrar una regla de decisión para el sistema\index{Prueba de hipótesis!normal!igualdad de dos medias}

\begin{equation}\label{muX=muY}
H_0:\ \mu^2_X=\mu^2_Y\ \ \  vs.\ H_1:\ \mu^2_X\neq\mu^2_Y
\end{equation}

En primer lugar, dado que las dos muestras son independientes, se tiene que la función de verosimilitud de las dos muestras es simplemente el producto de las dos funciones de verosimilitudes. Por lo tanto ésta está dada por
\begin{multline*}
L(x_1,\ldots,x_{n_X},y_1,\ldots,y_{n_Y})
=(2\pi\sigma^2_X)^{-n_X/2}\exp\left\{-\frac{1}{2\sigma^2_X}\sum_{i=1}^{n_X}(X_i-\mu_X)^2\right\}\\(2\pi\sigma^2_Y)^{-n_Y/2}\exp\left\{-\frac{1}{2\sigma^2_Y}\sum_{i=1}^{n_Y}(Y_i-\mu_Y)^2\right\}
\end{multline*}

Dado que en el sistema considerado, $\boldsymbol{\Theta}_1=\boldsymbol{\Theta}_0^c$, se tiene que el numerador de la razón generalizada de verosimilitudes $\lambda$ está dado por la función de verosimilitud evaluada en los estimadores $MV$ de $\mu_X$ y $\mu_Y$. Esto es,
\begin{multline*}
L(\hat{\mu}_{X,MV},\hat{\mu}_{Y,MV})=(2\pi\sigma^2_X)^{-n_X/2}\exp\left\{-\frac{1}{2\sigma^2_X}\sum_{i=1}^{n_X}(X_i-\bar{X})^2\right\}\\(2\pi\sigma^2_Y)^{-n_Y/2}\exp\left\{-\frac{1}{2\sigma^2_Y}\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2\right\}.
\end{multline*}
Por otro lado, bajo la hipótesis nula $H_0$, $\mu_X=\mu_Y$, entonces las dos muestras provienen de distribución con la misma media teórica, $\mu$. Se ha visto en (\ref{MV_mu_comun}) que el estimador $MV$ de la media teórica común está dado por
\begin{equation}\label{mu_comun}
\hat{\mu}_{MV}=\dfrac{\sigma^2_Yn_X\bar{X}+\sigma^2_Xn_Y\bar{Y}}{n_X\sigma^2_Y+n_Y\sigma^2_X}.
\end{equation}

Y de esta forma, el denominador de $\lambda$ está dado por
\begin{multline*}
L(\hat{\mu}_{MV})=(2\pi\sigma^2_X)^{-n_X/2}\exp\left\{-\frac{1}{2\sigma^2_X}\sum_{i=1}^{n_X}(X_i-\hat{\mu}_{MV})^2\right\}\\(2\pi\sigma^2_Y)^{-n_Y/2}\exp\left\{-\frac{1}{2\sigma^2_Y}\sum_{j=1}^{n_Y}(Y_j-\hat{\mu}_{MV})^2\right\}.
\end{multline*}

En conclusión, $\ln\lambda$ está dado por
\begin{multline*}
\ln\lambda=-\frac{1}{2\sigma^2_X}\left\{\sum_{i=1}^{n_X}\left[(X_i-\bar{X})^2-(X_i-\hat{\mu}_{MV})^2\right]\right\}-\frac{1}{2\sigma^2_Y}\\\left\{\sum_{j=1}^{n_Y}\left[(Y_j-\bar{Y})^2-(Y_j-\hat{\mu}_{MV})^2\right]\right\},
\end{multline*}

donde
\begin{align*}
\sum_{i=1}^{n_X}\left[(X_i-\bar{X})^2-(X_i-\hat{\mu}_{MV})^2\right]
&=\sum_{i=1}^{n_X}(2X_i-\bar{X}-\hat{\mu}_{MV})(\hat{\mu}_{MV}-\bar{X})\\
&=-n_X(\bar{X}-\hat{\mu}_{MV})^2.
\end{align*}

Simples operaciones algebraicas muestran que
\begin{equation}\label{auxiliar1}
\bar{X}-\hat{\mu}_{MV}=\frac{\sigma^2_Xn_Y(\bar{X}-\bar{Y})}{n_X\sigma^2_Y+n_Y\sigma^2_X},
\end{equation}

de donde
\begin{equation*}
\sum_{i=1}^{n_X}\left[(X_i-\bar{X})^2-(X_i-\hat{\mu}_{MV})^2\right]=-\frac{n_Xn_Y^2\sigma_X^4(\bar{X}-\bar{Y})^2}{(n_X\sigma^2_Y+n_Y\sigma_X^2)^2}.
\end{equation*}

Análogamente, se tiene que
\begin{equation*}
\sum_{j=1}^{n_Y}\left[(Y_i-\bar{Y})^2-(Y_i-\hat{\mu}_{MV})^2\right]=-\frac{n_X^2n_Y\sigma_Y^4(\bar{X}-\bar{Y})^2}{(n_X\sigma^2_Y+n_Y\sigma_X^2)^2}.
\end{equation*}

De donde, tenemos que
\begin{equation*}
\ln\lambda=\frac{n_Xn_Y}{2(n_X\sigma^2_Y+n_Y\sigma^2_X)^2}(\bar{X}-\bar{Y})^2.
\end{equation*}

Se debe rechazar $H_0$ para valores grandes de $\ln\lambda$, la cual es equivalente a rechazar $H_0$ para valores grandes de $(\bar{X}-\bar{Y})^2$ o $|\bar{X}-\bar{Y}|$. Y tenemos la siguiente regla de decisión
\begin{center}
Rechazar $H_0$ cuando $|\bar{X}-\bar{Y}|>K$, para algún $K>0$.
\end{center}

Para encontrar el valor de $K$, tenemos que
\begin{align}\label{barX-barYmayor}
\alpha&=Pr(|\bar{X}-\bar{Y}|>K)\notag\\
&=Pr(\bar{X}-\bar{Y}>K)+Pr(\bar{X}-\bar{Y}<-K),
\end{align}
suponiendo que $H_0$ es cierta. En este caso,
\begin{equation*}
\bar{X}-\bar{Y}\sim N\left(0,\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}\right),
\end{equation*}

y de (\ref{barX-barYmayor}), se concluye que $Pr(\bar{X}-\bar{Y}>K)=\alpha/2$, y se encuentra que $K=z_{1-\alpha/2}\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}$. Y tenemos la regla de decisión\index{Regla de decisión!normal!igualdad de dos medias}
\begin{center}
Rechazar $H_0$ cuando $|\bar{X}-\bar{Y}|>z_{1-\alpha/2}\sqrt{\dfrac{\sigma^2_X}{n_X}+\dfrac{\sigma^2_Y}{n_Y}}$
\end{center}
o equivalentemente
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\bar{X}-\bar{Y}}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}>z_{1-\alpha/2}$ o $\dfrac{\bar{X}-\bar{Y}}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}<-z_{1-\alpha/2}$.
\end{center}
Nótese que la anterior regla de decisión es equivalente al uso del intervalo de confianza (\ref{int_mux-muy_caso1}). Puesto que con el uso del intervalo, se rechaza $\mu_X=\mu_Y$ cuando el valor 0 no pertenece al intervalo, esto es, $0<\bar{X}-\bar{Y}-z_{1-\alpha/2}\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}$ o $0>\bar{X}-\bar{Y}+z_{1-\alpha/2}\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}$, lo cual es equivalente a la regla de decisión encontrada anteriormente.

\subsubsection*{$p$ valor}

\index{$p$ valor!normal!igualdad de dos medias}La forma de calcular el $p$ valor es similar a lo discutido para el sistema $\mu=\mu_0$ vs. $\mu\neq\mu_0$, cuando la varianza teórica es conocida. Y se encuentra que
\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr(Z>v)$}, & \hbox{para\ $v>0$ ;} \\
    \hbox{$2Pr(Z<v)$}, & \hbox{para \ $v<0$.}
  \end{array}
\right.
\end{equation*}

donde $v$ es el valor observado de la estadística de prueba $(\bar{X}-\bar{Y})/\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}$ y $Z$ denota una variable aleatoria con distribución normal estándar.

\subsubsection*{Función de potencia}

\index{Función de potencia!normal!igualdad de dos medias}Para encontrar la función de potencia tenemos que
\begin{align}\label{potencia_mux_muy}
&\ \ \ \ \beta(\mu_X,\mu_Y)\\&=Pr(\text{Rechazar $H_0$})\notag\\
&=Pr\left(\dfrac{\bar{X}-\bar{Y}}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}>z_{1-\alpha/2}\right)+
Pr\left(\dfrac{\bar{X}-\bar{Y}}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}<-z_{1-\alpha/2}\right)\notag\\
&=Pr\left(\dfrac{\bar{X}-\bar{Y}-(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}>z_{1-\alpha/2}+\dfrac{(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}\right)\\
&\ \ \ \ \ \ \ \ \ \ \ +Pr\left(\dfrac{\bar{X}-\bar{Y}-(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}<-z_{1-\alpha/2}+\dfrac{(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}\right)\notag\\
&=1-\Phi\left(z_{1-\alpha/2}+\dfrac{(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}\right)+\Phi\left(-z_{1-\alpha/2}+\dfrac{(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma^2_X}{n_X}+\frac{\sigma^2_Y}{n_Y}}}\right)
\end{align}

Observemos que la función $\beta(\mu_X,\mu_Y)$ depende, inicialmente, de dos parámetros $\mu_X$ y $\mu_Y$, por lo tanto es una función de dos argumentos, y la gráfica debe ser como la mostrada en la Figura 4.17.

Sin embargo, en (\ref{potencia_mux_muy}) podemos ver que la función de potencia depende de $\mu_X$ y $\mu_Y$ únicamente a través de $\mu_X-\mu_Y$, de hecho la gráfica en Figura 4.17 es simétrica con respecto al plano $\{(\mu_X,\mu_Y):\ \mu_X=\mu_Y\}$. De esta forma, podemos visualizar esta función de potencia solo variando los valores de $\mu_X-\mu_Y$. El siguiente código calcula y grafica la función (\ref{potencia_mux_muy}) para diferentes tamaños de muestra, y el resultado se observa en la Figura 4.18

\begin{verbatim}
> pote_2_norm<-function(dif,nx,ny,alpha,sigmaX,sigmaY){
+ 1-pnorm(dif/sqrt((sigmaX/nx)+(sigmaY/ny))+qnorm(1-alpha/2))+
+ pnorm(dif/sqrt((sigmaX/nx)+(sigmaY/ny))-qnorm(1-alpha/2)) }

> alpha<-0.05
> sigmaX<-1
> sigmaY<-4
> n1<-10
> n2<-30
> n3<-50

> plot(function(x) pote_2_norm(x,n1,n1,alpha,sigmaX,sigmaY),-4,4,
+ type="l",xlab="mu_X-mu_Y",ylab="función de potencia")
> curve(pote_2_norm(x,n2,n2,alpha,sigmaX,sigmaY),-4,4,lty=2,add=T)
> curve(pote_2_norm(x,n3,n3,alpha,sigmaX,sigmaY),-4,4,lty=3,add=T)
> legend(1.8,0.4,c("nx=ny=10","nx=ny=30","nx=ny=50"),lty=c(1,2,3))
\end{verbatim}

\begin{figure}[!h]
\centering
\includegraphics[bb=0 0 888 786, scale=0.3]{potencia3D.jpg}
\caption[\textsl{Función de potencia (\ref{potencia_sigma2})}]{\textsl{Función de potencia (\ref{potencia_sigma2}) para con $\alpha=0.05$, $\sigma^2_X=1$, $\sigma^2_Y=4$ y $n_X=n_Y=10$.}}
\end{figure}

Observamos que la fórmula de la anterior función de potencia se asemeja a la del sistema (\ref{igual_desigual}) con varianza teórica conocida, y por consiguiente es de esperar que la forma de las dos funciones de potencia también sean similares, lo cual se confirma observando la Figura 4.18.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.4]{potencia_mux_muY.eps}
\caption[\textsl{Función de potencia (\ref{potencia_mux_muy})}]{\textsl{Función de potencia (\ref{potencia_mux_muy}) para diferentes tamaños de muestra con $\alpha=0.05$ y $\sigma^2_0=10$.}}
\end{figure}

\subsubsection{$\sigma^2_X$ y $\sigma^2_Y$ son desconocidas, pero iguales.\index{Prueba de hipótesis!normal!igualdad de dos medias}}
Suponga que $\sigma^2_X=\sigma^2_Y=\sigma^2$ es desconocida, se debe reemplazarlas por el estimador MV de la varianza común $\sigma^2$. Como se mencionaba en el capítulo 2, cuando las dos muestras provienen de distribuciones con la misma varianza teórica $\sigma^2$, se puede usar las variables de las dos muestras para estimar la varianza común $\sigma^2$, en este caso, y se tiene que
\begin{equation*}
\hat{\sigma}^2_{MV}=\frac{(n_X-1)S^2_{n_X-1,X}+(n_Y-1)S^2_{n_Y-1,Y}}{n_X+n_Y}.
\end{equation*}

De esta forma tenemos que el numerador de la razón generalizada de verosimilitudes está dado por\index{Prueba!de razón generalizada de verosimilitudes!normal}
\begin{align}\label{nume_lambda_dosmuestras}
&\ \ \ \ \ L(\hat{\mu}_{X,MV},\hat{\mu}_{Y,MV},\hat{\sigma}^2_{MV})\notag\\
&=\left(2\pi\hat{\sigma}^2_{MV}\right)^{-(n_X+n_Y)/2}\exp\left\{-\frac{1}{2\hat{\sigma}^2_{MV}}\left[\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2\right]\right\}\notag\\
&=\left(2\pi\hat{\sigma}^2_{MV}\right)^{-(n_X+n_Y)/2}\exp\left\{-\frac{n_X+n_Y}{2}\right\}.
\end{align}

Por otro lado, suponiendo $H_0$ verdadera, $\mu_X=\mu_Y=\mu$, entonces las dos muestras provienen de la misma distribución, y en este caso el estimador MV de $\mu$ está dado por (\ref{MV_mu_comun1}), esto es
\begin{equation*}
\hat{\mu}_{MV}=\dfrac{\sum_{i=1}^{n_X}X_i+\sum_{j=1}^{n_Y}Y_j}{n_X+n_Y},
\end{equation*}

y
\begin{equation*}
\hat{\sigma}^2_{0,MV}=\dfrac{\sum_{i=1}^{n_X}(X_i-\hat{\mu}_{MV})^2+\sum_{j=1}^{n_Y}(Y_j-\hat{\mu}_{MV})^2}{n_X+n_Y}.
\end{equation*}

De donde el denominador de $\lambda$ está dado por
\begin{align}\label{verosimil1}
&\ \ \ \ \ L(\hat{\mu}_{MV},\hat{\sigma^2}_{0,MV})\notag\\
&=\left(2\pi\hat{\sigma}^2_{0,MV}\right)^{-(n_X+n_Y)/2}\exp\left\{-\frac{1}{2\hat{\sigma}^2_{0,MV}}\left[\sum_{i=1}^{n_X}(X_i-\hat{\mu}_{MV})^2+\sum_{j=1}^{n_Y}(Y_j-\hat{\mu}_{MV})^2\right]\right\}\\
&=\left(2\pi\hat{\sigma}^2_{0,MV}\right)^{-(n_X+n_Y)/2}\exp\left\{-\frac{n_X+n_Y}{2}\right\}.
\end{align}
Dado lo anterior, podemos tener que
\begin{equation*}
\lambda=\left(\dfrac{\hat{\sigma}^2_{MV}}{\hat{\sigma}^2_{0,MV}}\right)^{-(n_X+n_Y)/2},
\end{equation*}

y podemos concluir que se rechaza $H_0$ para valores grandes de la estadística $\dfrac{\hat{\sigma}^2_{0,MV}}{\hat{\sigma}^2_{MV}}$, donde
\begin{align}\label{lambda11}
\dfrac{\hat{\sigma}^2_{0,MV}}{\hat{\sigma}^2_{MV}}&=\dfrac{\sum_{i=1}^{n_X}(X_i-\hat{\mu}_{MV})^2+\sum_{j=1}^{n_Y}(Y_j-\hat{\mu}_{MV})^2}{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}\notag\\
&=\dfrac{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+n_X(\bar{X}-\hat{\mu}_{MV})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2+n_Y(\bar{Y}-\hat{\mu}_{MV})^2}{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}\notag\\
&=1+\dfrac{n_X(\bar{X}-\hat{\mu}_{MV})^2+n_Y(\bar{Y}-\hat{\mu}_{MV})^2}{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}.
\end{align}
Ahora, simples operaciones algebraicas muestran que
\begin{equation*}
n_X(\bar{X}-\hat{\mu}_{MV})^2=\frac{n_Xn_Y^2(\bar{X}-\bar{Y})^2}{(n_X+n_Y)^2},
\end{equation*}

y
\begin{equation*}
n_Y(\bar{Y}-\hat{\mu}_{MV})^2=\frac{n_Yn_X^2(\bar{X}-\bar{Y})^2}{(n_X+n_Y)^2}.
\end{equation*}

De esta forma, reemplazando en (\ref{lambda11}), tenemos que
\begin{equation*}
\dfrac{\hat{\sigma}^2_{0,MV}}{\hat{\sigma}^2_{MV}}=1+\frac{n_Xn_Y}{n_X+n_Y}\frac{(\bar{X}-\bar{Y})^2}{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}
\end{equation*}

Entonces la regla de decisión para el sistema de interés es
\begin{center}
Rechazar $H_0$ cuando $\dfrac{(\bar{X}-\bar{Y})^2}{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}>K$,
\end{center}
para algún $K>0$. La cual es equivalente a
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\bar{X}-\bar{Y}}{\sqrt{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}}>K_1$ o $\dfrac{\bar{X}-\bar{Y}}{\sqrt{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}}<-K_1$
\end{center}
para algún $K_1>0$.

Para encontrar el valor de $K_1$, se debe conocer la distribución de la estadística de prueba bajo $H_0:\ \mu_X=\mu_Y$, aunque esta distribución no es ninguna de las comunes, recordamos (\ref{t}), y tenemos que bajo $H_0$
\begin{equation*}
\dfrac{\bar{X}-\bar{Y}}{S_p\sqrt{\frac{1}{n_X}+\frac{1}{n_Y}}}\sim t_{n_X+n_Y-2},
\end{equation*}

con $S^2_p=\frac{\sum_{i=1}^{n_X}(X_i-\bar{X})^2+\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}{n_X+n_Y-2}$. Usando esta distribución, podemos modificar la regla de decisión encontrada anteriormente y así\index{Regla de decisión!normal!igualdad de dos medias}
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\bar{X}-\bar{Y}}{S_p\sqrt{\frac{1}{n_X}+\frac{1}{n_Y}}}>K_2$ o $\dfrac{\bar{X}-\bar{Y}}{S_p\sqrt{\frac{1}{n_X}+\frac{1}{n_Y}}}<-K_2$,
\end{center}
de donde usando la definición de error tipo I, se tiene que $K_2=t_{n_X+n_Y-2,1-\alpha/2}$, y completamos la regla de decisión. Se deja como ejercicio encontrar la fórmula del $p$ valor y la función de potencia (Ejercicio 4.9).

\begin{Eje}
En el Ejemplo 2.3.12, se planteó el problema de comparar dos institutos $A$ y $B$ de capacitación en términos de calificación obtenida por sus alumnos, y se verificó que la distribución normal parece ser apropiada para describir estos datos. Si $\mu_A$ y $\mu_B$ denotan la calificación promedio de los estudiantes de los dos institutos, entonces para ver si hay diferencia significativa entre los dos institutos, planteamos el sistema $H_0:\ \mu_A=\mu_B$ vs. $H_1:\ \mu_A\neq\mu_B$; para ello, necesitamos conocer si las va\-rian\-zas teóricas pueden considerarse iguales o no. Las estimaciones de las desviaciones estándares son 8.276185 y 8.55525, respectivamente, podemos ver que son bastante similares, lo cual puede ser un indicio de que las varianzas teóricas son iguales.

Dado lo anterior, aplicamos la prueba $t$ asumiendo igualdad entre las varianzas teóricas,
\begin{verbatim}
    > A<-c(75, 87, 83, 73, 74, 88, 88, 74, 64, 92, 73, 87, 91, 83,84)
    > B<-c(64, 85, 72, 64, 74, 93, 70, 79, 79, 75, 66, 83 ,74)
    > t.test(A,B, var.equal=T)

            Two Sample t-test

    data:  A and B
    t = 1.8321, df = 26, p-value = 0.07842
    alternative hypothesis: true difference in means is not equal to 0
    95 percent confidence interval:
     -0.7116975 12.3834924
    sample estimates:
    mean of x mean of y
     81.06667  75.23077
\end{verbatim}
Observamos que el $p$-valor de esta prueba es de 0.07842, entonces con un nivel de significación de 5\% no se rechaza $H_0$, pero si se cambia el nivel de significación de 10\% sí se rechaza $H_0$. El nivel de significación $\alpha$ es el límite superior para el error de rechazar una hipótesis verdadera, entonces al tomar un $\alpha$ pequeño, es más difícil rechazar $H_0$; de hecho, el área de la región de rechazo es más pequeña, y es más difícil que el valor de la estadística se sitúe dentro de la región de rechazo.
\end{Eje}

\subsubsection{$\sigma^2_X$ y $\sigma^2_Y$ son desconocidos y diferentes\index{Prueba de hipótesis!normal!igualdad de dos medias}}
Cuando las varianzas de las dos poblaciones son desconocidas y además diferentes, tenemos la misma situación considerada en la sección 3.1.2, donde se introdujo la estadística $D$ dada por (\ref{estadistica_D}), cuya distribución es $t_k$, con $k$ dado por (\ref{valor_k}). Y la regla de decisión queda determinada como\index{Regla de decisión!normal!igualdad de dos medias}
\begin{center}
Rechazar $H_0$ cuando $D>t_{k,1-\alpha/2}$ o $D<-t_{k,1-\alpha/2}$.
\end{center}

\subsection{Comparación entre dos varianzas\index{Prueba de hipótesis!normal!igualdad de dos varianzas}}

En la anterior sesión, se vio que para juzgar un sistema de hipótesis acerca de $\mu_X-\mu_Y$ es necesario conocer la estructura de las dos poblaciones en términos de las varianzas. Cuando éstas no son conocidas, hay que determinar si se puede asumir que sean iguales, y dependiendo de esto, se aplica la regla de decisión apropiada. Por lo anterior, es necesario considerar el siguiente sistema de hipótesis
\begin{equation}\label{sigX=sigY}
H_0:\ \sigma^2_X=\sigma^2_Y\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2_X\neq\sigma^2_Y,
\end{equation}

Teniendo en cuenta que los estimadores de máxima verosimilitud de $\sigma^2_X$ y $\sigma^2_Y$ son $\frac{1}{n_X}\sum_{i=1}^{n_X}(X_i-\bar{X})^2$ y $\frac{1}{n_Y}\sum_{j=1}^{n_Y}(Y_i-\bar{Y})^2$, respectivamente, podemos proponer la siguiente regla de decisión

\begin{center}
Rechazar $H_0$ cuando\index{Regla de decisión!normal!igualdad de dos varianzas} $\frac{\frac{1}{n_X}\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{\frac{1}{n_Y}\sum_{j=1}^{n_Y}(Y_i-\bar{Y})^2}>K_1$ o
$\frac{\frac{1}{n_X}\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{\frac{1}{n_Y}\sum_{j=1}^{n_Y}(Y_i-\bar{Y})^2}<K_2$
\end{center}
para constantes $K_1>1$ y $K_2<1$. Para encontrar los valores de $K_1$ y $K_2$, recordemos, en primer lugar, la siguiente distribución
\begin{equation*}
\dfrac{\sigma^2_YS^2_X}{\sigma^2_XS^2_Y}=\dfrac{\sigma^2_Y(n_Y-1)\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{\sigma^2_X(n_X-1)\sum_{j=1}^{n_Y}(Y_i-\bar{Y})^2}\sim F^{n_X-1}_{n_Y-1},
\end{equation*}

que, bajo $H_0$, se convierte en
\begin{equation}\label{sigx_sigy}
\dfrac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}=\dfrac{(n_Y-1)\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{(n_X-1)\sum_{j=1}^{n_Y}(Y_i-\bar{Y})^2}\sim F^{n_X-1}_{n_Y-1},
\end{equation}

Y usando la definición del error tipo I, tenemos que
\begin{align*}
\alpha&=Pr\left(\dfrac{n_Y\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{n_X\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}>K_1\right)+Pr\left(\dfrac{n_Y\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{n_X\sum_{j=1}^{n_Y}(Y_j-\bar{Y})^2}<K_2\right)\\
&=Pr\left(\dfrac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}>\frac{(n_Y-1)n_XK_1}{(n_X-1)n_Y}\right)+Pr\left(\dfrac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}<\frac{(n_Y-1)n_XK_2}{(n_X-1)n_Y}\right)
\end{align*}
asumiendo que $H_0$ es verdadera. Recurriendo a (\ref{sigx_sigy}), se tiene que $\frac{(n_Y-1)n_XK_1}{(n_X-1)n_Y}$ y $\frac{(n_Y-1)n_XK_2}{(n_X-1)n_Y}$ son percentiles de la distribución $F^{n_X-1}_{n_Y-1}$. Por facilidad, podemos escoger $\frac{(n_Y-1)n_XK_1}{(n_X-1)n_Y}=f^{n_X-1}_{n_y-1,1-\alpha/2}$ y $\frac{(n_Y-1)n_XK_2}{(n_X-1)n_Y}=f^{n_X-1}_{n_y-1,\alpha/2}$. De esta forma, se tiene la siguiente regla de decisión:
\begin{center}
Rechazar $H_0$ cuando $\dfrac{\frac{1}{n_X}\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{\frac{1}{n_Y}\sum_{j=1}^{n_Y}(Y_i-\bar{Y})^2}>\dfrac{(n_X-1)n_Yf^{n_X-1}_{n_y-1,1-\alpha/2}}{(n_Y-1)n_X}$ o $\dfrac{\frac{1}{n_X}\sum_{i=1}^{n_X}(X_i-\bar{X})^2}{\frac{1}{n_Y}\sum_{j=1}^{n_Y}(Y_i-\bar{Y})^2}>\dfrac{(n_X-1)n_Yf^{n_X-1}_{n_y-1,\alpha/2}}{(n_Y-1)n_X}$, \end{center}
la cual es equivalente a\index{Regla de decisión!normal!igualdad de dos varianzas}
\begin{center}
Rechazar $H_0$ cuando $\frac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}>f^{n_X-1}_{n_y-1,1-\alpha/2}$ ó $\frac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}>f^{n_X-1}_{n_y-1,\alpha/2}$. \end{center}
En R, la función \verb"var.test" lleva a cabo el procedimiento.

\subsubsection*{$p$ valor}

\index{$p$ valor!normal!igualdad de dos varianzas}Ahora, consideramos el $p$ valor asociado a la anterior regla de decisión, cuya estadística de prueba es $\frac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}$. Suponga que se observa una muestra aleatoria, el valor que toma la estadística puede ser mayor o menor que el percentil 0.5 de la distribución $f^{n_X-1}_{n_y-1}$ como lo ilustra la Figura 4.19. Si el valor de la estadística es mayor que $f^{n_X-1}_{n_y-1,0.5}$ (el valor $v_1$ en la figura), se rechaza $H_0$ cuando $Pr(F^{n_X-1}_{n_Y-1}>v_1)<\alpha/2$, donde $F^{n_X-1}_{n_Y-1}$ denota una variable aleatoria con distribución $f^{n_X-1}_{n_Y-1}$; por otro lado, si el valor de la estadística es menor que $f^{n_X-1}_{n_y-1,0.5}$, (el valor $v_2$ en la figura), se rechaza $H_0$ cuando $Pr(F^{n_X-1}_{n_Y-1}<v_1)<\alpha/2$

\begin{figure}[!htb]
\centering
\includegraphics[bb=0 0 1396 870, scale=0.2]{pvalor_f1.jpg}
\caption[\textsl{$p$ valor para la hipótesis (\ref{sigX=sigY})}]{\textsl{Ilustración del $p$ valor para la hipótesis (\ref{sigX=sigY}).}}
\end{figure}

Con lo anterior, podemos obtener la siguiente forma de calcular el $p$ valor.
\begin{equation*}
p\ \text{valor}=\left\{
  \begin{array}{ll}
    \hbox{$2Pr(F^{n_X-1}_{n_Y-1}>v)$}, & \hbox{para\ $v>f^{n_X-1}_{n_y-1,0.5}$ ;} \\
    \hbox{$2Pr(F^{n_X-1}_{n_Y-1}<v)$}, & \hbox{para \ $v<f^{n_X-1}_{n_y-1,0.5}$.}
  \end{array}
\right.
\end{equation*}

El siguiente código de R nos permite calcular el $p$ valor para el sistema de hipótesis (\ref{sigX=sigY}) para dos muestras.

\begin{verbatim}
> p.val<-function(x,y){
+ nx<-length(x)
+ ny<-length(y)
+ if(var(x)/var(y)>=qf(0.5,nx-1,ny-1)){
+ p.val<-2*(1-pf(var(x)/var(y),nx-1,ny-1))
+ }
+ if(var(x)/var(y)<qf(0.5,nx-1,ny-1)){
+ p.val<-2*(pf(var(x)/var(y),nx-1,ny-1))}
+ p.val
+ }
\end{verbatim}

\begin{Eje}
En el Ejemplo 4.3.1, donde se compararon dos institutos de ca\-pa\-ci\-ta\-ción en términos de calificación obtenida por sus alumnos, y para juzgar el sistema $H_0:\ \mu_A=\mu_B$ vs. $H_1:\ \mu_A\neq\mu_B$, se hizo el supuesto de que las varianzas teó\-ri\-cas son iguales teniendo en cuenta las estimaciones muestrales. Ahora, efectuamos la prueba $F$ para verificar la validez de este supuesto usando la anterior función para calcular el $p$-valor.
\begin{verbatim}
> A<-c(75, 87, 83, 73, 74, 88, 88, 74, 64, 92, 73, 87, 91, 83,84)
> B<-c(64, 85, 72, 64, 74, 93, 70, 79, 79, 75, 66, 83 ,74)
> p.val(A,B)
[1] 0.8954233
\end{verbatim}
Observamos que el $p$-valor es grande comparado con cualquier valor común en la práctica de $\alpha$, de donde podemos afirmar que $\sigma^2_A=\sigma^2_B$ es un supuesto razonable para los datos.

En R, la función \verb"var.test" lleva a cabo esta prueba $F$, y también calcula un intervalo de confianza para la cociente de varianzas $\sigma^2_A/\sigma^2_B$.
\begin{verbatim}
> var.test(A,B)

        F test to compare two variances

data:  A and B
F = 0.9358, num df = 14, denom df = 12, p-value = 0.8954
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.2918789 2.8544131
sample estimates:
ratio of variances
         0.9358256
\end{verbatim}

\end{Eje}

\subsubsection*{Función de potencia}

\index{Función de potencia!normal!igualdad de dos varianzas}La función de potencia para la anterior regla de decisión puede ser calculada como
\begin{align}\label{potencia_sigX_sigY}
&\ \ \ \ \ \beta(\sigma^2_X,\sigma^2_Y)\notag\\
&=Pr\left(\frac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}>f^{n_X-1}_{n_y-1,1-\alpha/2}\right)+Pr\left(\frac{S^2_{X,n_X-1}}{S^2_{Y,n_Y-1}}>f^{n_X-1}_{n_y-1,\alpha/2}\right)\notag\\
&=Pr\left(\frac{\sigma^2_YS^2_{X,n_X-1}}{\sigma^2_XS^2_{Y,n_Y-1}}>\frac{\sigma^2_X}{\sigma^2_Y}f^{n_X-1}_{n_y-1,1-\alpha/2}\right)+Pr\left(\sigma^2_Y\frac{S^2_{X,n_X-1}}{\sigma^2_XS^2_{Y,n_Y-1}}>\frac{\sigma^2_X}{\sigma^2_Y}f^{n_X-1}_{n_y-1,\alpha/2}\right)\notag\\
&=1-F_{n_X-1,n_Y-1}\left(\frac{\sigma^2_X}{\sigma^2_Y}f^{n_X-1}_{n_y-1,1-\alpha/2}\right)+F_{n_X-1,n_Y-1}\left(\frac{\sigma^2_X}{\sigma^2_Y}f^{n_X-1}_{n_y-1,\alpha/2}\right)
\end{align}

donde $F_{n_X-1,n_Y-1}(\cdot)$ denota la función de distribución de la distribución $F^{n_X-1}_{n_Y-1}$. Nótese que inicialmente la anterior función de potencia también es una función de dos argumentos que depende de $\sigma^2_X$ y $\sigma^2_Y$; sin embargo, $\beta(\sigma^2_X,\sigma^2_Y)$ depende de estos parámetros solo a través de la cociente $\sigma^2_X/\sigma^2_Y$, por lo tanto, graficamos esta función en función de $\sigma^2_X/\sigma^2_Y$.

\newpage

El siguiente código grafica $\beta(\sigma^2_X,\sigma^2_Y)$ para diferentes tamaños de muestra.

\begin{verbatim}
> pote_sigX_sigY<-function(cociente,nx,ny,alpha){
+ 1-pf(cociente*qf(1-alpha/2,nx-1,ny-1),nx-1,ny-1)+
+ pf(cociente*qf(alpha/2,nx-1,ny-1),nx-1,ny-1)
+ }
> alpha<-0.05
> n1<-10
> n2<-30
> n3<-50
>
> plot(function(x) pote_sigX_sigY(x,n3,n3,alpha),0,10,type="l",
+ xlab="sig_X/sig_Y",ylab="función de potencia")
> curve(pote_sigX_sigY(x,n2,n2,alpha),0,10,lty=2,add=T)
> curve(pote_sigX_sigY(x,n1,n1,alpha),0,10,lty=3,add=T)
> legend(6,0.4,c("nx=ny=10","nx=ny=30","nx=ny=50"),lty=c(3,2,1))
\end{verbatim}

En la Figura 4.20 se muestra esta función de potencia para diferentes tamaños de muestra con $n_X=n_Y$ y se observa un comportamiento similar a la función de potencia del sistema $H_0:\ \sigma^2=\sigma^2_0$ vs. $H_1:\ \sigma^2\neq\sigma^2_0$.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.6]{potencia_sigX_sigY.eps}
\caption[\textsl{Función de potencia (\ref{potencia_sigX_sigY})}]{\textsl{Función de potencia (\ref{potencia_sigX_sigY}) para diferentes tamaños de muestra con $\alpha=0.05$.}}
\end{figure}

\section{$k$ muestras}
Suponga que se dispone de $k$ muestras independientes, donde la $i$ ésima muestra de tamaño $n_i$ se denota por $X_1^i$, $\ldots$, $X_{n_i}^i$. Suponga además que las muestras provienen de distribución $N(\mu_i,\sigma^2_i)$ para $i=1,\ldots,k$.

\subsection{Igualdad de $k$ medias\index{Prueba de hipótesis!normal!igualdad de $k$ medias}}
El sistema de interés es
\begin{equation}\label{k_medias}
H_0:\ \mu_1=\ldots=\mu_k\ \ \ \ vs.\ \ \ \ H_1:\ \text{existen por lo menos dos medias diferentes}.
\end{equation}

Lo anterior es una generalización del problema de dos muestras estudiado anteriormente, donde se vio que dependiendo de las varianzas teóricas, la regla de decisión cambia según si éstas son conocidas o no. En el caso de $k$ muestras, hay $k$ varianzas teóricas, y puede haber un gran número de casos que dificultan el desarrollo teórico respectivo. Por esta razón, suponemos que las $k$ varianzas teóricas son iguales, esto es, $\sigma^2_1=\ldots=\sigma^2_k=\sigma^2$. Bajo este supuesto, la función de verosimilitud de las $k$ muestras está dada por
\begin{equation}\label{kmuestra_likelihood}
L(\mu_1,\ldots,\mu_k,\sigma^2)=(2\pi\sigma^2)^{-\sum_{i=1}^kn_i/2}\exp\left\{-\frac{1}{2\sigma^2}\left[\sum_{i=1}^{k}\sum_{j=1}^{n_i}(X_j^i-\mu_i)^2\right]\right\}
\end{equation}

Y desarrollamos la prueba de razón generalizada de verosimilitudes como sigue\index{Prueba! de razón generalizada de verosimilitudes!normal}.

En primer lugar, los estimadores de máxima verosimilitud de $\mu_1$, $\ldots$, $\mu_k$ y la varianza común $\sigma^2$ están dados por
\begin{equation}\label{mui_MV}
\hat{\mu}_{i,MV}=\bar{X}^i
\end{equation}

para $i=1,\ldots,k$, y
\begin{equation}\label{varianza_comun}
\hat{\sigma}^2_{MV}=\dfrac{n_1S^2_{1,n_1}+\ldots+n_kS^2_{k,n_k}}{n_1+\ldots+n_k}=\dfrac{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2}{\sum_{i=1}^kn_i}
\end{equation}

donde $\bar{X}^i$ y $S^2_{i,n_i}$ denotan el promedio muestral y la varianza muestral (dividiendo sobre $n_i$) de la $i$ ésima muestra.

\newpage

De esta forma, el numerador de la razón generalizada de verosimilitudes está dado por
\begin{equation*}
L(\hat{\mu}_{1,MV},\ldots,\hat{\mu}_{k,MV},\hat{\sigma}^2_{MV})=(2\pi\hat{\sigma}^2_{MV})^{-\sum_{i=1}^kn_i/2}\exp\left\{-\frac{\sum_{i=1}^kn_i}{2}\right\},
\end{equation*}

similar a la expresión (\ref{nume_lambda_dosmuestras}) obtenida para el caso de dos muestras.

Ahora, bajo $H_0$, las $k$ medias teóricas son iguales, y las $k$ muestras provienen de una misma distribución $N(\mu,\sigma^2)$. En este caso el estimador de máxima verosimilitud de la media común $\mu$ está dado por el promedio de las $k$ muestras, esto es,
\begin{equation}\label{mu_0_comun}
\hat{\mu}_{0,MV}=\dfrac{n_1\bar{X}^{1}+\ldots+n_k\bar{X}^{k}}{n_1+\ldots+n_k}=\dfrac{\sum_{i=1}^kn_i\bar{X}^i}{\sum_{i=1}^kn_i}=\dfrac{\sum_{i=1}^k\sum_{j=1}^{n_i}X_j^i}{\sum_{i=1}^kn_i},
\end{equation}

y el estimador de la varianza común $\sigma^2$ está dado por
\begin{equation}\label{sigma_0_comun}
\hat{\sigma}^2_{0,MV}=\dfrac{\sum_{i=1}^k\sum_{j=1}^{n_i}(X_j^i-\hat{\mu}_{0,MV})^2}{\sum_{i=1}^kn_i},
\end{equation}

De esta forma, el denominador de la razón generalizada de verosimilitudes está dado por
\begin{equation*}
L(\hat{\mu}_{MV},\hat{\sigma}^2_{0,MV})=(2\pi\hat{\sigma}^2_{0,MV})^{-\sum_{i=1}^kn_i/2}\exp\left\{-\frac{\sum_{i=1}^kn_i}{2}\right\}.
\end{equation*}

De esta forma, tenemos que la razón generalizada de verosimilitudes está dada por
\begin{equation*}
\lambda=\left(\dfrac{\hat{\sigma}^2_{MV}}{\hat{\sigma}^2_{0,MV}}\right)^{-\sum_{i=1}^kn_i/2}
\end{equation*}

y podemos concluir que se rechaza $H_0$ para valores grandes de la estadística $\frac{\hat{\sigma}^2_{0,MV}}{\hat{\sigma}^2_{MV}}$, con
\begin{align*}
\frac{\hat{\sigma}^2_{0,MV}}{\hat{\sigma}^2_{MV}}&=\frac{\sum_{i=1}^k\sum_{j=1}^{n_i}(X_j^i-\hat{\mu}_{0,MV})^2}{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2}\\
&=\frac{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2+\sum_{i=1}^kn_i(\bar{X}^i-\hat{\mu}_{0,MV})^2}{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2}\\
&=1+\frac{\sum_{i=1}^kn_i(\bar{X}^i-\hat{\mu}_{0,MV})^2}{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2}.
\end{align*}
Y podemos afirmar que se debe rechazar $H_0$ cuando
\begin{equation}\label{kmuestra_regla}
\frac{\sum_{i=1}^kn_i(\bar{X}^i-\hat{\mu}_{0,MV})^2}{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2}>K,
\end{equation}

para algún $K>0$. De nuevo, para encontrar el valor de $K$, se debe conocer la distribución de la estadística de prueba bajo la hipótesis nula. Para eso, en primer lugar tengamos en cuenta que la distribución de $\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2/\sigma^2$ es la distribución $\chi^2_{n_i-1}$, y usando la independencia de las $k$ muestras, se tiene que
\begin{equation}\label{kmuestra_estadistica1}
\sum_{i=1}^k\sum_{j=1}^{n_i}\frac{(X^i_j-\bar{X}^i)^2}{\sigma^2}\sim\chi^2_{\sum_{i=1}^kn_i-k}.
\end{equation}

Ahora, consideramos el numerador de la estadística de prueba en (\ref{kmuestra_regla}), tenemos que
\begin{align}\label{kmuestra_estadistica}
\sum_{i=1}^k\frac{n_i(\bar{X}^i-\mu)^2}{\sigma^2}&=\sum_{i=1}^{k}\frac{(\sqrt{n_i}\bar{X}^i-\sqrt{n_i}\hat{\mu}_{0,MV}+\sqrt{n_i}\hat{\mu}_{0,MV}-\sqrt{n_i}\mu)^2}{\sigma^2}\notag\\
&=\sum_{i=1}^k\frac{(\sqrt{n_i}\bar{X}^i-\sqrt{n_i}\hat{\mu}_{0,MV})^2}{\sigma^2}+\sum_{i=1}^k\frac{(\sqrt{n_i}\hat{\mu}_{0,MV}-\sqrt{n_i}\mu)^2}{\sigma^2}\notag\\
&=\sum_{i=1}^k\frac{(\sqrt{n_i}\bar{X}^i-\sqrt{n_i}\hat{\mu}_{0,MV})^2}{\sigma^2}+\frac{\sum_{i=1}^kn_i(\hat{\mu}_{0,MV}-\mu)^2}{\sigma^2}
\end{align}

Bajo la hipótesis nula, se tiene que $\bar{X}^i\sim N(\mu,\sigma^2/n_i)$, de donde se tiene que $n_i(\bar{X}^i-\mu)^2/\sigma^2\sim\chi^2_1$, y usando la independencia de las $k$ muestras, se tiene que bajo la hipótesis nula
\begin{equation*}
\sum_{i=1}^k\frac{n_i(\bar{X}^i-\mu)^2}{\sigma^2}\sim\chi^2_k.
\end{equation*}

Por otro lado, bajo $H_0$, $\hat{\mu}_{0,MV}$ es el promedio de las $k$ muestras provenientes de una distribución $N(\mu,\sigma^2)$, entonces se tiene que $\hat{\mu}_{0,MV}\sim N(\mu,\sigma^2/\sum_{i=1}^kn_i)$, entonces
\begin{equation}\label{chi_cuadrado_k}
\frac{\hat{\mu}_{0,MV}-\mu}{\sqrt{\dfrac{\sigma^2}{\sum_{i=1}^kn_i}}}\sim N(0,1),
\end{equation}

de donde
\begin{equation}\label{chi_cuadrado_1}
\frac{\sum_{i=1}^kn_i(\hat{\mu}_{0,MV}-\mu)^2}{\sigma^2}\sim\chi^2_1.
\end{equation}

Usando las distribuciones (\ref{chi_cuadrado_k}), (\ref{chi_cuadrado_1}), y la identidad (\ref{kmuestra_estadistica}), podemos concluir que bajo $H_0$,
\begin{equation}\label{kmuestra_estadistica2}
\sum_{i=1}^k\frac{(\sqrt{n_i}\bar{X}^i-\sqrt{n_i}\hat{\mu}_{0,MV})^2}{\sigma^2}=\sum_{i=1}^k\frac{n_i(\bar{X}^i-\hat{\mu}_{0,MV})^2}{\sigma^2}\sim\chi^2_{k-1}.
\end{equation}

Usando las distribuciones (\ref{kmuestra_estadistica1}) (\ref{kmuestra_estadistica2}) y la independencia de las dos estadísticas, se tiene que
\begin{equation*}
F=\frac{\sum_{i=1}^kn_i(\bar{X}^i-\hat{\mu}_{0,MV})^2/(k-1)}{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2/(\sum_{i=1}^kn_i-k)}\sim f^{k-1}_{\sum_{i=1}^kn_i-k}.
\end{equation*}

Ahora, retomando la regla de decisión encontrada anteriormente (\ref{kmuestra_regla}), usando nuevamente la definición del error tipo I, se tiene que $K=f^{k-1}_{\sum_{i=1}^kn_i-k,1-\alpha}$, y la regla de decisión finalmente está dada por\index{Regla de decisión!normal!igualdad de $k$ medias}
\begin{center}
Rechazar $H_0$ cuando
$F=\frac{\sum_{i=1}^kn_i(\bar{X}^i-\hat{\mu}_{0,MV})^2/(k-1)}{\sum_{i=1}^k\sum_{j=1}^{n_i}(X^i_j-\bar{X}^i)^2/(\sum_{i=1}^kn_i-k)}>f^{k-1}_{\sum_{i=1}^kn_i-k,1-\alpha}$.
\end{center}

Dada la anterior regla de decisión, el $p$-valor se calcula como $p-\text{valor}=Pr(F>v)$\index{$p$ valor!normal!igualdad de $k$ medias} donde $F\sim f^{k-1}_{\sum_{i=1}^kn_i-k}$ y $v$ denota el valor observado de la estadística $F$.

\begin{Eje}
Suponga que se quiere comparar tres marcas de carros con respecto al rendimiento en términos de la distancia recorrida por galón de tres marcas de automóviles en referencia a especificaciones similares bajo circunstancias similares con respecto a la carretera, clima y demás condiciones controlables por los técnicos y expertos automovilísticos. Los datos se muestran en la Tabla 4.2 y para ver si hay diferencia entre las tres marcas de automóviles, probamos el sistema $H_0:\ \mu_A=\mu_B=\mu_C$ frente a la alternativa de que por lo menos dos medias son diferentes. Las estimaciones de las desviaciones estándares son  2.3576, 1.663 y 3.466, respectivamente. Por ahora, asumimos que las varianzas teóricas son iguales, y más adelante comprabaremos la validez de este supuesto usando una prueba estadística.

\begin{table}[!htb]
\centering
\begin{tabular}{|c|c|}\hline
&Distancia recorrida (en Km) por galón\\\hline
Marca A&39.4, 41.1, 39.5, 40.0, 43.7, 46.0, 43.5, 42.1\\
Marca B& 42.7, 39.2, 41.2, 40.7, 37.4, 40.0, 40.7\\
Marca C&52.6, 49.4, 49.4, 46.4, 51.2, 49.2, 55.0, 53.6, 55.7, 57.4\\\hline
\end{tabular}
\caption[\textsl{Datos del Ejemplo 4.4.1}]{\textsl{Datos usados en el Ejemplo 4.4.1: kilometro recorrido por un galón de gasolina en tres marcas de automóviles.}}
\end{table}

Los siguientes comandos de R calculan el valor de estadística $F$, el percentil $f^{k-1}_{\sum_{i=1}^kn_i-k,1-\alpha}$  y el $p$-valor.
\begin{verbatim}
> A<-c(39.4, 41.1, 39.5, 40.0, 43.7, 46.0, 43.5, 42.1)
> B<-c(42.7, 39.2, 41.2, 40.7, 37.4, 40.0, 40.7)
> C<-c(52.6, 49.4, 49.4, 46.4, 51.2, 49.2, 55.0, 53.6, 55.7, 57.4)
> k<-3
> alpha<-0.05
> n1<-length(A)
> n2<-length(B)
> n3<-length(C)
> mu.comun<-mean(c(A,B,C))
> mu1<-mean(A)
> mu2<-mean(B)
> mu3<-mean(C)
> f1<-(n1*(mu1-mu.comun)^2+n2*(mu2-mu.comun)^2+n3*(mu3-mu.comun)^2)/(k-1)
> f2<-(var(A)*(n1-1)+var(B)*(n2-1)+var(C)*(n3-1))/(n1+n2+n3-k)
> estad<-f1/f2
> p.val<-pf(estad,k-1,n1+n2+n3-k,lower.tail=F)
> estad
[1] 48.10022
> qf(1-alpha,k-1,n1+n2+n3-k)
[1] 3.443357
> p.val
[1] 9.286228e-09
\end{verbatim}

Podemos ver que el $p$-valor es pequeño si utilizamos un nivel de significación del 5\%, de donde concluimos que el rendimiento de las tres marcas de carros no es igual. Pero eso no implica que las tres medias $\mu_A$, $\mu_B$ y $\mu_C$ son todas diferentes entre ellos, sino que por lo menos hay una media diferente. Entonces para detectar cuál marca de automóviles tine un rendimiento sustancialmente diferente, debemos probar por separado las hipótesis $\mu_A=\mu_B$, $\mu_A=\mu_C$ y $\mu_B=\mu_C$. Para eso, usamos \verb"t.test" para cada una de estas hipótesis. Los resultados se encuentran en la Tabla 4.3, y allí observamos que las marcas A y B tienen rendimientos similares, mientras que la marca C es muy diferente de las marcas A y B.

\begin{table}[!htb]
\centering
\begin{tabular}{|c|c|c|c|c|}\hline
Hipótesis&\multicolumn{2}{|c|}{Estimaciones}&Estadística&$p$-valor\\\hline
$\mu_A=\mu_B$&$\hat{\mu}_A= 41.91$&$\hat{\mu}_B=40.27$&1.5346& 0.1489\\
$\mu_A=\mu_C$&$\hat{\mu}_A= 41.91$&$\hat{\mu}_C=51.99$&-7.0082&2.953e-06\\
$\mu_B=\mu_C$&$\hat{\mu}_B= 40.27$&$\hat{\mu}_C=51.99$&-8.2465&5.914e-07\\\hline
\end{tabular}
\caption{\textsl{Prueba de igualdad de dos medias del Ejemplo 4.4.1.}}
\end{table}

\end{Eje}

\subsection{Igualdad de varianzas\index{Prueba de hipótesis!normal!igualdad de $k$ varianzas}}
El sistema de interés es
\begin{equation}\label{k_varianzas}
H_0:\ \sigma^2_1=\ \cdots\ =\sigma^2_k\ \ \ \ vs.\ \ \ \ H_1:\ \text{existen por lo menos dos varianzas diferentes}.
\end{equation}

Nuevamente, hacemos uso de la prueba de la razón generalizada de verosimilitudes. La función de verosimilitud de las $k$ muestras está dada por (\ref{kmuestra_likelihood}). Bajo la hipótesis nula, $\sigma^2_1=\ldots=\sigma^2_k=\sigma^2$, se ha visto anteriormente que los estimadores de máxima verosimilitud de $\sigma^2$, $\mu_1$, $\ldots$, $\mu_k$ están dados por (\ref{mui_MV}) y (\ref{varianza_comun}). Por otro lado, los estimadores de máxima verosimilitud de $\mu_i$ y $\sigma^2_i$ están dados por las respectivas medias y varianzas muestrales (dividiendo por $n_i-1$) de la $i$-ésima muestra para $i=1,\ldots,k$. De esta forma, la razón generalizada de verosimilitudes\index{Prueba! de razón generalizada de verosimilitudes!normal} está dada por
\begin{equation*}
\lambda=\frac{\prod_{i=1}^n(\hat{\sigma}^2_{i,MV})^{-n_i/2}}{(\hat{\sigma}^2_{MV})^{-\sum_{i=1}^kn_i/2}},
\end{equation*}

y se tiene que bajo $H_0$, $2\ln\lambda$ se distribuye aproximadamente como $\chi^2_{k-1}$ \cite[p. 394]{Bickel}. Y por consiguiente, se rechaza $H_0$ cuando\index{Regla de decisión!normal!igualdad de $k$ varianzas} $\sum_{i=1}^kn_i\ln\hat{\sigma}^2_{MV}-\sum_{i=1}^kn_i\ln\hat{\sigma}^2_{i,MV}>\chi^2_{k-1,1-\alpha}$.

\index{Prueba!de Bartlett}\citeasnoun{Bartlett} hizo una modificación a la anterior estadística de prueba con el fin de que la distribución de la estadística de prueba se acercara más a la distribución $\chi^2_{k-1}$. La modificación de Bartlett consiste en reemplazar los estimadores de máxima verosimilitud por los estimadores insesgados, reemplazar $n_i$ por $n_i-1$ y dividir la estadística por la constante $c$ dada por
\begin{equation*}
c=1+\left(\frac{1}{3(k-1)}\right)\left(\sum_{i=1}^k\frac{1}{n_i-1}-\frac{1}{\sum_{i=1}^kn_i-k}\right).
\end{equation*}

La estadística de prueba queda entonces expresada como
\begin{equation*}
A=\frac{1}{c}\left\{(\sum_{i=1}^kn_i-k)\ln S^2-\sum_{i=1}^k(n_i-1)\ln S^2_i\right\}
\end{equation*}

donde $S^2_i$ es el estimador insesgado de $\sigma^2_i$ en la $i$-ésima muestra, y $S^2=\sum_{i=1}^k(n_i-1)S^2_i/(\sum_{i=1}^kn_i-k)$. Y se rechaza $H_0$ cuando $A>\chi^2_{k-1,1-\alpha}$.\index{Regla de decisión!normal!igualdad de $k$ varianzas}

\begin{Eje}
En el Ejemplo 4.4.1 se probó la hipótesis de igualdad de tres medias teóricas para comparar tres marcas de automóviles en términos de la distancia recorrida por un galón de gasolina. En ese ejemplo se hizo la suposición de que las tres varianzas teóricas son iguales. A continuación, verificamos la validez de este supuesto usando la teoría desarrollada anteriormente y el siguiente código.

\begin{verbatim}
> A<-c(39.4, 41.1, 39.5, 40.0, 43.7, 46.0, 43.5, 42.1)
> B<-c(42.7, 39.2, 41.2, 40.7, 37.4, 40.0, 40.7)
> C<-c(52.6, 49.4, 49.4, 46.4, 51.2, 49.2, 55.0, 53.6, 55.7, 57.4)
> k<-3
> alpha<-0.05
> n1<-length(A)
> n2<-length(B)
> n3<-length(C)
> S1<-var(A)
> S2<-var(B)
> S3<-var(C)
> S<-(S1*(n1-1)+S2*(n2-1)+S3*(n3-1))/(n1+n2+n3-k)
>
> cons.c<-1+(1/(n1-1)+1/(n2-1)+1/(n3-1)-1/(n1+n2+n3-k))/(3*(k-1))
> estad<-(log(S)*(n1+n2+n3-k)-(n1-1)*log(S1)-(n2-1)*log(S2)-
+ (n3-1)*log(S3))/cons.c
> p.val<-pchisq(estad,k-1,lower.tail=F)
> estad
[1] 3.443527
> qchisq(1-alpha,k-1)
[1] 5.991465
> p.val
[1] 0.1787507
\end{verbatim}

De donde vemos que $p$-valor sugiere que el supuesto de igualdad de varianzas es adecuado con base en los datos observados. Esta anterior prueba también se puede llevar a cabo usando la función \verb"bartlett.test", pero se debe crear un vector de indicadores para etiquetar cada dato según a qué marca corresponde. El uso de esta función se ilustra a continuación.

\begin{verbatim}
> ind<-c(rep("A",n1),rep("B",n2),rep("C",n3))
> ind
 [1] "A" "A" "A" "A" "A" "A" "A" "A" "B" "B" "B" "B" "B"
[14] "B" "B" "C" "C" "C" "C" "C" "C" "C" "C" "C" "C"
> dato<-c(A,B,C)
> bartlett.test(dato,ind)

        Bartlett test of homogeneity of variances

data:  dato and ind
Bartlett's K-squared = 3.4435, df = 2, p-value = 0.1788
\end{verbatim}
\end{Eje}

\section{Muestras provenientes de la distribución Ber\-nou\-lli y binomial\index{Prueba de hipótesis!Bernoulli}}
\subsection{Una muestra}
\index{Prueba de hipótesis!Bernoulli!una muestra}Suponga que la muestra aleatoria $X_1$, $\ldots$, $X_n$ constituye una muestra aleatoria proveniente de la distribución Bernoulli con probabilidad de éxito $p$. Esta distribución es muy útil en ciencias como la medicina donde $p$ puede ser como probabilidad de contagiar alguna enfermedad, o probabilidad de éxito en cirugías complicadas como por ejemplo, trasplante de corazón; también en la investigación de mercados, para estudiar la preferencia de los clientes entre dos marcas.

En general, planteamos el sistema de hipótesis acerca de la probabilidad $p$
\begin{equation}\label{binom_igual_diferen}
H_0:\ p=p_0\ \ \ \ vs.\ \ \ \ H_1:\ p\neq p_0,
\end{equation}

Una de las prueba más sencillas hace uso del teorema límite central, que en el caso de una variable $X$ con distribución $Bin(n,p)$, se tiene que
\begin{equation*}
Z=\frac{X-np_0}{\sqrt{np_0(1-p_0)}}\rightarrow_{D}N(0,1),
\end{equation*}

de donde
\begin{equation*}
Z^2=\frac{(X-np_0)^2}{np_0(1-p_0)}\sim_{aprox}\chi^2_{1},
\end{equation*}

\index{Regla de decisión!Bernoulli!una muestra}\index{$p$ valor!Bernoulli!una muestra}bajo la hipótesis $H_0:\ p=p_0$. Podemos ver que la estadística $Z^2$ mide la <<diferencia>> entre la variable $X$ y su esperanza bajo $H_0$. De esta forma, un valor grande de $Z^2$ indica que $X$ está muy lejos de su esperanza suponiendo $H_0$ cierta, y esto nos conduce a la decisión de rechazar $H_0$. Dado lo anterior, podemos rechazar $H_0$ si el valor de $Z^2$ es mayor que el percentil $\chi^2_{1,1-\alpha}$, y el $p$-valor se puede calcular como $Pr(Z^2>v)$ donde $v$ es el valor observado de la estadística $Z^2$.

\begin{Eje}
Suponga que se quiere conocer la probabilidad de que una clienta prefiera la marca de shampoo <<LIZ>> ante otras marcas de shampoo. Si en 30 clientas que compraron shampoo, 7 compraron la marca <<LIZ>>, entonces qué podemos concluir acerca de la sospecha de que la probabilidad de que una clienta prefiera la marca de shampoo <<LIZ>> sea de 0.5. En este caso nuestro sistema de interés es $H_0:\ p=0.5$ vs. $H_1:\ p\neq0.5$. El cómputo de la estadística $Z^2$ y el $p$ valor se puede calcular como
\begin{verbatim}
> x<-7
> n<-30
> alpha<-0.05
> Z2<-(x-n*p)^2/(n*p*(1-p))
> Z2
[1] 8.533333
> p.val<-pchisq( 8.533333,1,lower.tail=F)
> p.val
[1] 0.003487006
\end{verbatim}

De donde observamos que el $p$ valor es muy pequeño, indicando que los datos sugieren que 0.5 no es un valor aceptable para la probabilidad $p$. El anterior cálculo también se puede realizar usando la instrucción \verb"prop.test" de la siguiente forma. Nótese que el valor de la estadística y el $p$ valor coinciden con los obtenidos anteriormente. Sin embargo, la instrucción \verb"prop.test" nos provee una estimación por intervalo de confianza.

\begin{verbatim}
> prop.test(7,30,0.5,correct=F)

        1-sample proportions test without continuity correction

data:  7 out of 30, null probability 0.5
X-squared = 8.5333, df = 1, p-value = 0.003487
alternative hypothesis: true p is not equal to 0.5
95 percent confidence interval:
 0.1179239 0.4092833
sample estimates:
        p
0.2333333
\end{verbatim}
\end{Eje}

En el anterior ejemplo cuando se utilizó la función \verb"prop.test" se agregó la opción de \verb"correct=F"; al no poner esta opción, se agrega \index{Corrección de continuidad}la corrección de continuidad de Yates, debido a que al utilizar el teorema límite central, estamos aproximando una distribución discreta con una distribución normal. Con esta corrección de continuidad, la estadística de prueba se calcula como
\begin{equation*}
Z^2_{c}=
\begin{cases}
\dfrac{(X-np_0)^2}{np_0(1-p_0)}&\text{si $x=np_0$}\\
\dfrac{(X-0.5-np_0)^2}{np_0(1-p_0)}&\text{si $x>np_0$}\\
\dfrac{(X+0.5-np_0)^2}{np_0(1-p_0)}&\text{si $x<np_0$}\\
\end{cases}
\end{equation*}

Podemos ver que la corrección de continuidad de Yates consiste en acercar el valor observado $x$ 0.5 unidad hacia el valor esperado bajo la hipótesis nula $np_0$, en caso de que $x$ difiera de éste. Con esta corrección, podemos ver que, excepto $x=np_0$, el valor de $Z^2_c$ siempre será menor que el de $Z^2$, y como se rechaza $H_0$ para valores grandes de estas estadísticas, podemos afirmar que al utilizar la corrección de Yates es más difícil rechazar $H_0$, es decir, se requieren evidencias realmente fuertes en los datos para poder rechazar $H_0$. Si aplicamos esta corrección de continuidad a los datos del Ejemplo 4.5.1, tenemos que

\begin{verbatim}
> prop.test(7,30,0.5)

        1-sample proportions test with continuity correction

data:  7 out of 30, null probability 0.5
X-squared = 7.5, df = 1, p-value = 0.00617
alternative hypothesis: true p is not equal to 0.5
95 percent confidence interval:
 0.1063502 0.4270023
sample estimates:
        p
0.2333333
\end{verbatim}

Podemos ver que efectivamente la estadística de prueba ahora es más pequeña, además el intervalo de confianza ahora es más ancho, de donde también podemos ver que con la corrección de continuidad es más fácil aceptar $H_0$.

\index{Prueba de hipótesis!Bernoulli!una muestra}\index{Prueba!binomial}Otra prueba para el sistema (\ref{binom_igual_diferen}) es utilizar directamente la distribución de la variable $X$ y no recurrir a aproximaciones como el teorema límite central. Sin embargo, el desarrollo de esta prueba es más fácil de entender partiendo desde el punto de vista del $p$ valor que iniciando una búsqueda de una regla de decisión. Ilustramos este proceso dentro del contexto del Ejemplo 4.5.1.

Un razonamiento natural es calcular la estimación de esta probabilidad que en este caso es $\hat{p}=7/30=0.233$ que es diferente del valor 0.7. Sin embargo, una variable con distribución $Bin(30,0.5)$ también puede tomar valor de 7, que fue lo observado en la muestra, en vez de tomar el valor esperado $30*0.5=15$. ¿Pero qué tan probable es que eso ocurra? Si $X\sim Bin(30,0.5)$, entonces podemos calcular la probabilidad de que el valor de $X$ difiera de su valor esperado por lo menos $15-7=8$, esto es
\begin{align*}
Pr(|X-15|\geq8)&=Pr(X\geq23)+Pr(X\leq7)\\
&=0.005222879,
\end{align*}

lo cual es una probabilidad bastante pequeña, indicando que si $p=0.5$, es muy improbable observar $X=7$ en la muestra. Lo anterior calcula realmente la probabilidad de que se observen valores más extremos que el observado, y esta es precisamente la definición o la interpretación que se da al $p$-valor, y usando el $p$-valor podemos tomar una decisión acerca de $p=p_0$. Este proceso se conoce como la prueba binomial exacta y en R se lleva a cabo usando el comando \verb"binom.test". Para los datos de preferencia del shampoo <<LIZ>>, la instrucción y el correspondiente resultado es:

\begin{verbatim}
> binom.test(7,30,0.5)

        Exact binomial test

data:  7 and 30
number of successes = 7, number of trials = 30, p-value = 0.005223
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.09933786 0.42283652
sample estimates:
probability of success
             0.2333333
\end{verbatim}

El $p$-valor calculado en R es 0.005223, y podemos ver que es el mismo resultado obtenido anteriormente calculando a mano.

Ahora, generalizamos la forma de calcular el $p$ valor para el sistema de hipótesis (\ref{binom_igual_diferen}). Suponga que se observa la realización $x$ de una variable aleatoria $X$ con distribución $Bin(n,p)$. Según la ilustración al principio del capítulo, el $p$ valor se calcula como la probabilidad de que la variable $X$ se difiera de su esperanza bajo $H_0$ por más de la diferencia observada en la muestra. Recordando que la esperanza de $X$ bajo $H_0$ es $np_0$, tenemos que\index{$p$ valor!Bernoulli!una muestra}\index{$p$ valor!prueba binomial}
\begin{align*}
p-\text{valor}=Pr(|X-np_0|\geq|np_0-x|)=
\begin{cases}
Pr(|X-np_0|\geq np_0-x)&\text{si $np_0>x$}\\
Pr(|X-np_0|\geq x-np_0)&\text{si $np_0<x$}\\
1&\text{si $np_0=x$}
\end{cases}
\end{align*}

De allí, el $p$ valor se calcula según los siguientes casos
\begin{itemize}
  \item Si $np_0>x$, entonces
        \begin{align*}
        p-\text{valor}&=Pr(|X-np_0|\geq np_0-x)\\
                    &=Pr(X-np_0\geq np_0-x)+Pr(X-np_0\leq x-np_0)\\
                    &=Pr(X\geq2np_0-x)+Pr(X\leq x)\\
                    &=1-Pr(X<2np_0-x)+Pr(X\leq x)
        \end{align*}
        donde $[\cdot]$ denota el operador parte entera. Podemos calcular este $p$ valor en R como \verb"1-pbinom(ceiling(2*n*p0-x)-1,n,p0)+pbinom(x,n,p0)"
  \item Si $np_0<x$, entonces
        \begin{align*}
        p-\text{valor}&=Pr(|X-np_0|\geq x-np_0)\\
                    &=Pr(X-np_0\geq x-np_0)+Pr(X-np_0\leq np_0-x)\\
                    &=Pr(X\geq x)+Pr(X\leq 2np_0-x)\\
                    &=1-Pr(X<x)+Pr(X\leq 2np_0-x)\\
                    &=1-Pr(X\leq x-1)+Pr(X\leq 2np_0-x)
        \end{align*}
        donde $[\cdot]$ denota el operador parte entera. Podemos calcular este $p$ valor en R como \verb"1-pbinom(x-1,n,p0)+pbinom(2*n*p0-x,n,p0)"
  \item Si $np_0=x$, entonces claramente $p-\text{valor}=Pr(|X-np_0|\geq0)=1$. Obsérvese que de allí, cuando la estimación puntual de $p$ dé igual al valor especificado de $H_0$, se acepta $H_0$, lo cual es muy lógico.
\end{itemize}

Para sistemas de tipo
\begin{equation*}
H_0:\ p=p_0\ \ \ \ vs.\ \ \ \ H_1:\ p> p_0,
\end{equation*}

o
\begin{equation*}
H_0:\ p\leq p_0\ \ \ \ vs.\ \ \ \ H_1:\ p> p_0.
\end{equation*}

Es claro que se rechaza $H_0$ para valores grandes de la estadística $X$, y por consiguiente podemos calcular el $p$ valor como $Pr(X\geq x)$ bajo $H_0$, es decir, con $X\sim Binom(n,p_0)$. También se puede emplear la función \verb"binom.test" con la opción \verb"greater".

Por otro lado, para sistemas como
\begin{equation}\label{k_varianzas}
H_0:\ p=p_0\ \ \ \ vs.\ \ \ \ H_1:\ p< p_0,
\end{equation}

o
\begin{equation}\label{k_varianzas}
H_0:\ p\geq p_0\ \ \ \ vs.\ \ \ \ H_1:\ p< p_0,
\end{equation}

Se rechaza $H_0$ para valores pequeños de $X$, y el $p$ valor se calcula como $Pr(X\leq x)$ con $X\sim Binom(n,p_0)$. En R se debe utilizar la opción \verb"less" en la función \verb"binom.test".

\begin{Eje}
Suponga que con las nuevas tecnologías en la ciencia médica se cree que la probabilidad de éxito de una cirugía de trasplante de corazón es mayor a 0.7 y suponga que en 15 cirugías de este tipo 11 fueron exitosas. Para ver qué tan acorde es esta hipótesis con los datos observados, tenemos el sistema
\begin{equation}\label{k_varianzas}
H_0:\ p\geq 0.7\ \ \ \ vs.\ \ \ \ H_1:\ p< 0.7,
\end{equation}

Al utilizar el comando \verb"binom.test", tenemos que
\begin{verbatim}
> binom.test(11,15,0.7,"less")

        Exact binomial test

data:  11 and 15
number of successes = 11, number of trials = 15, p-value = 0.7031
alternative hypothesis: true probability of success is less than 0.7
95 percent confidence interval:
 0.0000000 0.9033417
sample estimates:
probability of success
             0.7333333
\end{verbatim}

Del anterior resultado, observamos que la estimación muestral es $11/15=0.73$, y el $p$-valor es de 0.70 indicando que los datos están acordes con la hipótesis de $p\geq0.7$.
\end{Eje}

Otra prueba que podemos derivar para el sistema (\ref{binom_igual_diferen}) es la prueba de razón generalizada de \index{Prueba!de razón generalizada de verosimilitudes!Bernoulli} verosimilitudes donde teniendo en cuenta que en el sistema (\ref{binom_igual_diferen}) $\bTheta_0\bigcup\bTheta_1=\bTheta$ la estadística $\lambda$ se calcula como
\begin{equation*}
\lambda=\frac{L(\hat{p}_{MV})}{L(p_0)}=\dfrac{\bar{x}^{\sum_{i=1}^nx_i}(1-\bar{x}^{n-\sum_{i=1}^nx_i})}{p_0^{\sum_{i=1}^nx_i}(1-p_0^{n-\sum_{i=1}^nx_i})}
\end{equation*}

De acuerdo al razonamiento de la prueba de razón de verosimilitud, se rechaza $H_0$ para valores grandes de $\lambda$ y para establecer una regla de decisión explícita, se necesita la distribución nula de $\lambda$ y por la forma de la anterior expresión, encontrar su distribución nula puede ser muy difícil. Sin embargo, existe un resultado asintótico muy poderoso con respecto a la distribución nula de $2\ln\lambda$ que lo enunciamos a continuación, y lo vamos a utilizar en adelante en repetidas ocasiones\index{Prueba!de razón de verosimilitud!distribución asintótica}\index{Prueba!de razón generalizada de verosimilitudes!distribución asintótica}.

\begin{Res}
Sea $X_1$, $\cdots$, $X_n$ una muestra aleatoria con función de densidad $f(x_i,\theta)$, para el sistema de hipótesis $H_0:\ \theta\in\bTheta_0$ vs. $H_1:\ \theta\notin\bTheta_0$, la estadística $2\ln\lambda$ converge a una distribución $\chi^2_{v_1-v_0}$ bajo $H_0$, donde $v_0$ y $v_1$ son números de parámetros libres en los espacios $\bTheta_0$ y $\bTheta$, respectivamente.
\end{Res}

Utilizando el anterior resultado, tenemos que
\begin{align*}
2\ln\lambda&=2\left(\sum_{i=1}^nx_i\ln\bar{x}+(n-\sum_{i=1}^nx_i)\ln(1-\bar{x})-\sum_{i=1}^nx_i\ln p_0-(n-\sum_{i=1}^nx_i)\ln(1-p_0)\right)\\
&=2\left(\sum_{i=1}^nx_i\ln\frac{\bar{x}}{p_0}+(n-\sum_{i=1}^nx_i)\ln\frac{1-\bar{x}}{1-p_0}\right).
\end{align*}

Teniendo en cuenta que bajo $H_0$, $2\ln\lambda$ se distribuye como $\chi^2_{v_1-v_0}$ que en el caso del sistema (\ref{binom_igual_diferen}), tenemos que $v_1=1$ y $v_0=0$, y de esta forma $2\ln\lambda\sim_{asym}\chi^2_1$. Y la regla de \index{Regla de decisión!Bernoulli!una muestra}decisión será rechazar $H_0$ si $2\ln\lambda>\chi^2_{1,1-\alpha}$ y teniendo en cuenta esta regla de decisión, el $p$-valor\index{$p$ valor!Bernoulli!una muestra} se puede calcular como $1-F_{\chi^2_{1}}(v)$ donde $v$ denota el valor observado de la estadística $2\ln\lambda$.

\begin{Eje}
Para los datos del Ejemplo 4.5.1 acerca de preferencia de una marca de shampoo, podemos utilizar la siguiente función en R para calcular la estimación puntual, el valor de la estadística $2\ln\lambda$ y el correspondiente $p$-valor.

\begin{verbatim}
> binom<-function(n,x,p0){
+ estimacion<-x/n
+ estad<-2*(x*log(estimacion/p0)+(n-x)*log((1-estimacion)/(1-p0)))
+ p.val<-pchisq(estad,1,lower.tail=F)
+ list(estimacion=estimacion,estadistica=estad,p.val=p.val)
+ }
>
> binom(30,7,0.5)
$estimacion
[1] 0.2333333

$estadistica
[1] 8.992464

$p.val
[1] 0.002710952
\end{verbatim}

Podemos ver que el $p$-valor es bastante pequeño, indicando que $H_0$ no es una hipótesis adecuada de acuerdo con los datos observados, lo cual coincide con los resultados obtenidos con las pruebas anteriores.
\end{Eje}


Finalmente, realizamos un estudio de simulación para comparar las tres pruebas mencionadas anteriormente, con el fin de examinar qué tan buenas son estas tres pruebas y así aceptar una hipótesis nula verdadera y rechazar una hipótesis falsa. Simulamos 10000 muestras provenientes de una distribución $Bin(n,p_0)$ para diferentes valores de $n=5,15,30,50,100$ y $p=0.1,0.3,0.5,0.7,0.9$. En cada muestra simulada se aplican las tres pruebas para la hipótesis $p=p_0$, y se calcula el tamaño de cada prueba como el número de veces que se rechaza $p=p_0$ dividido por 10000. Los resultados se muestran en la Tabla 4.4.

\newpage

\begin{table}[!htb]\label{ab}
\centering
\begin{tabular}{|c|ccccc|}\hline
        &\multicolumn{5}{|c|}{Prueba asintótica normal sin corrección}\\\hline
        &$n=5$&$n=15$&$n=30$&$n=50$&$n=100$\\\hline
$p_0=0.1$ &0.0827&0.0530  & 0.0265 & 0.0310  & 0.0642 \\
$p_0=0.3$ &0.0313&0.0865  & 0.0696 & 0.0439  & 0.0669 \\
$p_0=0.5$ &0.0618&0.0331  & 0.0401 & 0.0666  & 0.0599 \\
$p_0=0.7$ &0.0331&0.0849  & 0.0683 & 0.0429  & 0.0625 \\
$p_0=0.9$ &0.0793&0.0519  & 0.0248 & 0.0278  & 0.0636 \\\hline
&\multicolumn{5}{|c|}{Prueba asintótica normal con corrección}   \\\hline
 $p_0=0.1$  & 0.0072   & 0.0128 & 0.0265 & 0.0310   &  0.0284 \\
 $p_0=0.3$  & 0.0018   & 0.0196 & 0.0255 & 0.0439   &  0.0391 \\
 $p_0=0.5$  & 0.0000   & 0.0331 & 0.0401 & 0.0318   &  0.0361 \\
 $p_0=0.7$  & 0.0027   & 0.0224 & 0.0274 & 0.0429   &  0.0380 \\
 $p_0=0.9$  & 0.0081   & 0.0128 & 0.0248 & 0.0278   &  0.0270 \\ \hline
&\multicolumn{5}{|c|}{Prueba exacta binomial}   \\\hline
 $p_0=0.1$  & 0.0072  & 0.0128 & 0.0265 & 0.0310   &  0.0443 \\
 $p_0=0.3$  & 0.0313  & 0.0196 & 0.0462 & 0.0439   &  0.0522 \\
 $p_0=0.5$  & 0.0000  & 0.0331 & 0.0401 & 0.0318   &  0.0361 \\
 $p_0=0.7$  & 0.0331  & 0.0224 & 0.0468 & 0.0429   &  0.0500 \\
 $p_0=0.9$  & 0.0081  & 0.0128 & 0.0248 & 0.0278   &  0.0435 \\ \hline
\end{tabular}\caption[\textsl{Tamaños de pruebas bajo distribución binomial}]{\textsl{Comparación de tamaños de prueba para la prueba exacta binomial, la prueba asintótica
  normal sin corrección y la prueba asintótica normal con corrección bajo una distribución binomial.}}
\end{table}

\begin{table}[!htb]
\centering
\begin{tabular}{|c|ccccc|}\hline
&\multicolumn{5}{|c|}{Prueba asintótica normal sin corrección}\\\hline
&$n=5$&$n=15$&$n=30$&$n=50$&$n=100$\\\hline
$p=0.1$  &0.5926& 0.9470  & 0.9995  & 1.0000 & 1.0000  \\
$p=0.3$  &0.1710& 0.2902  & 0.5873  & 0.8608 & 0.9876  \\
$p=0.7$  &0.1739& 0.2984  & 0.5905  & 0.8591 & 0.9881  \\
$p=0.9$  &0.5949& 0.9454  & 0.9995  & 1.0000 & 1.0000  \\\hline
&\multicolumn{5}{|c|}{Prueba asintótica normal con corrección}   \\\hline
 $p=0.1$  & 0  & 0.9470& 0.9995&  1.0000 &  1.0000    \\
 $p=0.3$  & 0  & 0.2902& 0.5873&  0.7842 &  0.9789    \\
 $p=0.7$  & 0  & 0.2984& 0.5905&  0.7822 &  0.9797    \\
 $p=0.9$  & 0  & 0.9454& 0.9995&  1.0000 &  1.0000    \\ \hline
&\multicolumn{5}{|c|}{Prueba exacta binomial}   \\\hline
 $p=0.1$  &0   &0.9470 &0.9995 & 1.0000  &   1.0000   \\
 $p=0.3$  &0   &0.2902 &0.5873 & 0.7842  &   0.9789   \\
 $p=0.7$  &0   &0.2984 &0.5905 & 0.7822  &   0.9797   \\
 $p=0.9$  &0   &0.9454 &0.9995 & 1.0000  &   1.0000   \\ \hline
  \end{tabular}\caption[\textsl{Potencia de pruebas bajo distribución binomial}]{\textsl{Comparación de potencia de prueba para la prueba exacta binomial, la prueba asintótica normal sin corrección y la prueba asintótica normal con corrección bajo una distribución binomial.}}
\end{table}

\newpage

Podemos ver que tal como se comentó anteriormente, la prueba normal con corrección tiende a aceptar más fácil $H_0$, por consiguiente siempre tiene un tamaño menor que la prueba normal sin corrección. Por otro lado, no parece haber una diferencia marcada entre la prueba binomial y las pruebas asintóticas normales.

Con respecto a la potencia de estas pruebas, simulamos 10000 muestras de una distribución $Bin(n,p)$ con $p=0.1,0.3,0.7,0.9$ y en cada muestra se aplican las tres pruebas para el hipótesis $p=0.5$ el cual no corresponde al valor teórico de $p$. Estimamos la potencia de estas tres pruebas como el número de veces que se rechaza $p=0.5$ dividido por 10000, y los resultados se muestran en la Tabla 4.5.

Asimismo, es posible observar que en muestras pequeñas con $n=5$, la prueba normal con corrección y la prueba binomial tienen potencia igual a 0, es decir, en ninguna de las 10000 muestras simuladas, se llegó a rechazar la hipótesis nula $p=0.5$, mientras que la prueba normal sin corrección tiene una potencia significativamente mayor. En muestras más grandes la potencia de estas tres pruebas puede coincidir, aunque la prueba normal sin corrección siempre tuvo una potencia mayor o igual que las otras dos pruebas. De donde podemos concluir que estas simulaciones mostraron que la prueba normal sin corrección es mejor que las otras dos.

\subsection{Dos muestras\index{Prueba de hipótesis!Bernoulli}\index{Prueba de hipótesis!Bernoulli!dos muestras}}
En esta parte, consideramos el problema de comparar dos muestras Bernoulli en términos de las probabilidades de éxito, o equivalentemente, tenemos $X$ que denota el número de éxitos en $n_X$ ensayos donde cada ensayo tiene como probabilidad de éxito $p_1$ y $Y$ el número de éxitos en $n_Y$ ensayos con $p_2$ denotando la probabilidad de éxito en esta población. Ejemplo de ello es la probabilidad de que un cliente compre una determinada marca de arroz con el empaque actual y la probabilidad de que un cliente compre esta marca de arroz con un nuevo empaque; también en la medicina, la probabilidad de cura de una enfermedad con el medicamento A y la misma probabilidad de cura con el medicamento B. En estos casos, el sistema de hipótesis de interés puede ser
\begin{equation}\label{binom_dos_muestras}
H_0:\ p_1=p_2\ \ \ \ vs.\ \ \ \ H_1:\ p_1\neq p_2,
\end{equation}

En primer lugar, es claro que los parámetros $p_1$ y $p_2$ se pueden estimar con los porcentajes de éxito en las dos muestras, esto es, $\hat{p}_1=X/n_X$ y $\hat{p}_2=Y/n_Y$. Para encontrar una regla de decisión para el sistema (\ref{binom_dos_muestras}), un primer acercamiento es utilizar el teorema de límite central, en el tema de intervalo de confianza para la diferencia de dos proporciones se había hecho uso de este teorema, y se encontró que
\begin{equation*}
\hat{p}_1-\hat{p}_2\sim_{aprox}N\left(p_1-p_2,\frac{p_1(1-p_1)}{n_X}+\frac{p_2(1-p_2)}{n_Y}\right)
\end{equation*}

cuya distribución nula bajo $H_0:\ p_1=p_2=p$ es
\begin{equation*}
\hat{p}_1-\hat{p}_2\sim_{aprox}N\left(0,p(1-p)\left(\frac{1}{n_X}+\frac{1}{n_Y}\right)\right)
\end{equation*}

de donde
\begin{equation*}
\frac{(\hat{p}_1-\hat{p}_2)^2}{p(1-p)\left(\frac{1}{n_X}+\frac{1}{n_Y}\right)}\sim_{aprox}\chi^2_1
\end{equation*}

En la anterior expresión, la probabilidad común $p$ no es conocida, por consiguiente, para establecer una regla de decisión usando la anterior estadística, se debe obtener un estimador de $p$. Se deja como ejercicio verificar que el estimador de máxima verosimilitud de esta probabilidad común $p$ es (Ejercicio 4.15)
\begin{equation}\label{binom_p_comun_MV}
\hat{p}_{MV}=\frac{X+Y}{n_X+n_Y}.
\end{equation}

De esta forma, comparamos\index{Regla de decisión!Bernoulli!dos muestras} el valor de la estadística
\begin{equation*}
Z^2=\frac{(\hat{p}_1-\hat{p}_2)^2}{\hat{p}_{MV}(1-\hat{p}_{MV})\left(\frac{1}{n_X}+\frac{1}{n_Y}\right)}
\end{equation*}

con el percentil $\chi^2_{1,1-\alpha}$ para tomar una decisión para el sistema (\ref{binom_dos_muestras}) con un nivel de significación de $\alpha$. Y el $p$-valor\index{$p$ valor!Bernoulli!dos muestras} de esta prueba se calcula como $p-\text{valor}=Pr(Z^2>v)$ donde $Z^2\sim\chi^2_1$ y $v$ denota el valor observado de la estadística $Z^2$.

En R, la prueba anterior se lleva a cabo mediante el comando \verb"prop.test" que nos fue útil para el problema de una muestra. En \citeasnoun{Racismo}, se planteó un problema de prueba de cambio de empaque en la investigación de mercados, lo presentamos a continuación.

\begin{Eje}
Supongamos que una empresa desea cambiar el empaque y la forma de presentación de un producto particular que está regularmente posicionado en el mercado. Para evaluar el impacto de la nueva presentación en la intención de compra del producto, el gerente de marketing planea una prueba de empaque por medio de la recolección de información en una sesión de grupo (focus group). La prueba fue realizada en 98 consumidores, donde a cada uno de ellos se le pregunta sobre la
preferencia entre el empaque nuevo y el actual, en términos de la intención de compra, y los resultados de la prueba de empaque se muestran en la Tabla 4.6.
\begin{table}[!htb]
\centering
\begin{tabular}{|c|cc|c|}\hline
Empaque&Compra&No compra&Total\\\hline
Nuevo&32&31&63\\
Actual&11&24&35\\\hline
\end{tabular}\caption{\textsl{Datos de la prueba de empaque del Ejemplo 4.5.4.}}
\end{table}

Para conocer si el nuevo empaque tiene un efecto significativo sobre la preferencia de los consumidores comparado con el empaque actual, estamos interesados en comparar la probabilidad de compra con el empaque nuevo $p_1$ y la probabilidad de compra con el empaque actual $p_2$. En primer lugar, podemos ver que de los 63 consumidores a quienes se les preguntó sobre la preferencia del empaque nuevo, 32 de ellos se mostraron favorables; mientras que de los 35 consumidores a quienes se les preguntó la preferencia del empaque actual, 11 se mostraron favorables. De allí, podemos ver que la estimación de las probabilidades están dadas por $\hat{p}_1=0.508$ y $\hat{p}_2=11/35=0.314$.
\begin{verbatim}
> nx <- 63 ; x <- 32
> ny <- 35 ; y <- 11
> prop.test(c(x,y),c(nx,ny))
    2-sample test for equality of proportions with continuity correction

data:  c(x, y) out of c(nx, ny)
X-squared = 2.6852, df = 1, p-value = 0.1013
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.02578597  0.41308755
sample estimates:
   prop 1    prop 2
0.5079365 0.3142857
\end{verbatim}

De esta manera, para un nivel de significación del 5\%, no se rechaza la hipótesis de igualdad de proporciones. En otras palabras, no se encuentra evidencia de que el cambio al empaque nuevo tenga algún efecto sobre la decisión de compra comparado con el empaque actual. También podemos ver que el intervalo de confianza del 95\% para $p_1-p_2$ contiene el valor 0, conduciendo a la misma conclusión.

También notemos que con la anterior instrucción, se incluye la corrección de continuidad de Yates de manera semejante a lo expuesto en el caso de una muestra, si se desea excluir esta corrección se debe usar la opción \verb"correct=F".
\end{Eje}

Existe otro enfoque basado en una tabla de contingencia que estudia dos variables cualitativas, y los datos registrados corresponden a conteos y éstos se ubican en celdas en tablas como los datos del Ejemplo 4.5.4, donde la hipótesis de que la probabilidad de compra con el empaque nuevo sea igual a la probabilidad de compra con el empaque actual es equivalente a la hipótesis de que la intención de compra es independiente de la presentación del empaque, y en términos de una tabla de contingencia, equivale a probar la independencia entre las filas y las columnas.

Retomando el sistema de interés
\begin{equation*}
H_0:\ p_1=p_2\ \ \ \ vs.\ \ \ \ H_1:\ p_1\neq p_2,
\end{equation*}

Si $p_1=p_2$, entonces se espera que en la muestra $\hat{p}_1\approx\hat{p}_2$ y $1-\hat{p}_1\approx1-\hat{p}_2$, y por consiguiente $\frac{\hat{p}_1(1-\hat{p}_1)}{\hat{p}_2(1-\hat{p}_2)}\approx1$. Y esta cociente se define como la razón de \emph{odds} muestral\footnote{Este nombre viene de la palabra en inglés \emph{Odds ratio}, que ocasionalmente en español se traduce como cociente de probabilidades ó razón de ventaja.}. Entre más se difiere esta razón de odds, más evidencia hay en los datos en desfavor de la hipótesis $p_1=p_2$. Fisher desarrolló la prueba usando este enfoque. En el apéndice expondremos los temas relacionados con el análisis de tabla de contingencias usando esta prueba y una prueba adicionalmente de $\chi^2$, también muy usada.
\begin{Eje}
Los datos mostrados en la Tabla 4.7 fueron la base de una demanda en un caso de discriminación racial en 1980 entre los solicitantes de empleo en una fábrica de placas metálicas \cite{Carlin}.

\begin{table}[!htb]
\centering
\begin{tabular}{|c|cc|c|}\hline
Raza&Admitido&Rechazado&Total\\\hline
Blanca&41&39&80\\
Negra&14&30&44\\\hline
Total&55&69&124\\\hline
\end{tabular}\caption{\textsl{Datos de la discriminación racial del Ejemplo 4.5.5.}}
\end{table}

Mediante el análisis estadístico de estos datos se debe responder a la siguiente pregunta: ¿existe evidencia de discriminación racial? O equivalentemente, ¿la aceptación de una solicitud de empleo depende de la raza del solicitante? Para aplicar la prueba exacta de Fisher o la prueba $\chi^2$, podemos utilizar las funciones \verb"fisher.test"\index{Prueba!exacta de Fisher} y \verb"chisq.test"\index{Prueba!de Ji-cuadrado de independencia} que ilustramos a continuación.

\begin{verbatim}
> racis<-matrix(c(41,39,14,30),2,2)
> fisher.test(racis)

        Fisher's Exact Test for Count Data

data:  racis
p-value = 0.04025
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
 0.9796526 5.2952825
sample estimates:
odds ratio
  2.237988
> chisq.test(racis)

        Pearson's Chi-squared test with Yates' continuity correction

data:  racis
X-squared = 3.5913, df = 1, p-value = 0.05808
\end{verbatim}

Podemos observar que con la prueba exacta de Fisher la razón de odds tomó el valor de 2.238, el cual se puede sospechar que es muy diferente del valor 1; por otro lado, el $p$-valor es de 0.04, indicando evidencias en desfavor de $p_1=p_2$ con un nivel de significación de 5\%. Señalamos que al observar el intervalo de confianza para la razón de odds poblacional $\frac{p_1/(1-p_1)}{p_2/(1-p_2)}$, podemos ver que éste contiene el valor 1, lo cual produce una decisión contraria al observar el $p$-valor.

Por otro lado, observando los resultados de la prueba $\chi^2$, advertimos que con el mismo nivel de significación de 5\%, se llega a la conclusión de aceptar la hipótesis $H_0:\ p_1=p_2$.

\end{Eje}

\section{Muestras provenientes de una distribución Poi\-sson\index{Prueba de hipótesis!Poisson}}
\subsection{Una muestra\index{Prueba de hipótesis!Poisson!una muestra}}
En la práctica es común encontrar datos que corresponden a resultados de conteos y posiblemente pueden ser descritos por medio de la distribución Poisson. En el Ejemplo 2.3.2, se planteó la situación donde se investiga el nivel de violencia en una determinada ciudad por medio de datos que denotan el número de muertes violentos que ocurren mensualmente en distintos barrios de la ciudad y que por la naturaleza del problema, una distribución Poisson puede ser apropiada.

Suponga que el sistema de interés es
\begin{equation*}
H_0:\ \lambda=\lambda_0\ \ \ \ vs.\ \ \ \ H_1:\ \lambda\neq\lambda_0.
\end{equation*}

Utilizamos la prueba generalizada de razón de verosimilitud\index{Prueba! de razón generalizada de verosimilitudes!Poisson} definida, como en el anterior sistema, en $\bTheta_0\bigcup\bTheta_1=\bTheta$, entonces
\begin{equation*}
\lambda=\frac{L(\hat{\lambda}_{MV})}{L(\lambda_0)}=\exp\left\{n\lambda_0-\sum_{i=1}^nx_i\right\}\left(\frac{\bar{x}}{\lambda_0}\right)^{\sum_{i=1}^nx_i}
\end{equation*}

Y tenemos que
\begin{align*}
2\ln\lambda&=2\left(\ln L(\hat{\lambda}_{MV})-\ln L(\lambda_0)\right)\\
&=2\left(-n\bar{x}+\sum_{i=1}^nx_i\ln\bar{x}+n\lambda_0-\sum_{i=1}^n\ln\lambda_0\right)\\
&=2\left(n\bar{x}\ln\frac{\bar{x}}{\lambda_0}+n(\lambda_0-\bar{x})\right)
\end{align*}

Dado el razonamiento en la formulación de la prueba de razón de verosimilitud, valores grandes de $2\ln\lambda$ muestran la gran evidencia que tienen los datos en contra de $H_0$, y de allí podemos establecer dos reglas de decisión.

\begin{enumerate}
    \item Anteriormente se ha establecido la distribución asintótica de $2\ln\lambda$ bajo $H_0$ que es $\chi^2_{v_1-v_0}$ que en este caso $v_1=1$ y $v_0=0$. Así, podemos encontrar la regla de decisión: rechazar $H_0$ si $2\ln\lambda>\chi^2_{1,1-\alpha}$\index{Regla de decisión!Poisson!una muestra}.
    \item Por otro lado, observando la forma de la estadística $2\ln\lambda$, vemos que ésta compara el estimador de $\lambda$, $\bar{X}$ con el valor especificado por $H_0$, $\lambda_0$. Y esta estadística depende de los valores de la muestra sólo mendiante $\bar{X}$, así que podemos pensar en encontrar la relación que existe entre $\bar{X}$ y $2\ln\lambda$, puesto que si $2\ln\lambda$ es una función creciente de $\bar{X}$ entonces valores grandes de $\bar{X}$ conducen a valores grandes de $2\ln\lambda$ y por consiguiente, se rechaza $H_0$ para valores grandes de $\bar{X}$. Para ver dónde $2\ln\lambda$ es una función creciente/decreciente de $\bar{X}$, derivamos a $2\ln\lambda$ con respecto a $\bar{X}$. Tenemos que
        \begin{equation*}
        \frac{\partial2\ln\lambda}{\partial\bar{X}}=2n\ln\frac{\bar{X}}{\lambda_0}
        \end{equation*}
        En la anterior derivada, si $\bar{X}$ es muy grande, entonces la anterior derivada será positiva mientras que la derivada será negativa si los valores de $\bar{X}$ son pequeños. Esto indica que $2\ln\lambda$ es función creciente de $\bar{X}$ para valores grandes de $\bar{X}$ y función decreciente para valores pequeños de $\bar{X}$. En conclusión, cuando $\bar{X}$ toma valores muy grandes o muy pequeños, $2\ln\lambda$ toma valores grandes. Por consiguiente, tenemos la regla de decisión de rechazar $H_0$ si $\bar{X}>K_1$, o $\bar{X}<K_2$ para algunos valores $K_1$ y $K_2$.

        Al utilizar la restricción de que el máximo error de tipo I permitido es $\alpha$ y la distribución nula de $n\bar{X}$ dada por $Pois(\lambda_0)$, podemos encontrar que $K_1=Pois(\lambda_0,1-\alpha/2)/n$ y $K_2=Pois(\lambda_0,\alpha/2)/n$, respectivamente, y así tenemos la regla de decisión\index{Regla de decisión!Poisson!una muestra}: rechazar $H_0$ si $\bar{X}>Pois(\lambda_0,1-\alpha/2)/n$ o $\bar{X}<Pois(\lambda_0,\alpha/2)/n$.
\end{enumerate}

De lo anterior vemos que existen por lo menos dos pruebas distintas para el sistema de hipótesis considerado bajo una distribución Poisson: una basada en la distribución exacta de $n\bar{X}$, y la otra basada en la distribución asintótica de la estadística $2\ln\lambda$. Dado que la distribución asintótica es válida cuando $n\rightarrow\infty$, que en la práctica se refleja en las muestras grandes, es interesante conocer cuál prueba es mejor en el sentido en que los errores tipo I ocurren con frecuencia inferior a $\alpha$ y los errores tipo II no ocurren con frecuencia. Un sencillo ejercicio de simulación nos puede dar pistas acerca del funcionamiento de estas dos pruebas. A continuación describimos cómo se pueden realizar estas simulaciones.
\begin{enumerate}
\item Para comparar las dos pruebas con respecto al error tipo I, simulamos 10000 muestras de tamaño $n$ provenientes de una distribución $Pois(\lambda_0)$, y aplicamos las dos pruebas a cada una de las muestras simuladas para probar el sistema $H_0:\ \lambda=\lambda_0$ vs. $H_1:\ \lambda\neq\lambda_0$, es decir, ya conocemos de antemano que $H_0$ es verdadero, entonces de las 1000 muestras simuladas, el número de veces que una prueba rechaza $H_0$ debe ser pequeño, no superior a $\alpha$. Realizamos el procedimiento para $n=5,15,30,50,100$ y $\lambda_0=2,5,15,25$, y los resultados se muestran en la Tabla 4.8, donde cada entrada es el porcentaje de muestras donde erróneamente rechaza $H_0$, es decir, una aproximación del error tipo I.

    Observamos que con la prueba exacta casi siempre se tiene menor riesgo de rechazar una hipótesis falsa, aunque la diferencia entre las pruebas es muy reducida, inclusive para muestras muy pequeñas.
    \begin{table}[!htb]
\centering
\begin{tabular}{|c|ccccc|}\hline
                    &\multicolumn{5}{|c|}{Prueba exacta}\\\hline
                    &$n=5$&$n=15$&$n=30$&$n=50$&$n=100$\\\hline
$\lambda_0=2$  &0.0238& 0.0428&  0.0408 & 0.0456 & 0.0487 \\
$\lambda_0=5$  &0.0454& 0.0516&  0.0468 & 0.0487 & 0.0471 \\
$\lambda_0=15$ &0.0483& 0.0458&  0.0515 & 0.0478 & 0.0481 \\
$\lambda_0=25$ &0.0498& 0.0475&  0.0482 & 0.0481 & 0.0489 \\\hline
&\multicolumn{5}{|c|}{Prueba asintótica}   \\\hline
 $\lambda_0=2$  &  0.0533 &0.0428 &0.0534 & 0.0521  &0.0487      \\
 $\lambda_0=5$  &  0.0454 &0.0516 &0.0520 & 0.0518  &0.0471      \\
 $\lambda_0=15$ &  0.0483 &0.0494 &0.0533 & 0.0478  &0.0481      \\
 $\lambda_0=25$ &  0.0498 &0.0475 &0.0482 & 0.0519  &0.0502      \\  \hline
  \end{tabular}\caption[\textsl{Tamaños de pruebas bajo distribución Poisson}]{\textsl{Comparación de tamaños de prueba para la prueba exacta y la prueba asintótica bajo una distribución Poisson.}}
\end{table}
\item Para comparar las dos pruebas con respecto a la potencia, es decir, la capacidad de rechazar una hipótesis falsa, el procedimiento de simulación es similar al caso anterior, pero probamos el sistema $H_0:\ \lambda=\lambda_0$ vs. $H_1:\ \lambda\neq\lambda_0$ en muestras provenientes de distribución $Pois(\lambda)$ con $\lambda\neq\lambda_0$, es decir, ya conocemos de antemano que $H_0$ es falsa. De esta forma, una buena prueba será aquella que rechaza más veces $H_0$ en las 10000 muestras simuladas. Las simulaciones se realizaron para $n=5,15,30,50,100$, $\lambda_0=20$ y $\lambda=13,15,17,19,21,23,25,27$. Los resultados se muestran en la Tabla 4.9, donde cada entrada es el porcentaje de muestras donde correctamente rechaza $H_0$, es decir, una aproximación de la potencia de la prueba.
\begin{table}[!htb]
\centering
\begin{tabular}{|c|ccccc|}\hline
&\multicolumn{5}{|c|}{Prueba exacta}\\\hline
&$n=5$&$n=15$&$n=30$&$n=50$&$n=100$\\\hline
$\lambda=13$ &0.9689&1.0000&1.0000& 1.0000 &1.0000 \\
$\lambda=15$ &0.7364&0.9965&1.0000& 1.0000 &1.0000 \\
$\lambda=17$ &0.3202&0.7699&0.9643& 0.9989 &1.0000 \\
$\lambda=19$ &0.0725&0.1429&0.2208& 0.3439 &0.6063 \\
$\lambda=21$ &0.0763&0.1434&0.2279& 0.3470& 0.5933  \\
$\lambda=23$ &0.2929&0.7113&0.9489& 0.9954& 1.0000  \\
$\lambda=25$ &0.6452&0.9842&0.9999& 1.0000& 1.0000  \\
$\lambda=27$ &0.9013&0.9997&1.0000& 1.0000& 1.0000  \\ \hline
&\multicolumn{5}{|c|}{Prueba asintótica}            \\ \hline
$\lambda=13$ &0.9761& 1.0000 &1.0000& 1.0000& 1.0000   \\
$\lambda=15$ &0.7707& 0.9965 &1.0000& 1.0000& 1.0000   \\
$\lambda=17$ &0.3563& 0.7699 &0.9681& 0.9990& 1.0000   \\
$\lambda=19$ &0.0880& 0.1429 &0.2335& 0.3570& 0.6063   \\
$\lambda=21$ &0.0792& 0.1434 &0.2280& 0.3471& 0.5933   \\
$\lambda=23$ &0.2929& 0.7113 &0.9489& 0.9954& 1.0000   \\
$\lambda=25$ &0.6452& 0.9842 &0.9999& 1.0000& 1.0000   \\
$\lambda=27$ &0.9013& 0.9997 &1.0000& 1.0000& 1.0000   \\  \hline
  \end{tabular}\caption[\textsl{Potencia de pruebas bajo distribución Poisson}]{\textsl{Comparación de potencia de prueba para la prueba exacta y la prueba asintótica bajo una distribución Poisson.}}
\end{table}

    Observamos en primer lugar que para cada $n$ fijo, entre más se aleja $\lambda$, el parámetro verdadero del valor especificado por $H_0$, mayor potencia tiene cada prueba. En segundo lugar, observamos que la potencia de la prueba asintótica, aún en muestras pequeñas, es más alta que la prueba exacta, aunque las di\-fe\-ren\-cias no son significativas.
\end{enumerate}

De los anteriores comentarios, podemos concluir que el desempeño de la prueba asintótica y la prueba exacta son muy similares, y por consiguiente en la práctica se puede optar por cualquiera de estas dos, aunque la prueba asintótica puede ser más fácil, por lo menos al momento de calcular el $p$ valor.

Presentamos una aplicación en el siguiente ejemplo.

\begin{Eje}
En el Ejemplo 2.3.2, con el fin de conocer el nivel de violencia de una ciudad, se disponen los datos que corresponden al número de muertes violentas de 15 de los 63 barrios: éstos son 1, 1, 5, 5, 2, 3, 3, 6, 4, 3, 2, 3, 2, 3 y 4. Supongamos que se cree que mensualmente suceden en promedio 70 muertes violentas en toda la ciudad. ¿Cómo podemos confirmar o refutar esta creencia? En primer lugar, nótese que los datos que tenemos a la mano corresponden a observaciones no sobre la ciudad, sino sobre barrios que son parte de la ciudad\footnote{Si se hace observación directa sobre la ciudad, las observaciones se harán en diferentes meses, y en este caso las observaciones ya no constituyen una muestra aleatoria por ser observaciones hechas a través del tiempo.}. Entonces realmente la inferencia se puede hacer sobre el número promedio de muertes violentas $\lambda_b$ por barrio en esta ciudad, pero el parámetro de interés no es al nivel de barrios sino en toda la ciudad $\lambda_c$; sin embargo, por las anotaciones hechas en el Ejemplo 2.3.2, se puede establecer que $\lambda_c=63*\lambda_b$, por lo tanto la hipótesis $\lambda_c=70$ equivale a $\lambda_b=70/63\approx1.11$. De esta forma, ya podemos utilizar directamente los datos a la mano. Usando la prueba asintótica, encontramos que la estadística $2\ln\lambda\approx36.78$, y el $p$ valor están dados por $F_{\chi^2_{1}}(36.78)= 1.31e-09$ mostrando una fuerte discordancia entre los datos observados y la hipótesis $\lambda_b=70/63\approx1.11$ ó $\lambda_c=70$. Se deja como ejercicio la aplicación de la prueba exacta.
\end{Eje}

\subsection{Dos muestras\index{Prueba de hipótesis!Poisson!dos muestras}}
$X_1$, $\cdots$, $X_{n_X}$ provenientes de una distribución $Pois(\lambda_X)$ y $Y_1$, $\cdots$, $Y_{n_Y}$ provenientes de una distribución $Pois(\lambda_Y)$
\begin{equation}\label{poisson_2}
H_0:\ \lambda_X=\lambda_Y\ \ \ \ vs.\ \ \ \ H_1:\ \lambda_X\neq\lambda_Y
\end{equation}

Para el anterior sistema, es natural pensar que los datos muestran evidencia en contra de $H_0$ si las estimaciones de $\lambda_X$ y $\lambda_Y$ son muy diferentes, esto es, si $|\bar{X}-\bar{Y}|$ es muy grande. A pesar de que este razonamiento es completamente lógico y válido, no es posible o es muy complicado encontrar la distribución nula exacta\footnote{Aunque se puede utilizar el teorema del límite central para encontrar que bajo $\lambda_X=\lambda_Y=\lambda$ $\bar{X}-\bar{Y}\sim_{asym}N\left(0,\lambda\left(\frac{1}{n_X}+\frac{1}{n_Y}\right)\right)$, pero la varianza de esta distribución es desconocida y por consiguiente tampoco nos es útil para encontrar una regla de decisión.} de $\bar{X}-\bar{Y}$. Por lo tanto, hacemos uso de la prueba generalizada de razón de verosimilitud\index{Prueba! de razón generalizada de verosimilitudes!Poisson}. Para calcular esta estadística, tengamos presente que
\begin{equation*}
\ln L=-n_X\lambda_X-n_Y\lambda_Y+\sum_{i=1}^{n_X}X_i\ln\lambda_X+\sum_{j=1}^{n_Y}Y_j\ln\lambda_Y-\ln\prod_{i=1}^{n_X}X_i-\ln\prod_{j=1}^{n_Y}Y_i
\end{equation*}

Los estimadores de máxima verosimilitud $\lambda_X$ y $\lambda_Y$ son $\bar{X}$ y $\bar{Y}$, respectivamente; por otro lado, bajo $H_0:\ \lambda_X=\lambda_Y=\lambda$, el estimador de máxima verosimilitud de $\lambda$ es $(\sum_{i=1}^{n_X}X_i+\sum_{j=1}^{n_Y}Y_j)/(n_X+n_Y)$, es decir, el promedio de los datos de ambas muestras. Dado lo anterior, la estadística $2\ln\lambda$ se puede calcular como
\begin{equation*}
2\ln\lambda=2\left(n_X\bar{X}\ln\bar{X}+n_Y\bar{Y}\ln\bar{Y}-(n_X\bar{X}+n_Y\bar{Y})\ln\frac{n_X\bar{X}+n_Y\bar{Y}}{n_X+n_Y}\right)
\end{equation*}

Para encontrar la distribución nula de $2\ln\lambda$ observamos que en primer lugar, hay dos parámetros teóricos en el espacio paramétrico completo, mientras que bajo $H_0$, los dos parámetros son iguales, y por consiguiente se reducen a un solo parámetro. De esta forma, tenemos que $v_1=2$ y $v_0=1$, y por consiguiente
\begin{equation*}
2\ln\lambda\sim_{asym}\chi^2_1.
\end{equation*}

\index{Regla de decisión!Poisson!dos muestras}Y se rechaza $H_0$ si $2\ln\lambda>\chi^2_{1,1-\alpha}$. También podemos calcular el correspondiente $p$ valor como\index{$p$ valor!Poisson!dos muestras}
\begin{equation*}
p\ \text{valor}=1-F_{\chi^2_1}(v)
\end{equation*}

donde $F_{\chi^2_1}$ es la función de distribución de una distribución $\chi^2_1$ y $v$ denota el valor que toma la estadística $2\ln\lambda$.

\begin{Eje}
Una empresa de telefonía móvil (A) lanza una promoción limitada de precios especiales en equipos para atraer clientes, y la directa competencia (B) de esta empresa quiere saber si la promoción de la compañía A surtió algún efecto significativo sobre la venta de los equipos\footnote{Nótese que la empresa A tiene pleno conocimiento sobre el efecto de la promoción puesto que tiene los registros sobre el volumen de ventas, pero la competencia B no tiene esa información y por lo tanto debe recurrir a otros medios para investigar el fenómeno.}. Para eso la empresa B observa el número de clientes que realizan compras en 10 puntos de ventas de la empresa A en un día determinado durante la vigencia de la promoción, y después de la promoción. Suponga que los datos que se registraron son los de la Tabla 4.10.
\begin{table}[!htb]
\begin{tabular}{|c|cccccccccc|}\hline
&\multicolumn{10}{|c|}{Punto de venta}\\\hline
&1&2&3&4&5&6&7&8&9&10\\\hline
Durante la promoción& 36& 31 &28 &41 &35& 52& 25& 31& 32 &34\\
Después de la promoción&31& 41& 29 &20& 29& 35 &31& 29& 33& 30\\\hline
\end{tabular}\caption{\textsl{Datos del Ejemplo 4.6.2.}}
\end{table}

Dada la naturaleza del problema, existen dos tipos de comportamientos que pueden considerarse como dos poblaciones, una concerniente al número de ventas durante la promoción, y la otra, después de la promoción. Los datos registrados corresponden al número de ventas diarias y pueden considerarse como realización de variables tipo Poisson. De esta forma, los datos de la primera muestra corresponden al número de ventas durante la promoción en diez puntos de venta, y los datos de la segunda muestra, después de la promoción. Si denotamos el número promedio de ventas diarias en un punto de venta durante y después de la promoción como $\lambda_1$ y $\lambda_2$, respectivamente, entonces al considerar el sistema de hipótesis
\begin{equation*}
H_0:\ \lambda_1=\lambda_2\ \ \ \ vs.\ \ \ \ H_1:\ \lambda_1\neq\lambda_2
\end{equation*}

podríamos hacernos una idea acerca de si la promoción ha mejorado significativamente las ventas.

El siguiente código en R computa las estimaciones de $\lambda_1$ y $\lambda_2$, la estadística $2\ln\lambda$ y el $p$ valor.
\begin{verbatim}
> pois_2<-function(x,y){
+ nx<-length(x)
+ ny<-length(y)
+ est.X<-mean(x)
+ est.Y<-mean(y)
+ l1<-sum(x)*log(est.X)+sum(y)*log(est.Y)
+ l2<-(sum(x)+sum(y))*log((sum(x)+sum(y))/(nx+ny))
+ estad<-2*(l1-l2)
+ p<-pchisq(estad,1,lower.tail = F)
+ list(estima.X=est.X,estima.Y=est.Y,estadistica=estad,p.valor=p)
+ }
>
> Durante<-c(36, 31 ,28, 41 ,35 ,52, 25, 31, 32, 34)
> Despues<-c(31 ,41 ,29 ,20, 29, 35 ,31, 29, 33 ,30)
> pois_2(Durante,Despues)
$estima.X
[1] 34.5

$estima.Y
[1] 30.8

$estadistica
[1] 2.097601

$p.valor
[1] 0.1475305
\end{verbatim}

De los resultados vemos que las estimaciones de $\lambda_1$ y $\lambda_2$ son bastante similares, y la prueba de razón de verosimilitudes indica que la diferencia entre estas estimaciones no es significativa. De donde los directivos de la compañía B pueden concluir que la promoción lanzada por la compañía A no obtuvo un efecto significativo en el volumen de ventas. Es decir, probablemente la promoción no tuvo en cuenta las necesidades que tienen los usuarios de la telefonía móvil y/o los aspectos de interés que llaman la atención de los clientes. De allí, la compañía B puede lanzar una promoción que corrige estas deficiencias, atraer más clientes y tomar la delantera en el mercado.
\end{Eje}


\section{Muestras provenientes de la distribución exponencial\index{Prueba de hipótesis!exponencial}}
\subsection{Una muestra\index{Prueba de hipótesis!exponencial!una muestra}}
Suponga que tenemos $X_1$, $\cdots$, $X_n$, una muestra proveniente de una distribución $Exp(\theta)$. Y estamos interesados en probar el sistema de hipótesis
\begin{equation}\label{exp_1}
H_0:\ \theta=\theta_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta\neq\theta_0
\end{equation}

Hay por lo menos tres formas de encontrar una regla de decisión para este sistema. Las dos primeras teniendo en cuenta la dualidad entre los intervalos de confianza y la prueba de sistema de hipótesis, y la tercera usando la prueba generalizada de razón de verosimilitud.

\begin{enumerate}
  \item Anteriormente se encontró el siguiente intervalo bilateral exacto para $\theta$ dado por
        \begin{equation*}
            IC(\theta)=\left(\dfrac{\sum_{i=1}^nX_i}{Gamma(n,1)_{1-\alpha/2}},\dfrac{\sum_{i=1}^nX_i}{Gamma(n,1)_{\alpha/2}}\right).
        \end{equation*}

       Utilizando el anterior intervalo, podemos rechazar $H_0:\ \theta=\theta_0$ si $\theta_0$ no se encuentra dentro del intervalo, es decir:

        \index{Regla de decisión!exponencial!una muestra}Rechazar $H_0$ si $\sum_{i=1}^nX_i>\theta_0Gamma(n,1)_{1-\alpha/2}$ ó si $\sum_{i=1}^nX_i<\theta_0Gamma(n,1)_{\alpha/2}$. El $p$ valor asociado a esta prueba se puede calcular como\index{$p$ valor!exponencial!una muestra}
        \begin{equation*}
        p\ \text{valor}=
        \begin{cases}
        2(1-F_{G(n,\theta_0)}(v))&\text{si $v>Gamma(n,\theta_0)_{0.5}$}\\
        2F_{G(n,\theta_0)}(v)&\text{si $v<Gamma(n,\theta_0)_{0.5}$}\\
        \end{cases}
        \end{equation*}
        donde $v$ es el valor observado de la estadística $\sum_{i=1}^nX_i$ y $F_{G(n,\theta_0)}(\cdot)$ denota la función de distribución de la distribución $Gamma(n,\theta_0)$.

  \item Usando el mismo argumento del punto anterior y el intervalo aproximado de $\theta$ dado por
      \begin{equation*}
        IC(\theta)=\left(\frac{\sqrt{n}\bar{X}}{z_{1-\alpha/2}+\sqrt{n}},\frac{\sqrt{n}\bar{X}}{-z_{1-\alpha/2}+\sqrt{n}}\right).
      \end{equation*}
      Podemos obtener la prueba:

      \index{Regla de decisión!exponencial!una muestra}Rechazar $H_0$ si $\bar{X}>\dfrac{\theta_0}{\sqrt{n}}z_{1-\alpha/2}+\theta_0$ ó si $\bar{X}<-\dfrac{\theta_0}{\sqrt{n}}z_{1-\alpha/2}+\theta_0$. El $p$ valor asociado a esta prueba se puede calcular como\index{$p$ valor!exponencial!una muestra}
        \begin{equation*}
        p\ \text{valor}=
        \begin{cases}
        2(1-\Phi(v))&\text{si $v\geq0$}\\
        2\Phi(v)&\text{si $v<0$}\\
        \end{cases}
        \end{equation*}

        donde $v$ es el valor observado de la estadística $\sqrt{n}(\bar{X}-\theta_0)/\theta_0$.


  \item Aplicando la prueba generalizada de razón de verosimilitudes\index{Prueba!de razón generalizada de verosimilitudes!exponencial}, es fácil verificar que
        \begin{equation}\label{exp_lambda_tarea}
            2\ln\lambda=2n\left(\frac{\bar{X}}{\theta_0}-\log\frac{\bar{X}}{\theta_0}-1\right)
        \end{equation}
        cuya distribución nula asintótica es $\chi^2_1$, y por consiguiente tenemos la decisión de\index{Regla de decisión!exponencial!una muestra}

        Rechazar $H_0$ si $2\ln\lambda>\chi^2_{1,1-\alpha}$.
\end{enumerate}

Dado que hay tres diferentes pruebas para el mismo sistema de hipótesis, debemos compararlas en términos del tamaño y la potencia.

Primero comprobamos que el tamaño de las pruebas sea cercano al nivel de significación nominal $\alpha$, y lo realizamos mediante simulaciones. El procedimiento es similar a las comparaciones realizadas bajo la distribución Poisson, es decir, se simulan 10000 muestras provenientes de una distribución $Exp(\theta_0)$ y en cada muestra simulada, se juzga la hipótesis $H_0:\ \theta=\theta_0$, y el tamaño de la prueba es el número de veces que se rechaza erróneamente $H_0$ divido por 10000. Los resultados de estas simulaciones para diferentes tamaños de muestra y diferentes valores de $\theta_0$ se encuentran en la Tabla 4.11, donde podemos observar que las tres pruebas, incluyendo las pruebas asintóticas con pequeños tamaños de muestra, tienen buen desempeño en términos del tamaño, ya que el porcentaje de error tipo I cometido es similar al nivel de signficación $\alpha$.

\begin{table}[!htb]
\centering
\begin{tabular}{|c|ccccc|}\hline
                    &\multicolumn{5}{|c|}{Prueba exacta}\\\hline
                    &$n=5$&$n=15$&$n=30$&$n=50$&$n=100$\\\hline
$\theta_0=2$  &  0.0490& 0.0483 &  0.0499  & 0.0488&  0.0503 \\
$\theta_0=5$  &  0.0495& 0.0526 &  0.0473  & 0.0473&  0.0470 \\
$\theta_0=15$ &  0.0491& 0.0491 &  0.0477  & 0.0493&  0.0491 \\
$\theta_0=25$ &  0.0523& 0.0502 &  0.0474  & 0.0500&  0.0456 \\\hline
&\multicolumn{5}{|c|}{Prueba asintótica normal}   \\\hline
 $\theta_0=2$  & 0.0409 &0.0454&  0.0466 &  0.0462 &   0.0508 \\
 $\theta_0=5$  & 0.0414 &0.0479&  0.0463 &  0.0471 &   0.0460 \\
 $\theta_0=15$ & 0.0408 &0.0459&  0.0464 &  0.0486 &   0.0484 \\
 $\theta_0=25$ & 0.0462 &0.0480&  0.0474 &  0.0510 &   0.0448 \\  \hline
&\multicolumn{5}{|c|}{Prueba asintótica $\chi^2$}   \\\hline
 $\theta_0=2$  & 0.0536&0.0494 &0.0501  &0.0484    &  0.0499  \\
 $\theta_0=5$  & 0.0554&0.0523 &0.0480  &0.0489    &  0.0474  \\
 $\theta_0=15$ & 0.0519&0.0516 &0.0484  &0.0513    &  0.0495  \\
 $\theta_0=25$ & 0.0547&0.0495 &0.0489  &0.0501    &  0.0463  \\  \hline
  \end{tabular}\caption[\textsl{Tamaños de pruebas bajo distribución Exponencial}]{\textsl{Comparación de tamaños de prueba para la prueba exacta y las dos pruebas asintóticas bajo una distribución Exponencial.}}
\end{table}

Con respecto a la potencia, para la prueba exacta, podemos hallar la función de potencia como\index{Función de potencia!exponencial!una muestra}
\begin{align*}
\beta_1(\theta)&=Pr\left(\sum_{i=1}^nX_i>\theta_0Gamma(n,1)_{1-\alpha/2}\right)+Pr\left(\sum_{i=1}^nX_i<\theta_0Gamma(n,1)_{\alpha/2}\right)\\
&=1-F_{G(n,\theta)}(\theta_0Gamma(n,1)_{1-\alpha/2})+F_{G(n,\theta)}(\theta_0Gamma(n,1)_{\alpha/2})
\end{align*}

puesto que $\sum_{i=1}^nX_i\sim Gamma(n,\theta)$, y $F_{G(n,\theta)}(\cdot)$ denota la función de distribución de la distribución $Gamma(n,\theta)$.

De manera análoga y teniendo en cuenta que $\frac{\sqrt{n}(\bar{X}-\theta)}{\theta}\sim_{asym}N(0,1)$ por el teorema límite central, podemos ver que la potencia de la prueba asintótica basada en la distribución normal en el numeral 2 es\index{Función de potencia!exponencial!una muestra}
\begin{equation}\label{potencia_exp_z}
\beta_2(\theta)=1-\Phi\left(\frac{\theta_0}{\theta}z_{1-\alpha/2}+\sqrt{n}(\frac{\theta_0}{\theta}-1)\right)+\Phi\left(-\frac{\theta_0}{\theta}z_{1-\alpha/2}+\sqrt{n}(\frac{\theta_0}{\theta}-1)\right).
\end{equation}

Finalmente, debemos hallar la función de potencia de la prueba de razón de verosimilitud cuya regla de decisión se basa en una distribución $\chi^2$. Sin embargo, no es nada fácil hallar esta función y por cuestión de simplicidad usamos simulaciones para aproximar esta función de potencia, similar a las simulaciones de potencia realizadas previamente bajo una distribución Poisson. En la Figura 4.21, graficamos conjuntamente las funciones de potencia $\beta_1(\theta)$, $\beta_2(\theta)$ y las aproximaciones de la función de potencia de la prueba asintótica de verosimilitud basada en la distribución $\chi^2$ con $n=30$.

\begin{verbatim}
> set.seed(1234)
> alpha<-0.05
> theta0<-20
> theta<-theta0+seq(-7,7,2)
> n<-30
> n.sim<-10000
>
> ## Potencia de la prueba exacta gamma
> pote_gamma<-function(theta,theta0,n,alpha){
+ 1-pgamma(theta0*qgamma(1-alpha/2,n,1),n,1/theta)+
+ pgamma(theta0*qgamma(alpha/2,n,1),n,1/theta)
+ }
> # Potencia de la prueba asintótica normal
> pote_norm<-function(theta,theta0,n,alpha){
+ 1-pnorm((theta0/theta)*(qnorm(1-alpha/2)+sqrt(n))-sqrt(n))+
+ pnorm((theta0/theta)*(-qnorm(1-alpha/2)+sqrt(n))-sqrt(n))
+ }
> ## Potencia de la prueba asintótica Ji-cuadrado
> pote_chi<-function(theta,theta0,n,alpha){
+ aux<-0
+ for(k in 1:n.sim){
+ muestra<-rexp(n,1/theta)
+ ba<-mean(muestra)
+ LRT<-2*n*(ba/theta0-log(ba/theta0)-1)
+ if(LRT>qchisq(1-alpha,1)){aux<-aux+1}
+ }
+ aux/n.sim
+ }
> ##
>
> pote_chis<-pote_gammas<-pote_norms<-matrix(NA)
> theta<-seq(5,50,0.1)
> for(i in 1:length(theta)){
+ pote_chis[i]<-pote_chi(theta[i],theta0,n,alpha)
+ pote_gammas[i]<-pote_gamma(theta[i],theta0,n,alpha)
+ pote_norms[i]<-pote_norm(theta[i],theta0,n,alpha)
+ }
>
> plot(pote_chis,type="l",xaxt="n",xlab="theta",ylab="Potencia")
> axis(1,1:length(theta),theta)
> lines(pote_norms,lty=2)
> lines(pote_gammas,lty=3)
> legend(220,0.3,c("Prueba exacta", "Prueba asintótica normal",
+ "Prueba asintótica chi2"),lty=c(3,2,1),bty="n")
\end{verbatim}


\begin{figure}[!htb]
\centering
\includegraphics[scale=0.6]{Potencia_exp.eps}
\caption[\textsl{Función de potencia de pruebas para $\theta$ en $Exp(\theta)$}]{\textsl{Función de potencia de las tres pruebas para la media teórica bajo la distribución exponencial con $\alpha=0.05$ y $n=30$.}}
\end{figure}

Observamos que, en primer lugar, el compotamiento de la prueba exacta basada en la distribución Gamma y la prueba asintótica basada en la distribución $\chi^2$ son muy similares, mientras que la prueba asintótica basada en la distribución normal difiere levemente, en el sentido de que tiene mayor capacidad para detectar una hipótesis falsa del tipo $\theta=\theta_0$ cuando $\theta_0$ es menor que el parámetro verdadero, pero cuando el valor especificado por $H_0$ es mayor que el parámetro verdadero, esta prueba tiene menor potencia que las restantes dos.

\begin{Eje}
En el Ejemplo 2.3.4, se planteó el problema de monitorear llamadas contestadas por operadores de una aerolínea con el fin de evitar pérdida de clientes potenciales debido a largos tiempos de espera en línea. Los minutos transcurridos en 20 llamadas antes de ser contestadas fueron 0.13, 0.06, 0.50, 0.41, 1.44, 0.60, 0.22, 1.08, 0.78, 0.92, 2.73, 0.83, 0.19, 0.21, 1.75, 0.79, 0.02, 0.05, 2.30 y 1.03, y en el Ejemplo 2.3.4 se hizo la anotación de que la distribución exponencial describe adecuadamente los datos. Suponga que la hipótesis que sostiene el supervisor de estos operadores es que en promedio se necesita medio minuto para que una llamada sea contestada. Para ver la validez de esta hipótesis usando los datos muestrales, planteamos el sistema
\begin{equation*}
H_0:\ \theta=0.5\ \ \ \ vs.\ \ \ \ H_1:\ \theta\neq0.5
\end{equation*}

donde $\theta$ denota el tiempo promedio (en minutos) de espera. El siguiente código efectúa cualquiera de las tres pruebas descritas anteriormente dependiendo de la opción que el usuario le dé.

\begin{verbatim}
>     exp_1<-function(x,theta0,type = c("gamma","normal", "chi")){
+
+     n<-length(x)
+     est<-mean(x)
+
+     if(type=="gamma"){
+       prueba<-"Prueba exacta gamma"
+       if(sum(x)>qgamma(0.5,n,1/theta0)){
+       p<-2*pgamma(sum(x),n,1/theta0,lower.tail=F)        }
+       else{p<-2*pgamma(sum(x),n,1/theta0)   }
+     }
+
+     if(type=="normal"){
+       prueba<-"Prueba asintótica normal"
+       v<-sqrt(n)*(est-theta0)/theta0
+       if(v<0){
+       p<-2*pnorm(v)        }
+       else{p<-2*pnorm(v,lower.tail=F)   }
+     }
+
+     if(type=="chi"){
+       prueba<-"Prueba asintótica Ji-cuadrado"
+       lambda<-2*n*((est/theta0)-log(est/theta0)-1)
+       p<-pchisq(lambda,1,lower.tail=F)
+     }
+
+     list(tipo=prueba,estimación=est,p.valor=p)
+     }
\end{verbatim}

Para los datos de este ejemplo, la estimación del parámetro $\theta$ es $\bar{x}=0.802$, el cual es superior al valor especificado en $H_0$, de donde podríamos sospechar que posiblemente el valor de $\theta$ también sea mayor de $\theta_0$, y por consiguiente utilizar la prueba asintótica basada en la distribución normal ya que en la Figura 4.21 se observó que ésta es la más potente en este caso. Por lo tanto utilizamos la función \verb"exp_1" de la siguiente manera

\begin{verbatim}
>     tiempo<-c(0.13, 0.06, 0.50, 0.41, 1.44, 0.60, 0.22,
+    1.08, 0.78, 0.92, 2.73, 0.83, 0.19, 0.21, 1.75, 0.79,
+    0.02, 0.05, 2.30, 1.03)
>     exp_1(tiempo,0.5,type="normal")
$tipo
[1] "Prueba asintótica normal"

$estimación
[1] 0.802

$p.valor
[1] 0.006909599
\end{verbatim}

El $p$ valor muestra que la hipótesis $\theta=0.5$ no es apoyada por los datos observados, y por consiguiente se rechaza $H_0$.
\end{Eje}

\subsection{Dos muestras\index{Prueba de hipótesis!exponencial!dos muestras}}
$X_1$, $\cdots$, $X_{n_X}$ provenientes de una distribución $Exp(\theta_X)$ y $Y_1$, $\cdots$, $Y_{n_Y}$ provenientes de una distribución $Exp(\theta_Y)$.
\begin{equation}\label{exp_2}
H_0:\ \theta_X=\theta_Y\ \ \ \ vs.\ \ \ \ H_1:\ \theta_X\neq\theta_Y
\end{equation}

Se deja como ejercicio verificar con el método de la prueba generalizada de verosimilitudes\index{Prueba!de razón generalizada de verosimilitudes!exponencial}, tenemos que (Ejercicio 4.24)

\newpage

\begin{equation}\label{lambda_exp_2}
2\ln\lambda=2\left((n_X+n_Y)\ln\dfrac{n_X\bar{X}+n_Y\bar{Y}}{n_X+n_Y}-n_X\ln\bar{X}-n_Y\ln\bar{Y}\right)
\end{equation}

cuya distribución nula asintótica es $\chi^2_1$ y se \index{Regla de decisión!exponencial!dos muestras}rechaza $H_0$ cuando $2\ln\lambda>\chi^2_{1,1-\alpha}$.

\begin{Eje}
En el problema de control del tiempo de espera de llamadas que entran a una aerolínea, ahora, según si las llamadas salen del capital, Bogotá, o de ciudades diferentes a Bogotá, los números marcados son diferentes. Para llamadas salientes de Bogotá, los clientes llaman a un número fijo de 7 dígitos, mientras que los clientes que llaman de otra ciudad marcan un número del tipo 018000 de 12 dígitos. Dado lo anterior, es claro que el sistema de operación es diferente, y por consiguiente podemos formular la inquietud de si esta diferencia puede causar que el tiempo de espera de llamadas salientes de Bogotá y las salientes de otra ciudad sea sustancialmente diferente.

En este contexto, al denotar el tiempo promedio de espera de estos dos tipos de llamadas por $\theta_X$ y $\theta_Y$, respectivamente, el sistema de hipótesis de interés es de la forma (\ref{exp_2}). Dadas dos muestras de las dos poblaciones, para aplicar la prueba de razón de verosimilitud, solo necesitamos conocer los medios muestrales $\bar{X}$ y $\bar{Y}$, además de verificar que la distribución exponencial es apropiada para describir ambas muestras, éste se puede corroborar con una sencilla QQ plot para la distribución exponencial. Si en dos muestras de tamaño 54 y 38, las estimaciones muestrales fueron $\bar{x}=0.83$ minutos y $\bar{y}=0.79$ minutos, entonces la estadística $2\ln\lambda=0.054$, el cual es claramente más pequeño que los percentiles $\chi^2_{1,1-\alpha}$ para los valores comunes de $\alpha$ en la práctica, y podemos concluir que con base en las muestras, $\theta_X=\theta_Y$ puede ser una hipótesis apropiada para las dos poblaciones, es decir, el tiempo de espera no es influenciado por la ciudad de donde provienen las llamadas.

\end{Eje}

\section{Acerca del $p$-valor\index{$p$ valor}}

\subsection{Diversos puntos de vistas acerca del $p$-valor}

El libro <<The cult of statistical significance>> de Ziliak y McCloskey (2008) tiene un buen punto acerca de los tópicos de la inferencia estadística y se basa en una crítica científica a la mala costumbre de los estadísticos en la prueba de hipótesis.  Los autores se preguntan ¿por qué las decisiones científicas están restringidas a un espacio discreto binario $ \{0,1\}$ inducido por una regla de decisión? Los autores del libro sugieren que tendría más sentido científico que las decisiones estuvieran sujetas a una función de pérdida continua en el intervalo $ (0,1)$.

Tiene sentido, más aún cuando a la hora de realizar contrastes sea cual sea la rama de aplicación (econometría, mercadeo, epidemiología, ciencia política, etc.), siempre se utiliza la misma regla de decisión que Fisher impuso hace varias décadas: si el valor $ p$ es menor que 0.05, entonces rechace la hipótesis. Pero la verdad que todos sabemos, y a veces no queremos aceptar, es otra. A continuación se presenta un ejemplo detallado adaptado de las primeras páginas del libro.

Imagínese que usted y su pequeño niño de cuatro años caminan por una de las aceras de la ciudad. Se detienen en una esquina y compran un perro caliente (hot dog). El vendedor del carrito de perros lo atiende muy amablemente y le da justo lo que usted pidió. El semáforo se va a poner en rojo pero usted se atreve a cruzar la calle. Situación número uno: cuando va a llegar a la otra acera, usted se da cuenta que el vendedor olvidó colocar mostaza en su perro. Si usted y su hijo se atreven a devolverse y cruzar la calle esquivando carros, motos y tractomulas, existe una probabilidad, digamos 0.95, de que logren tener la  mostaza en su perro caliente sin que haya ocurrido ningún accidente. Situación número dos: cuando usted va a llegar a la otra acera, usted se da cuenta que olvido a su hijo y cuando voltea su mirada, el niño está intentando cruzar la calle. Inmediatamente usted se devuelve esquivando carros, motos y tractomulas. Existe una probabilidad de 0.95 de que usted alcance a su hijo y llegue a la otra acera de la calle sano y salvo.

Dos situaciones con dos premios distintos, la mostaza o su hijo, y con la misma probabilidad. La significación estadística ignora esta diferencia puesto que las dos decisiones son iguales en cuanto a la probabilidad de ''éxito". Ambas variables NIÑO y MOSTAZA son significativas si $ p<0.05$ y la conclusión sería: existen dos razones, que son igualmente importantes, para cruzar la calle.

Es claro que lo anterior es un punto muy bueno. Los métodos estadísticos deben tener validez teórica desde el punto de vista del usuario. De esta manera, en epidemiología, economía, contaduría, sociología o en marketing, los métodos estadísticos tienen validez siempre y cuando sirvan para apoyar la teoría desarrollada en estas áreas del conocimiento. No le digan a un gerente de mercadeo que la variable satisfacción del consumidor no entra en el modelo de regresión porque el beta no resultó significativo. En estos aspectos, la ciencia estadística debe ser vista como una herramienta. Ahora, como sucede con toda herramienta, es necesario adecuarla al terreno y afinarla de tal manera que se convierta en una herramienta indispensable en manos del experto y no en una más de las herramientas a las cuales se puede acceder. En esta ocasión, le tocó el turno al análisis de correspondencias. Específicamente al muy conocido y bien ponderado mapa perceptual, resultado de este análisis.

Jim Berger ha diseñado un software que demuestra que las interpretaciones usuales acerca de los $p$-valores pueden ser erradas. Al respecto, John Cook hace una lista de cinco autores que tienen puntos de vista muy críticos acerca de la práctica e interpretación  usual del estadístico con respecto al procedimiento de las pruebas de hipótesis.

Andrew Gelman afirma que en la realidad, la hipótesis nula es siempre falsa. ¿Es el tratamiento A igual de efectivo al tratamiento B? Seguramente no. Está claro que antes de la realización de un experimento deben existir algunas diferencias que se pueden manifestar con un número suficiente de datos.

Según Jim Berger, un $p$-valor pequeño implica que los datos recolectados son inverosímiles bajo la hipótesis nula. Sin embargo, también pueden serlo bajo la hipótesis alternativa. Las comparaciones de las hipótesis deberían estar condicionadas a la realización de los datos.

Stephen Ziliak y Deirdra McCloskey indican que la significación estadística no es lo mismo que la significación científica. La cuestión más importante para la ciencia es el tamaño de un efecto y no si existe o no tal efecto.

Para William Gosset, el error estadístico es sólo uno de los componentes del error real y quizás sea un componente pequeño.

John Ioannidis, por último, señala que los $p$-valores pequeños no implican una probabilidad pequeña de que la hipótesis nula sea incorrecta. En una revisión de estudios médicos se encontró que el 74\% de los estudios con $p$-valores menores que 0.05 llegaba a conclusiones erróneas.

Algun extremista diría que la herramienta de las pruebas de hipótesis y de sus respectivos $p$-valores es una mala herramienta. Nuestro punto de vista es que cuando se entiende que un $p$-valor es una variable aleatoria, entonces las conclusiones y por consiguiente la toma de decisiones se hacen con más cuidado. Sin embargo, existe otra herramienta estadística que puede ser usada como complemento a los $p$-valores. Se trata de los factores de Bayes que son la razón entre las probabilidades a posteriori de las dos hipótesis, dada la realización de los datos. Según John Cook, los factores de Bayes no tienen las debilidades de las pruebas de hipótesis, especialmente las que señalan los criticismos de Jim Berger y John Ioannidis.


\subsection{$p$ valores aleatorios}

En esta época de avances computacionales, una lección de intervalos de confianza incluye, además de teoría, simulaciones que tienden a enfatizar el carácter aleatorio de los límites de los intervalos de confianza: un parámetro se fija y el 95\% de los intervalos construidos en la simulación lo cubren. Pero qué pasa con la enseñanza de otros conceptos fundamentales de la inferencia estadística. En esta entrada vamos a enfocarnos en una metodología alternativa en la enseñanza del $p$ valor.

La respuesta que muchos usuarios de la estadística, no estadísticos, encuentran frente a la pregunta ¿qué es un $p$ valor? ¿es un $p$ valor la probabilidad de que la hipótesis nula ($H_o$) sea cierta?.

La anterior respuesta es, además de pragmática y utilitarista, falsa. Lo cierto es que, técnicamente, la definición de $p$ valor es la siguiente: un $p$ valor es la probabilidad, calculada al asumir que Ho es cierta, de que la estadística de prueba tome valores tan o más extremos que los calculados con la muestra actual.

Ahora, dado que las estadísticas de prueba se construyen para cuantificar las desviaciones de la hipótesis nula con los datos actuales, entonces rechazamos Ho cuando el $p$ valor es pequeño porque si éste es pequeño entonces los datos actuales proveen una fuerte evidencia en contra de Ho. En otras palabras, el hecho de que el $p$ valor sea grande hace que Ho sea difícil de rechazar; por tanto, es casi intuitivo, pero no valido, tomar al $p$ valor como una medida de soporte en contra (o a favor) del rechazo de Ho.

Sin embargo, esta presentación estándar esconde la aleatoriedad del $p$ valor. El $p$ valor es una estadística, por tanto es aleatorio y no puede ser interpretado como una medida de soporte. Se sugiere, siguiendo los lineamentos de Murdoch (2008), que la enseñanza de este importante concepto siga una metodología alternativa, basada en simulaciones, totalmente diferente a lo que hasta ahora se está realizando. Con un simple ejemplo es posible que el estudiante entienda que un $p$ valor es una cantidad aleatoria condicionada a las realizaciones de las variables aleatorias de la muestra y, por consiguiente, será posible liberarnos de las definiciones incorrectas que pueden guiar a malinterpretaciones en el campo aplicado.

Considere una prueba $t$, basada en una muestra aleatoria de tamaño $n$ y con distribución $N(\mu, 1)$, apoyada en el siguiente sistema de hipótesis

$H_0:\ \mu=0$            vs.   $H_a:\ \mu\neq0.$

Es claro que la estadística de prueba sigue una distribución t-student con (n-1) grados de libertad. Para presentar los resultados, es conveniente empezar con $H_0:\ \mu=0$ .

Bajo la hipótesis nula, el histograma de los $p$ valores toma la forma de una distribución plana y uniforme sobre el intervalo [0, 1]. Para enfatizar el punto de que un $p$ valor no es la probabilidad de que Ho sea cierto, el instructor sólo necesita explicar este histograma, en donde claramente Ho es cierta; sin embargo, el $sp$ valor está uniformemente distribuido entre cero y uno.
Bajo la hipótesis alternativa, la distribución de los $p$ valores no es uniforme (ver Figura 4.22). Es claro que el chance de obtener $p$ valores menores al nivel de significación será más alto bajo la hipótesis alterna que bajo la hipótesis nula y ese efecto es más claro a medida que mu incrementa su valor.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{pval1.eps}
\caption{\textsl{$p$ valores aleatorios}}
\end{figure}

Ahora, consideramos el sistema de la forma

$H_0:\ \mu=0$             vs.    $H_a:\ \mu<0.$

Bajo $H_a$, la distribución de los $p$ valores sobre el intervalo [0, 1] no será uniforme y tenderá al valor uno (ver Figura 4.23). De esta forma, queda claro que la distribución de los p valores no está determinada por el sistema de hipótesis sino por los parámetros.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{pval2.eps}
\caption{\textsl{$p$ valores aleatorios}}
\end{figure}

El programa en R de la simulación de los $p$ valores que generaron las anteriores gráficas se encuentra a continuación.

\begin{verbatim}
set.seed(7654321,kind=NULL)
nsim<-10000
p<-rep(NA,nsim)
par(mfrow=c(1,2))
#################### H0 mu=0 #####################
for(m in 1:nsim){
n<-4
mu<-0.5
x<-rnorm(n,mu,1)
xbar<-mean(x)
s<-sqrt(var(x))
T<-abs((xbar-mu)/(s/sqrt(n)))
p[m]<-2*(1-pt(T,n-1))
#-----------------------
if(floor(m/1000)==m/1000) print(m)
}
hist(p,main=c("mu = 0"))
#################### Ha mu=1 #####################
for(m in 1:nsim){
n<-4
mu<-0
x<-rnorm(n,mu,1)
xbar<-mean(x)
s<-sqrt(var(x))
T<-abs((xbar-1)/(s/sqrt(n)))
p[m]<-2*(1-pt(T,n-1))
#-----------------------
if(floor(m/1000)==m/1000) print(m)
}
hist(p,main=c("mu = 1"))
#################### H0 mu<0 #####################
for(m in 1:nsim){
n<-4
mu<--0.5
x<-rnorm(n,mu,1)
xbar<-mean(x)
s<-sqrt(var(x))
T<-(xbar-0)/(s/sqrt(n))
p[m]<-1-pt(T,n-1)
#-----------------------
if(floor(m/1000)==m/1000) print(m)
}
hist(p,main=c("mu = -0.5"))
\end{verbatim}


\subsubsection{Nota bibliográfica}

Erin Leahey, en un reciente artículo, escribe acerca del uso del nivel de significación en pruebas estadísticas, el valor 0.05 y el sistema de tres estrellas que se han convertido en métodos legítimos y dominantes en la mayoría de las investigaciones de tipo social. De acuerdo a Erin, el sistema de hipótesis merece una estrella cuando el $p$-valor es menor de 0.05, dos estrellas si el $p$-valor es menor de 0.01 y tres estrellas si el $p$-valor es menor de 0.001. Erin atribuye el primer uso del nivel de significación 0.05 a Ronald Fisher en su libro publicado en 1935, \emph{Diseño de experimentos}. También nota que otras formas de pruebas de significación eran muy populares en la década de 1930, cuando cerca del 40\% de los artículos publicados en ASR y AJS aplicaban sólo una técnica de prueba de significación.

El famoso 0.05, que nos da de comer a la mayoría de nosotros, fue muy usado desde 1930 hasta 1950, pero declinó hasta 1970. Sin embargo, volvió a revivir hasta nuestra época. Actualmente, cerca del 80\% de los artículos publicados en ASR y AJS emplean ambos procedimientos (nivel de significación y estrellas). El sistema de tres estrellas emergió en la década de 1950, pero se volvió muy popular sólo después de 1970. Un porcentaje cercano al 40\% de artículos publicados en los anteriores journals utiliza la metodología de las tres estrellas.

¿Qué es lo que cuenta en la difusión de tales prácticas? Erin da varios argumentos para responder a esta pregunta. Por ejemplo, ella concluye que los factores institucionales como inversión en investigación y computadores, entrenamiento a nivel de postgrado y la preferencia del editor del journal pueden ser algunos de los factores más importantes en la difusión de tales prácticas. En una conclusión muy interesante, ella encontró que los egresados de Harvard tenían un efecto negativo significativo al adoptar tales prácticas estadísticas.

Por supuesto, este estudio está limitado a la muestra que tomó Erin y no puede ser generalizado. Sin embargo, es una lectura divertida. Si alguien está interesado en los elementos históricos de cómo las prácticas estadísticas fueron introducidas y comenzaron a legitimarse en la investigación social, Camic y Xie (1994) es un muy buen punto de partida.

\subsection{El $p$ valor no es una medida de soporte}

\citeasnoun{Mark} afirma que los $p$-valores están siendo usados por los usuarios de la estadística como medidas de soporte (además de algunas otras malinterpretaciones) cuando éstos precisamente se caracterizan por carecer de consistencia como medidas de la evidencia a favor de un conjunto de hipótesis. Al respecto, es plausible pensar que si es posible obtener evidencia de que cierto animal es un oso, entonces debe existir también evidencia para afirmar que ese animal es un mamífero. Nótese que en el ejemplo anterior existen dos hipótesis: la primera hace referencia a que el animal es un oso y la segunda a que el animal es un mamífero y, por supuesto, la primera está contenida en la segunda. Ahora, utilizar los $p$-valores como una medida de soporte a favor de la evidencia de la segunda hipótesis puede ser una muy mala idea.

Una medida de soporte debería satisfacer la siguiente propiedad (muy útil en el contexto de comparaciones múltiples):

\begin{quote}
Si una hipótesis $H_1$ implica una hipótesis $H_2$, entonces una medida de soporte es coherente si el rechazo de $H_2$ siempre implica el rechazo de $H_1$
\end{quote}


En otras palabras:

\begin{quote}
Si una hipótesis $H_1$ implica otra $H_2$, entonces la evidencia a favor de $H_2$ debe ser al menos tan grande como la evidencia en favor de $H_1$
\end{quote}


Teniendo en cuenta este criterio, se sigue que el $p$-valor es una pésima medida de soporte. Schervish lo explica con el siguiente ejemplo: suponga que se observa la realización de una variable aleatoria con distribución normal de varianza una y media desconocida. Sea $H_1:\mu\in(-0.5,0.5)$ y sea $H_2:\mu\in(-0.82,0.52)$, claramente el espacio paramétrico de $H_1$ está contenido en $H_2$ y, por consiguiente, $H_1$ implica $H_2$.

\citeasnoun{Mark}, citando el libro de \citeasnoun{Lehmann86}, establece la regla de decisión para sistemas del tipo $H_0:\ \mu\in(\mu_1,\mu_2)$ vs. $H_0:\ \mu\notin(\mu_1,\mu_2)$ basado en una observación como rechazar $H_0$ si $|x-0.5(\mu_1+\mu_2)|>c$ donde $c$ es una constante que satisface $\Phi(0.5(\mu_1-\mu_2)-c)+\Phi(0.5(\mu_2-\mu_1)-c)=\alpha$. El $p$-valor de esta regla de decisión se puede calcular como
\begin{equation*}
p-\text{valor}=\begin{cases}
\Phi(x-\mu_1)+\Phi(x-\mu_2)&\text{si $x<0.5(\mu_1+\mu_2)$}\\
\Phi(\mu_1-x)+\Phi(\mu_2-x)&\text{si $x\geq0.5(\mu_1+\mu_2)$}
\end{cases}
\end{equation*}

Ahora, si la observación correspondió a $x=2.18$, entonces para probar $H_1:\mu\in(-0.5,0.5)$, $\mu_1=-0.5$, $\mu_2=0.5$ y $x>0.5(\mu_1+\mu_2)$, por consiguiente el $p$-valor se calcula como $\Phi(-0.5-2.18)+\Phi(0.5-2.18)=0.05016$. Por otro lado, si se desea probar $H_2:\mu\in(-0.82,0.52)$, entonces $\mu_1=-0.82$, $\mu_2=0.52$ t de nuevo $x>0.5(\mu_1+\mu_2)$, y el $p$-valor se calcula como $\Phi(-0.82-2.18)+\Phi(0.52-2.18)=0.0498$. Lo anterior implica que, tomando el $p$-valor como medida de soporte, existe más evidencia a favor de $H_1$ que a favor de $H_2$, lo cual es contradictorio con el sentido común. Más aún, si el nivel de significación es de 0.05, la regla de decisión implicaría que debemos rechazar $H_2$ y aceptar $H_1$. En otras palabras, la media de la distribución puede estar entre (-0.5, 0.5), pero de ninguna manera puede estar entre (-0.82, 0.52), lo cual es muy contradictorio.

Lo anterior nos ilustra que en la práctica, cuando tenemos varios sistemas de hipótesis, cada uno debe ser tratado de manera individual. Es errado tomar decisiones acerca de un sistema usando como base la decisión tomada acerca de otro sistema o lo que puede llamar la transitividad, tal como se ilustró anteriormente.

\subsection{Acerca de la igualdad en la hipótesis nula}

Para terminar el tema de prueba de hipótesis, discutimos la posibilidad de incluir el signo igual en la hipótesis nula. Suponga que se dispone de una muestra aleatoria de tamaño $n$ denotada por $X_1$, $\cdots$, $X_n$ y proviene de una distribución $N(\mu,\sigma^2_0)$ con $\mu$ desconocido y $\sigma^2_0$ conocido. Y supongamos que el sistema de hipótesis de interés es
\begin{equation}\label{Sistema}
H_0:\ \mu>\mu_0\ \ \ vs.\ H_1:\ \mu\leq\mu_0,
\end{equation}
donde la igualdad $\mu=\mu_0$ está incluida dentro del espacio paramétrico especificado por la hipótesis alterna, $H_1$. En la teoría estadística, no se establece con claridad si se pueden plantear sistemas de esta forma. \citeasnoun{Igualdad} encontró que en el sistema (\ref{Sistema}), se puede encontrar una regla de decisión sin mayores complicaciones, pero a pesar de esto, al incluir la igualdad en $H_1$, se conducirá a una contradicción con el estimador de máxima verosimilitud, y por consiguiente se recomienda poner la igualdad en la hipótesis nula $H_0$.

La hipótesis alterna del sistema (\ref{Sistema}) especifica espacios paramétricos que incluyen valores menores o iguales a $\mu_0$, entonces es natural pensar en rechazar $H_0$ cuando $\bar{X}<K$ para alguna constante $K$. Ahora, para determinar el valor de $K$ y completar la regla de decisión, recurrimos a la definición del tamaño de una prueba dada por
\begin{equation}
\alpha=sup\{P(\text{rechazar}\ H_0)\}\ \text{cuando $H_0$ es verdadera}.
\end{equation}

En el sistema específico (\ref{Sistema}), la anterior definición se convierte en
\begin{equation}\label{Alpha}
\alpha=sup\left\{P(\bar{X}<K)\right\}\ \text{cuando $H_0$ es verdadera}.
\end{equation}

Para determinar el valor de $K$ es necesario encontrar la distribución nula de $\bar{X}$, esto es, la distribución de $\bar{X}$ cuando $H_0$ es verdadera. Ahora, la hipótesis nula $\mu>\mu_0$ es equivalente a $\mu=\mu^*$ con $\mu^*>\mu_0$. De esta forma, tenemos que
\begin{equation}
\dfrac{\sqrt{n}(\bar{X}-\mu^*)}{\sigma_0}\sim\ N(0,1).
\end{equation}

Por lo tanto, la definición (\ref{Alpha}) se convierte en
\begin{align}
\alpha&=sup\left\{\mu^*>\mu_0:\ P\left(\dfrac{\sqrt{n}(\bar{X}-\mu^*)}{\sigma_0}<\dfrac{\sqrt{n}(K-\mu^*)}{\sigma_0}\right)\right\}\\
&=sup\left\{\mu^*>\mu_0:\ \Phi(\dfrac{\sqrt{n}(K-\mu^*)}{\sigma_0})\right\},
\end{align}

donde $\Phi(\cdot)$ denota la función de distribución correspondiente a la distribución normal estándar. Como $\Phi(\dfrac{\sqrt{n}(K-\mu^*)}{\sigma_0})$ es una función decreciente de $\mu^*$, entonces el supremo del conjunto $\left\{\mu^*>\mu_0:\ \Phi(\dfrac{\sqrt{n}(K-\mu^*)}{\sigma_0})\right\}$ se da cuando $\mu^*=\mu_0$. Y en este caso, se tiene que $\alpha=\Phi(\dfrac{\sqrt{n}(K-\mu_0)}{\sigma_0})$, y podemos obtener el valor de $K$ como
\begin{equation}
K=\mu_0+\Phi^{-1}(\alpha)\dfrac{\sigma_0}{\sqrt{n}}=\mu_0+z_{\alpha}\dfrac{\sigma_0}{\sqrt{n}},
\end{equation}

y así, encontramos a la regla de decisión: rechazar $H_0$ si $\bar{X}<\mu_0+z_{\alpha}\dfrac{\sigma_0}{\sqrt{n}}$, equivalente a rechazar $H_0$ si $\dfrac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}<z_{\alpha}$ y el tamaño de la prueba es $\alpha$. Nótese que
\begin{itemize}
    \item La regla de decisión encontrada anteriormente coincide con la regla de decisión del sistema de hipótesis $H_0:\ \mu\geq\mu_0\ \ \ vs.\ H_1:\ \mu<\mu_0$. Es decir, el hecho de que $H_1$ incluye la igualdad no afectó matemáticamente en la regla de decisión.
    \item La razón por la que la inclusión de la igualdad en $H_1$ no influyó en la regla de decisión es el hecho de que el tamaño de una prueba se define con término del supremo tal como se definió en (\ref{Alpha}). Si en lugar del supremo se u\-sa\-ra el máximo, el anterior procedimiento ya no será válido, y no será posible matemáticamente encontrar una regla de decisión de tamaño $\alpha$.
\end{itemize}

Ahora, veamos que esta regla de decisión puede conducir a una contradicción con el estimador de máxima verosimilitud en algunos casos.

Dada la regla de decisión, el $p$-valor se calcula como $\Phi(z)$ con $z$ el valor que toma la estadística de prueba $\sqrt{n}(\bar{X}-\mu_0)/\sigma_0$. Suponga que en una muestra observada, el estimador de máxima verosimilitud dio exactamente el valor $\mu_0$, es decir, $\bar{x}=\mu_0$. En este caso, $z=0$, y el $p$-valor será $\Phi(0)=0.5$ y nos lleva a la decisión de aceptar $H_0:\ mu>\mu_0$ el cual no incluye el valor de $\mu_0$. Esto es una clara contradicción, puesto que se rechaza el valor de $\bar{x}$ como posible valor de $\mu$.

\section{Ejercicios}
\begin{enumerate}[4.1]

\item Para las siguientes situaciones, plantee un sistema de hipótesis donde el error tipo I es más grave que el error tipo II.
        \begin{enumerate}[(a)]
            \item El gerente de una empresa de ventas desea conocer el rendimiento del empleado Pérez, y el índice que el gerente tiene en cuenta es el porcentaje de ventas exitosas $p$, y el gerente cree que un porcentaje inferior a los 20\% es indicio de un desempeño pobre. Desde el punto de vista del gerente ¿cómo se puede plantear el sistema de hipótesis?
            \item En un departamento del país se modifica la fecha para pagar los impuestos prediales, y la entidad está interesada en conocer si la población está enterada de ese cambio, y además la entidad considera que con las publicidades realizadas, más del 80\% de la población conoce del cambio, ¿cómo se puede plantear el sistema?
        \end{enumerate}

\item Sea $X_1$, $\cdots$, $X_n$ proveniente de una población $N(\mu,\sigma^2)$ donde $\sigma^2=\sigma_0^2$ es conocida, para el siguiente sistema de hipótesis
        \begin{equation*}
        H_0:\ \mu\geq\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu<\mu_0,
        \end{equation*}

        Desarrolle una regla de decisión para el anterior sistema. Además, especifique la estadística de prueba, dibuje la región de rechazo y obtenga la fórmula del $p$ valor y la función de potencia. ¿El uso de cuál intervalo de confianza es equivalente al uso de la regla de decisión encontrada?

\item Repetir el anterior ejercicio con el sistema de hipótesis
            \begin{equation*}
            H_0:\ \mu\leq\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu>\mu_0
            \end{equation*}

            con $\sigma^2$ desconocida.

\item Sea $X_1$, $\cdots$, $X_n$, proveniente de una población $N(\mu,\sigma^2)$ donde $\sigma^2$ es desconocida. Encuentre una regla de decisión para el siguiente sistema de hipótesis:
        \begin{equation*}
        H_0:\ \mu=\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu<\mu_0.
        \end{equation*}
        \begin{enumerate}[(a)]
            \item Sin usar la prueba de razón de verosimilitud.
            \item Usando la prueba de razón de verosimilitud.
        \end{enumerate}

\item Un tipo de bombillo industrial debe tener la vida útil promedio superior a 12 mil horas para poder entrar al mercado colombiano. Para verificar que cumplen con este requisito, se seleccionó 20 bombillos y los resultados del laboratorio indican que la vida útil de estos 20 bombillos es repectivamente (en miles de horas):  11.4, 12.1, 12.5, 13.1, 12.6, 11.9, 12.4, 13.1, 14.0, 11.9, 13.1, 12.8, 12.6, 13.2, 12.4, 11.6, 13.0, 12.4, 12.6, 12.5.
    \begin{enumerate}[(a)]
      \item Encuentre una distribución apropiada para los datos.
      \item Plantee un sistema de hipótesis adecuado y aplique el procedimiento adecuado (calculando el $p$ valor) para decidir si los bombillos pueden o no entrar al mercado colombiano.
    \end{enumerate}

\item Demuestre las expresiones (\ref{potencia_sigma2}) y (\ref{potencia_sigma3}).

\item Sea $X_1$, $\cdots$, $X_n$ proveniente de una población $N(\mu,\sigma^2)$, encuentre una regla de decisión, $p$ valor y la función de potencia para el sistema de hipótesis
            \begin{equation*}
            H_0:\ \sigma^2=\sigma^2_0\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2<\sigma^2_0.
            \end{equation*}
    cuando
    \begin{enumerate}[(a)]
        \item $\mu$ es conocido.
        \item $\mu$ es desconocido.
    \end{enumerate}

\item Para los datos del Ejercicio 4.4, plantee un sistema de hipótesis para corroborar o refutar la hipótesis de que la vida útil entre los bombillos se difiere a lo más por 500 horas.

\item Escriba la fórmula del $p$ valor y la función de potencia para el sistema $H_0:\ \mu_X=\mu_Y$ vs. $H_0:\ \mu_X\neq\mu_Y$ cuando las varianzas son iguales pero desconocidas. Utilice la fórmula encontrada para calcular el $p$ valor para los datos del Ejemplo 4.3.1, y compare con el $p$ valor obtenido en el ejemplo con el comando \verb"t.test".

\item Sea $X_1$, $\cdots$, $X_n$ y $Y_1$, $\cdots$, $Y_m$ dos muestras aleatorias independientes provenientes de $N(\mu_X,\sigma_X^2)$ $N(\mu_Y,\sigma_Y^2)$ respectivamente. Encuentre reglas de decisión para los siguientes sistemas de hipótesis.
        \begin{enumerate}[(a)]
        \item $H_0:\ \mu_X-\mu_Y\leq\mu_0\ \ \ \ vs.\ \ \ \ H_1:\ \mu_X-\mu_Y>\mu_0$ con $\sigma^2_X=\sigma^2_Y$ desconocidas.
        \item $H_0:\ \sigma^2_X=\sigma^2_Y\ \ \ \ vs.\ \ \ \ H_1:\ \sigma^2_X\neq\sigma^2_Y$ con $\mu_X$ y $\mu_Y$ conocidos.
        \end{enumerate}

\item Un ganadero desea aumentar la producción lechera diaria de sus vacas, y decide probar un nuevo concentrado. Para verificar la efectividad del nuevo concentrado, el ganadero separa 35 vacas, de las cuales 15 son alimentadas con el concentrado actual y las restantes con el concentrado nuevo. Después de tres semanas de alimentación, él toma nota de la producción lechera. Para las vacas alimentadas con el concentrado actual, los resultados fueron (en litros): 16.4, 18.9, 15.7, 20.2, 16.8, 19.4, 14.7, 17.8, 19.5, 16.8, 18.4, 14.6, 20.7, 21.1, 17.3, y para las vacas alimentadas con el concentrado nuevo, los resultados fueron: 19.4, 18.1, 21.0, 20.4, 20.5, 17.4, 19.6, 18.4, 21.4, 19.2, 15.7, 22.8, 21.6, 17.2, 18.4, 19.4, 20.5, 23.6, 18.4, 18.3.
        Contesta las siguientes preguntas usando técnicas de prueba de hipótesis
        \begin{enumerate}[(a)]
        \item Verifique si los datos pueden ser descritos de manera adecuada con la distribución normal.
        \item ¿Los dos tipos de concentrados son iguales de efectivos? Si la respuesta es negativa, ¿cuál es más efectivo?
        \item ¿Cuál concentrado produce resultados más homogéneos?
        \end{enumerate}

\item Verifique las expresiones (\ref{mui_MV}), (\ref{varianza_comun}), (\ref{mu_0_comun}) y (\ref{sigma_0_comun}).

\item Suponga que para aumentar la producción de la cosecha arrocera hay tres tipos de abonos. Para conocer cuál de los tres tipos de abonos es el más eficiente, se divide una finca de 100 hectáreas con cultivos de arroz en 4 grupos de 25 hectáreas cada uno, y a 3 de 4 grupos se les aplican los 3 abonos, y al grupo restante no se le aplica ningún abono. Para cada una de las 100 hectáreas se mide la producción arrocera (en toneladas), los datos se muestran en la Tabla 4.12.
    \begin{table}[!h]
    \centering
   \begin{tabular}{|c|c|}
     \hline
     % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
     Abono & Producción (en toneladas)\\\hline
     A & 3.0, 3.1, 2.6, 2.6, 2.1, 2.9, 2.5, 3.5, 3.3, 3.6, 3.9, 3.8, 1.8\\
      &2.8, 3.7, 3.8, 3.1, 2.8, 2.4, 3.0, 2.6, 2.9, 3.9, 4.2, 3.4 \\\hline
     B & 3.3, 3.6, 4.1, 2.6, 3.1, 2.9, 3.0, 2.7, 2.7, 3.4, 2.7, 3.3, 3.1\\
      &2.8, 3.4, 3.3, 3.1, 2.9, 2.8, 2.9, 2.3, 3.0, 3.2, 3.1, 3.1 \\\hline
     C &  5.1, 5.1, 5.5, 4.9, 5.1, 5.6, 5.0, 5.5, 4.7, 5.7, 5.3, 4.5, 4.4\\
      &5.1, 5.1, 5.1, 5.1, 4.9, 4.6, 4.9, 4.9, 4.5, 4.4, 5.4, 4.6\\\hline
     D & 5.8, 5.8, 5.6, 5.3, 6.1, 5.7, 6.0, 5.6, 6.1, 5.9, 5.1, 5.3, 5.0\\
     &5.6, 5.3, 5.5, 4.6, 5.4, 6.0, 6.0, 5.6, 5.7, 5.2, 5.9 , 5.6 \\\hline
     Ninguno &  3.1, 2.9, 2.9, 3.1, 3.4, 2.5, 3.3, 2.7, 3.2, 1.9, 2.5, 2.9\\
      &3.1, 2.2, 2.4, 2.9, 3.2, 2.5, 2.2, 3.0, 2.7, 4.0, 2.7, 3.3, 3.6\\\hline
   \end{tabular}\caption{\emph{Datos del Ejercicio 4.13.}}
   \end{table}
    \begin{enumerate}[(a)]
        \item Lleve a cabo un procedimiento de prueba de hipótesis para ver si hay diferencias significativas en términos de producción entre la aplicación y no de abonos.
        \item Lleve a cabo un procedimiento de prueba de hipótesis para ver si hay diferencias significativas entre los diferentes tipos de abonos.
        \item Si hay diferencia entre los diferentes tipos de abonos, diga cuáles abonos son similares y cuáles son diferentes.
    \end{enumerate}

\item Sea $X_1$, $\cdots$, $X_n$ proveniente de una población $Ber(p)$, encuentre una regla de decisión para el sistema de hipótesis usando la razón de verosimilitud:
        \begin{equation*}
        H_0:\ p=p_0\ \ \ \ vs.\ \ \ \ H_1:\ p>p_0,
        \end{equation*}

\item Demuestre la expresión (\ref{binom_p_comun_MV}).

\item Repita el Ejemplo 4.5.1 usando la prueba exacta. Compare el resultado obtenido con el de la prueba asintótica.

\item Una semana antes de comenzar las elecciones presidenciales, a los estudiantes mayores de 18 años de una universidad privada se les pregunta: ¿usted va a votar en estas elecciones?. Se observó que entre los 312 estudiantes entrevistados, 198 respondieron sí a la pregunta. Suponga que el parámetro de interés es el porcentaje de estudiantes que votarán este 30 de mayo.
    \begin{enumerate}[(a)]
        \item  ¿Se puede afirmar que más de la mitad de los estudiantes de esta universidad votarán en las elecciones?
        \item Suponga que en una universidad pública, se realizó el mismo estudio, y de los 571 entrevistados, 420 dijeron que sí. ¿Se puede afirmar que el porcentaje de los estudiantes que votarán es el mismo en las dos universidades?
    \end{enumerate}

\item El director de un hospital, con el fin de mejorar la atención en la sección de urgencias, necesita conocer acerca del número de clientes que llegan en una hora a urgencias. Si durante dos semanas se observa el número de pacientes durante una misma hora, y los resultados son 5, 6, 3, 6, 7, 3, 5, 4, 8, 1, 5, 4, 1 y 6.
    \begin{enumerate}[(a)]
        \item ¿Qué distribución parece ser apropiada para estos datos?
        \item Si la hipótesis que maneja el hospital antes del estudio es que en promedio llegan 5 pacientes por hora, ¿qué conclusión se puede obtener acerca de esta hipótesis basándose en los datos observados?
    \end{enumerate}

\item En el contexto planteado en el ejercicio anterior, en época de invierno, más pacientes recurren a urgencias. Si los datos del ejemplo anterior denotan el número de pacientes en días normales, y en épocas de invierno, los datos registrados en dos semanas fueron 8, 6, 13, 8, 7, 8, 3, 10, 8, 7, 5, 9, 7 y 8. ¿Se puede afirmar que el número de clientes que llegan a urgencias en una hora es diferente en invierno?


\item Sea $X_1$, $\cdots$, $X_n$ proveniente de una población $Pois(\theta)$, encuentre una regla de decisión para el sistema de hipótesis:
        \begin{equation*}
        H_0:\ \theta\geq\theta_0\ \ \ \ vs.\ \ \ \ H_1:\ \theta<\theta_0.
        \end{equation*}

\item Repita el Ejemplo 4.6.1 usando la prueba exacta. Compare el resultado obtenido con el del ejemplo.

\item Para los datos del Ejercicio 3.16, plantee un sistema de hipótesis para probar que desde el momento de contacto, la enfermedad demora menos de 20 horas en manifestar síntomas.

\item Se desea comparar dos marcas de bombillos, Philips y Filips, para eso se realiza un estudio donde se pone a funcionar bombillos de ambas marcas y se registra el tiempo que duran estos bombillos antes de fundirse, de lo cual se obtienen los siguientes datos. Para 100 bombillos de la marca Philips, el tiempo promedio de duración es de 11300 horas, mientras que para 100 bombillos de la marca Filips, el tiempo promedio de duración es de 8050 horas. ¿Se puede afirmar que las dos marcas tienen la misma calidad?

\item Demuestre la expresión (\ref{exp_lambda_tarea}), (\ref{potencia_exp_z}) y (\ref{lambda_exp_2}).

\end{enumerate}

